Sender: LSF System <lsfadmin@eu-g3-025>
Subject: Job 232208905: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-03> by user <goezsoy> in cluster <euler> at Fri Sep 23 16:43:41 2022
Job was executed on host(s) <4*eu-g3-025>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Fri Sep 23 16:44:06 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Fri Sep 23 16:44:06 2022
Terminated at Fri Sep 23 16:44:38 2022
Results reported at Fri Sep 23 16:44:38 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   10.37 sec.
    Max Memory :                                 5888 MB
    Average Memory :                             244.00 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               10496.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                4
    Run time :                                   31 sec.
    Turnaround time :                            57 sec.

The output (if any) follows:

2022-09-23 16:44:09.476012: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-23 16:44:28.733163: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-23 16:44:28.739509: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-23 16:44:28.793580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:41:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-23 16:44:28.793625: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-23 16:44:28.830569: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-23 16:44:28.830649: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-23 16:44:28.842215: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-23 16:44:28.854265: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-23 16:44:28.885187: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-23 16:44:28.895781: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-23 16:44:28.899143: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-23 16:44:28.904422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-23 16:44:32.709918: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-23 16:44:32.711536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:41:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-23 16:44:32.711588: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-23 16:44:32.711637: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-23 16:44:32.711662: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-23 16:44:32.711686: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-23 16:44:32.711709: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-23 16:44:32.711731: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-23 16:44:32.711756: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-23 16:44:32.711780: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-23 16:44:32.714249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-23 16:44:32.718214: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-23 16:44:34.986947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-23 16:44:34.987020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-23 16:44:34.987034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-23 16:44:34.995943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:41:00.0, compute capability: 7.5)
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
cfg: {'experiment': {'name': '23_sep_layers6_s32_e256_latent50_constrastive_rec0', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 30, 'num_constrains': 6000, 'batch_size': 64, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 20, 'lrs': True}, 'model': {'latent_dim': 50, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Traceback (most recent call last):
  File "main_contrastive.py", line 124, in <module>
    run_experiment(cfg)
  File "main_contrastive.py", line 73, in run_experiment
    model.fit(train_generator, steps_per_epoch=int(len(Y)/cfg['training']['batch_size']), epochs=cfg['training']['epochs'], verbose=2)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 1050, in fit
    data_handler = data_adapter.DataHandler(
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py", line 1100, in __init__
    self._adapter = adapter_cls(
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py", line 779, in __init__
    peek, x = self._peek_and_restore(x)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py", line 836, in _peek_and_restore
    peek = next(x)
  File "/cluster/home/goezsoy/constrastive-DC-GMM/src/dataset.py", line 1252, in gen
    X_aug1 = self.transformation1(X, training=True)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py", line 1012, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py", line 375, in call
    return super(Sequential, self).call(inputs, training=training, mask=mask)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/functional.py", line 424, in call
    return self._run_internal_graph(
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/functional.py", line 560, in _run_internal_graph
    outputs = node.layer(*args, **kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py", line 1012, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py", line 277, in call
    output = control_flow_util.smart_cond(training, random_cropped_inputs,
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/utils/control_flow_util.py", line 114, in smart_cond
    return smart_module.smart_cond(
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/smart_cond.py", line 54, in smart_cond
    return true_fn()
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py", line 236, in random_cropped_inputs
    check = control_flow_ops.Assert(
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/util/dispatch.py", line 201, in wrapper
    return target(*args, **kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/util/tf_should_use.py", line 247, in wrapped
    return _add_should_use_warning(fn(*args, **kwargs),
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/ops/control_flow_ops.py", line 154, in Assert
    raise errors.InvalidArgumentError(
tensorflow.python.framework.errors_impl.InvalidArgumentError: Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: 72
72
Sender: LSF System <lsfadmin@eu-g3-029>
Subject: Job 232212340: <python main_contrastive.py --config ../config.yml> in cluster <euler> Done

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-03> by user <goezsoy> in cluster <euler> at Fri Sep 23 17:20:12 2022
Job was executed on host(s) <4*eu-g3-029>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Fri Sep 23 17:20:25 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Fri Sep 23 17:20:25 2022
Terminated at Fri Sep 23 18:24:11 2022
Results reported at Fri Sep 23 18:24:11 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   3916.16 sec.
    Max Memory :                                 10753 MB
    Average Memory :                             8943.42 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               5631.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                23
    Run time :                                   3825 sec.
    Turnaround time :                            3839 sec.

The output (if any) follows:

2022-09-23 17:20:29.923581: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-23 17:20:46.497775: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-23 17:20:46.505505: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-23 17:20:46.549638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:41:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-23 17:20:46.549684: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-23 17:20:46.651933: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-23 17:20:46.652017: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-23 17:20:46.693650: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-23 17:20:46.730463: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-23 17:20:46.828139: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-23 17:20:46.869717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-23 17:20:46.876314: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-23 17:20:46.881127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-23 17:20:50.555982: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-23 17:20:50.557781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:41:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-23 17:20:50.557825: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-23 17:20:50.557865: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-23 17:20:50.557886: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-23 17:20:50.557906: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-23 17:20:50.557926: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-23 17:20:50.557944: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-23 17:20:50.557963: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-23 17:20:50.557982: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-23 17:20:50.560599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-23 17:20:50.567028: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-23 17:20:52.804635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-23 17:20:52.804708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-23 17:20:52.804722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-23 17:20:52.814502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:41:00.0, compute capability: 7.5)
2022-09-23 17:20:54.234378: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-23 17:21:07.056053: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-23 17:21:08.699842: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-23 17:21:09.497174: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-23 17:21:09.501948: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2250010000 Hz
cfg: {'experiment': {'name': '23_sep_layers6_s32_e256_latent50_constrastive_rec0_2', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 5, 'num_constrains': 6000, 'batch_size': 64, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 20, 'lrs': True}, 'model': {'latent_dim': 50, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/5
937/937 - 729s - loss: 1874.7991
Epoch 2/5
937/937 - 736s - loss: 1785.5114
Epoch 3/5
937/937 - 741s - loss: 1743.3816
Epoch 4/5
937/937 - 751s - loss: 1614.5142
Epoch 5/5
937/937 - 812s - loss: 1488.0195
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
WARNING:tensorflow:Saver is deprecated, please switch to tf.train.Checkpoint or tf.keras.Model.save_weights for training checkpoints. When executing eagerly variables do not necessarily have unique names, and so the variable.name-based lookups Saver performs are error-prone.
finished pretraining
Sender: LSF System <lsfadmin@eu-lo-s4-073>
Subject: Job 232214073: <python main_contrastive.py --config ../config.yml> in cluster <euler> Done

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-03> by user <goezsoy> in cluster <euler> at Fri Sep 23 17:45:03 2022
Job was executed on host(s) <4*eu-lo-s4-073>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Fri Sep 23 17:45:18 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Fri Sep 23 17:45:18 2022
Terminated at Fri Sep 23 18:51:46 2022
Results reported at Fri Sep 23 18:51:46 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4340.26 sec.
    Max Memory :                                 8906 MB
    Average Memory :                             7406.44 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               7478.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                31
    Run time :                                   4003 sec.
    Turnaround time :                            4003 sec.

The output (if any) follows:

2022-09-23 17:45:23.791382: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-23 17:46:18.284138: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-23 17:46:18.302611: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-23 17:46:18.396251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:1c:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-23 17:46:18.396296: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-23 17:46:18.482061: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-23 17:46:18.482172: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-23 17:46:18.521655: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-23 17:46:18.553490: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-23 17:46:18.612420: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-23 17:46:18.642559: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-23 17:46:18.658441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-23 17:46:18.664396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-23 17:46:21.544291: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-23 17:46:21.548969: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-23 17:46:21.549777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:1c:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-23 17:46:21.549810: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-23 17:46:21.549849: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-23 17:46:21.549861: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-23 17:46:21.549872: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-23 17:46:21.549883: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-23 17:46:21.549894: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-23 17:46:21.549904: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-23 17:46:21.549915: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-23 17:46:21.551051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-23 17:46:21.555040: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-23 17:46:22.126882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-23 17:46:22.126916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-23 17:46:22.126922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-23 17:46:22.136597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1c:00.0, compute capability: 7.5)
2022-09-23 17:46:24.232361: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-23 17:46:31.105496: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-23 17:46:32.422815: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-23 17:46:32.886092: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-23 17:46:32.894560: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
cfg: {'experiment': {'name': '23_sep_layers6_s32_e256_latent50_constrastive3', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 3, 'num_constrains': 6000, 'batch_size': 64, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 20, 'lrs': True}, 'model': {'latent_dim': 50, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/3
937/937 - 1284s - loss: 40.8824 - cont_loss: 40.2126
Epoch 2/3
937/937 - 1306s - loss: 40.2889 - cont_loss: 39.6297
Epoch 3/3
937/937 - 1309s - loss: 40.1733 - cont_loss: 39.5245
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape_1:0", shape=(None,), dtype=int32), values=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape:0", shape=(None, None), dtype=float32), dense_shape=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
WARNING:tensorflow:Saver is deprecated, please switch to tf.train.Checkpoint or tf.keras.Model.save_weights for training checkpoints. When executing eagerly variables do not necessarily have unique names, and so the variable.name-based lookups Saver performs are error-prone.
finished pretraining
Sender: LSF System <lsfadmin@eu-g2-12>
Subject: Job 232223495: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-18> by user <goezsoy> in cluster <euler> at Fri Sep 23 21:28:29 2022
Job was executed on host(s) <4*eu-g2-12>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Fri Sep 23 21:28:53 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Fri Sep 23 21:28:53 2022
Terminated at Fri Sep 23 21:49:32 2022
Results reported at Fri Sep 23 21:49:32 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 143.

Resource usage summary:

    CPU time :                                   1370.92 sec.
    Max Memory :                                 9042 MB
    Average Memory :                             7855.76 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               7342.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                31
    Run time :                                   1238 sec.
    Turnaround time :                            1263 sec.

The output (if any) follows:

2022-09-23 21:28:57.322054: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-23 21:29:16.438912: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-23 21:29:16.445267: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-23 21:29:16.503090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3e:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-23 21:29:16.503163: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-23 21:29:16.512791: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-23 21:29:16.512918: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-23 21:29:16.516894: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-23 21:29:16.518697: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-23 21:29:16.526028: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-23 21:29:16.528293: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-23 21:29:16.531209: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-23 21:29:16.539523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-23 21:29:21.013854: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-23 21:29:21.018413: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-23 21:29:21.019192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3e:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-23 21:29:21.019225: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-23 21:29:21.019264: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-23 21:29:21.019275: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-23 21:29:21.019286: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-23 21:29:21.019296: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-23 21:29:21.019307: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-23 21:29:21.019316: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-23 21:29:21.019327: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-23 21:29:21.020280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-23 21:29:21.025270: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-23 21:29:21.692705: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-23 21:29:21.692744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-23 21:29:21.692751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-23 21:29:21.700824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:3e:00.0, compute capability: 7.5)
2022-09-23 21:29:23.667839: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-23 21:29:38.019450: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-23 21:29:39.976292: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-23 21:29:40.446233: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-23 21:29:40.449879: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape_1:0", shape=(None,), dtype=int32), values=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape:0", shape=(None, None), dtype=float32), dense_shape=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
cfg: {'experiment': {'name': '23_sep_layers6_s32_e256_latent50_constrastive_cont0', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 30, 'num_constrains': 6000, 'batch_size': 64, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 20, 'lrs': True}, 'model': {'latent_dim': 50, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/30
Traceback (most recent call last):
  File "main_contrastive.py", line 124, in <module>
    run_experiment(cfg)
  File "main_contrastive.py", line 73, in run_experiment
    model.fit(train_generator, steps_per_epoch=int(len(Y)/cfg['training']['batch_size']), epochs=cfg['training']['epochs'], verbose=2)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 1100, in fit
    tmp_logs = self.train_function(iterator)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 828, in __call__
    result = self._call(*args, **kwds)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 855, in _call
    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/function.py", line 2942, in __call__
    return graph_function._call_flat(
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/function.py", line 1918, in _call_flat
    return self._build_call_outputs(self._inference_function.call(
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/function.py", line 555, in call
    outputs = execute.execute(
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/execute.py", line 59, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
KeyboardInterrupt
Terminated
Sender: LSF System <lsfadmin@eu-g3-025>
Subject: Job 232224230: <python main_contrastive.py --config ../config.yml> in cluster <euler> Done

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-18> by user <goezsoy> in cluster <euler> at Fri Sep 23 21:49:55 2022
Job was executed on host(s) <4*eu-g3-025>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Fri Sep 23 21:50:27 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Fri Sep 23 21:50:27 2022
Terminated at Fri Sep 23 22:56:34 2022
Results reported at Fri Sep 23 22:56:34 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4356.57 sec.
    Max Memory :                                 11071 MB
    Average Memory :                             9103.38 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               5313.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                23
    Run time :                                   3967 sec.
    Turnaround time :                            3999 sec.

The output (if any) follows:

2022-09-23 21:50:30.845042: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-23 21:50:49.448209: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-23 21:50:49.453902: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-23 21:50:49.504416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:c1:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-23 21:50:49.504474: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-23 21:50:49.606352: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-23 21:50:49.606529: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-23 21:50:49.626624: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-23 21:50:49.664105: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-23 21:50:49.762179: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-23 21:50:49.804383: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-23 21:50:49.810391: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-23 21:50:49.814735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-23 21:50:53.565751: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-23 21:50:53.567314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:c1:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-23 21:50:53.567367: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-23 21:50:53.567415: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-23 21:50:53.567440: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-23 21:50:53.567464: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-23 21:50:53.567486: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-23 21:50:53.567509: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-23 21:50:53.567531: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-23 21:50:53.567554: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-23 21:50:53.569563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-23 21:50:53.572735: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-23 21:50:55.787304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-23 21:50:55.787591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-23 21:50:55.787602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-23 21:50:55.795686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:c1:00.0, compute capability: 7.5)
2022-09-23 21:50:57.266780: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-23 21:51:10.451082: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-23 21:51:12.091813: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-23 21:51:12.516003: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-23 21:51:12.517243: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2250005000 Hz
cfg: {'experiment': {'name': '23_sep_layers6_s32_e256_latent50_constrastive_cont0', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 5, 'num_constrains': 6000, 'batch_size': 64, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 20, 'lrs': True}, 'model': {'latent_dim': 50, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/5
937/937 - 770s - loss: 40.2878 - cont_loss: 40.2878
Epoch 2/5
937/937 - 789s - loss: 39.7123 - cont_loss: 39.7123
Epoch 3/5
937/937 - 783s - loss: 39.5674 - cont_loss: 39.5674
Epoch 4/5
937/937 - 776s - loss: 39.4956 - cont_loss: 39.4956
Epoch 5/5
937/937 - 790s - loss: 39.4155 - cont_loss: 39.4155
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape_1:0", shape=(None,), dtype=int32), values=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape:0", shape=(None, None), dtype=float32), dense_shape=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
WARNING:tensorflow:Saver is deprecated, please switch to tf.train.Checkpoint or tf.keras.Model.save_weights for training checkpoints. When executing eagerly variables do not necessarily have unique names, and so the variable.name-based lookups Saver performs are error-prone.
finished pretraining
Sender: LSF System <lsfadmin@eu-g3-039>
Subject: Job 232210891: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-03> by user <goezsoy> in cluster <euler> at Fri Sep 23 17:00:32 2022
Job was executed on host(s) <4*eu-g3-039>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Fri Sep 23 17:01:05 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Fri Sep 23 17:01:05 2022
Terminated at Fri Sep 23 23:04:22 2022
Results reported at Fri Sep 23 23:04:22 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

TERM_MEMLIMIT: job killed after reaching LSF memory usage limit.
Exited with exit code 137.

Resource usage summary:

    CPU time :                                   22347.05 sec.
    Max Memory :                                 16384 MB
    Average Memory :                             12593.13 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               0.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                23
    Run time :                                   21797 sec.
    Turnaround time :                            21830 sec.

The output (if any) follows:

2022-09-23 17:01:08.847549: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-23 17:01:21.226648: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-23 17:01:21.233551: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-23 17:01:21.282549: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:a1:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-23 17:01:21.282595: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-23 17:01:21.384904: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-23 17:01:21.384990: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-23 17:01:21.427323: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-23 17:01:21.464601: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-23 17:01:21.563452: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-23 17:01:21.606574: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-23 17:01:21.612882: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-23 17:01:21.616094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-23 17:01:25.320287: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-23 17:01:25.325272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:a1:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-23 17:01:25.325327: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-23 17:01:25.325377: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-23 17:01:25.325405: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-23 17:01:25.325431: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-23 17:01:25.325472: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-23 17:01:25.325498: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-23 17:01:25.325523: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-23 17:01:25.325549: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-23 17:01:25.327634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-23 17:01:25.331422: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-23 17:01:27.531946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-23 17:01:27.532013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-23 17:01:27.532023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-23 17:01:27.539864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:a1:00.0, compute capability: 7.5)
2022-09-23 17:01:28.924472: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-23 17:01:41.779248: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-23 17:01:43.376833: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-23 17:01:44.173406: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-23 17:01:44.174250: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2250045000 Hz
cfg: {'experiment': {'name': '23_sep_layers6_s32_e256_latent50_constrastive_rec0', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 30, 'num_constrains': 6000, 'batch_size': 64, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 20, 'lrs': True}, 'model': {'latent_dim': 50, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/30
937/937 - 722s - loss: 1873.8976
Epoch 2/30
937/937 - 761s - loss: 1780.8777
Epoch 3/30
937/937 - 849s - loss: 1768.7413
Epoch 4/30
937/937 - 834s - loss: 1637.9862
Epoch 5/30
937/937 - 821s - loss: 1500.4768
Epoch 6/30
937/937 - 812s - loss: 1341.0549
Epoch 7/30
937/937 - 809s - loss: 1195.7684
Epoch 8/30
937/937 - 799s - loss: 936.3917
Epoch 9/30
937/937 - 789s - loss: 825.2145
Epoch 10/30
937/937 - 784s - loss: 624.6324
Epoch 11/30
937/937 - 784s - loss: 350.9970
Epoch 12/30
937/937 - 800s - loss: -1.4404e+02
Epoch 13/30
937/937 - 782s - loss: -2.9903e+02
Epoch 14/30
937/937 - 787s - loss: 95.7568
Epoch 15/30
937/937 - 834s - loss: -6.3827e+02
Epoch 16/30
937/937 - 810s - loss: -1.0666e+03
Epoch 17/30
937/937 - 790s - loss: -9.9776e+02
Epoch 18/30
937/937 - 781s - loss: -1.6060e+03
Epoch 19/30
937/937 - 773s - loss: -1.6864e+03
Epoch 20/30
937/937 - 767s - loss: -2.2050e+03
Epoch 21/30
937/937 - 764s - loss: -2.1323e+03
Epoch 22/30
937/937 - 769s - loss: -2.6915e+03
Epoch 23/30
937/937 - 765s - loss: -2.6915e+03
Epoch 24/30
937/937 - 756s - loss: -3.4922e+03
Epoch 25/30
937/937 - 752s - loss: -3.4671e+03
Epoch 26/30
937/937 - 753s - loss: -3.6979e+03
Epoch 27/30
937/937 - 751s - loss: -4.1032e+03
/cluster/shadow/.lsbatch/1663945232.232210891: line 8: 116083 Killed                  python main_contrastive.py --config ../config.yml
Sender: LSF System <lsfadmin@eu-g3-043>
Subject: Job 232226392: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-18> by user <goezsoy> in cluster <euler> at Fri Sep 23 22:50:47 2022
Job was executed on host(s) <4*eu-g3-043>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Fri Sep 23 22:51:03 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Fri Sep 23 22:51:03 2022
Terminated at Sat Sep 24 05:24:52 2022
Results reported at Sat Sep 24 05:24:52 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

TERM_MEMLIMIT: job killed after reaching LSF memory usage limit.
Exited with exit code 137.

Resource usage summary:

    CPU time :                                   25659.59 sec.
    Max Memory :                                 16384 MB
    Average Memory :                             12332.25 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               0.00 MB
    Max Swap :                                   1 MB
    Max Processes :                              3
    Max Threads :                                23
    Run time :                                   23629 sec.
    Turnaround time :                            23645 sec.

The output (if any) follows:

2022-09-23 22:51:07.820485: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-23 22:51:25.813539: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-23 22:51:25.818495: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-23 22:51:25.860804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:41:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-23 22:51:25.860849: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-23 22:51:25.891950: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-23 22:51:25.892030: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-23 22:51:25.930408: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-23 22:51:25.956374: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-23 22:51:26.048225: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-23 22:51:26.079353: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-23 22:51:26.082658: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-23 22:51:26.088860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-23 22:51:29.924313: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-23 22:51:29.925676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:41:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-23 22:51:29.925734: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-23 22:51:29.925781: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-23 22:51:29.925806: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-23 22:51:29.925829: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-23 22:51:29.925851: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-23 22:51:29.925873: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-23 22:51:29.925895: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-23 22:51:29.925917: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-23 22:51:29.927909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-23 22:51:29.931722: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-23 22:51:32.115885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-23 22:51:32.116166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-23 22:51:32.116174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-23 22:51:32.124831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:41:00.0, compute capability: 7.5)
2022-09-23 22:51:33.603375: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-23 22:51:38.475903: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-23 22:51:38.834600: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-23 22:51:39.363436: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-23 22:51:39.364685: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2249870000 Hz
cfg: {'experiment': {'name': '23_sep_layers6_s32_e256_latent50_constrastive_cont1', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 50, 'num_constrains': 6000, 'batch_size': 64, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 20, 'lrs': True}, 'model': {'latent_dim': 100, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/50
937/937 - 832s - loss: 40.5616 - cont_loss: 40.5616
Epoch 2/50
937/937 - 870s - loss: 39.7215 - cont_loss: 39.7215
Epoch 3/50
937/937 - 848s - loss: 39.5430 - cont_loss: 39.5430
Epoch 4/50
937/937 - 839s - loss: 39.4691 - cont_loss: 39.4691
Epoch 5/50
937/937 - 860s - loss: 39.3876 - cont_loss: 39.3876
Epoch 6/50
937/937 - 856s - loss: 39.3469 - cont_loss: 39.3469
Epoch 7/50
937/937 - 872s - loss: 39.2881 - cont_loss: 39.2881
Epoch 8/50
937/937 - 868s - loss: 39.2379 - cont_loss: 39.2379
Epoch 9/50
937/937 - 873s - loss: 39.2381 - cont_loss: 39.2381
Epoch 10/50
937/937 - 879s - loss: 39.2138 - cont_loss: 39.2138
Epoch 11/50
937/937 - 837s - loss: 39.1700 - cont_loss: 39.1700
Epoch 12/50
937/937 - 872s - loss: 39.1516 - cont_loss: 39.1516
Epoch 13/50
937/937 - 862s - loss: 39.1207 - cont_loss: 39.1207
Epoch 14/50
937/937 - 865s - loss: 39.1010 - cont_loss: 39.1010
Epoch 15/50
937/937 - 859s - loss: 39.0921 - cont_loss: 39.0921
Epoch 16/50
937/937 - 865s - loss: 39.0860 - cont_loss: 39.0860
Epoch 17/50
937/937 - 842s - loss: 39.0702 - cont_loss: 39.0702
Epoch 18/50
937/937 - 849s - loss: 39.0754 - cont_loss: 39.0754
Epoch 19/50
937/937 - 861s - loss: 39.0642 - cont_loss: 39.0642
Epoch 20/50
937/937 - 866s - loss: 39.0409 - cont_loss: 39.0409
Epoch 21/50
937/937 - 876s - loss: 39.0385 - cont_loss: 39.0385
Epoch 22/50
937/937 - 839s - loss: 39.0172 - cont_loss: 39.0172
Epoch 23/50
937/937 - 872s - loss: 39.0198 - cont_loss: 39.0198
Epoch 24/50
937/937 - 863s - loss: 39.0143 - cont_loss: 39.0143
Epoch 25/50
937/937 - 854s - loss: 39.0124 - cont_loss: 39.0124
Epoch 26/50
937/937 - 860s - loss: 39.0003 - cont_loss: 39.0003
Epoch 27/50
937/937 - 839s - loss: 38.9837 - cont_loss: 38.9837
/cluster/shadow/.lsbatch/1663966247.232226392: line 8: 78982 Killed                  python main_contrastive.py --config ../config.yml
Sender: LSF System <lsfadmin@eu-g2-12>
Subject: Job 232245966: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-47> by user <goezsoy> in cluster <euler> at Sat Sep 24 11:50:26 2022
Job was executed on host(s) <4*eu-g2-12>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Sat Sep 24 11:50:56 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Sat Sep 24 11:50:56 2022
Terminated at Sat Sep 24 12:19:05 2022
Results reported at Sat Sep 24 12:19:05 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 143.

Resource usage summary:

    CPU time :                                   2085.61 sec.
    Max Memory :                                 9646 MB
    Average Memory :                             8278.16 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               6738.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                31
    Run time :                                   1688 sec.
    Turnaround time :                            1719 sec.

The output (if any) follows:

2022-09-24 11:51:00.220928: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 11:51:18.065611: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-24 11:51:18.071918: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-24 11:51:18.127820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3e:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-24 11:51:18.127848: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 11:51:18.131700: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-24 11:51:18.131753: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-24 11:51:18.133490: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-24 11:51:18.134205: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-24 11:51:18.137960: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-24 11:51:18.139189: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-24 11:51:18.141682: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-24 11:51:18.145855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-24 11:51:22.552856: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-24 11:51:22.557245: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-24 11:51:22.558409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3e:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-24 11:51:22.558444: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 11:51:22.558484: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-24 11:51:22.558495: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-24 11:51:22.558506: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-24 11:51:22.558517: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-24 11:51:22.558527: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-24 11:51:22.558538: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-24 11:51:22.558549: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-24 11:51:22.559496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-24 11:51:22.564191: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 11:51:23.129154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-24 11:51:23.129190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-24 11:51:23.129197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-24 11:51:23.137183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:3e:00.0, compute capability: 7.5)
2022-09-24 11:51:25.013791: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-24 11:51:38.912157: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-24 11:51:40.860378: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-24 11:51:41.446028: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-24 11:51:41.448159: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
cfg: {'experiment': {'name': '24_sep_layers6_s32_e256_latent20_temp01_onlycont2', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 30, 'num_constrains': 6000, 'batch_size': 128, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 20, 'lrs': True}, 'model': {'latent_dim': 20, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/30
234/234 - 295s - loss: 23.9687 - cont_loss: 23.9687
Epoch 2/30
234/234 - 289s - loss: 12.0514 - cont_loss: 12.0514
Epoch 3/30
234/234 - 290s - loss: 9.1500 - cont_loss: 9.1500
Epoch 4/30
234/234 - 289s - loss: 7.9658 - cont_loss: 7.9658
Epoch 5/30
234/234 - 288s - loss: 7.7561 - cont_loss: 7.7561
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape_1:0", shape=(None,), dtype=int32), values=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape:0", shape=(None, None), dtype=float32), dense_shape=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
Epoch 6/30
Traceback (most recent call last):
  File "main_contrastive.py", line 124, in <module>
    run_experiment(cfg)
  File "main_contrastive.py", line 73, in run_experiment
    model.fit(train_generator, steps_per_epoch=int(len(Y)/(2*cfg['training']['batch_size'])), epochs=cfg['training']['epochs'], verbose=2)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 1100, in fit
    tmp_logs = self.train_function(iterator)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 828, in __call__
    result = self._call(*args, **kwds)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 855, in _call
    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/function.py", line 2942, in __call__
    return graph_function._call_flat(
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/function.py", line 1918, in _call_flat
    return self._build_call_outputs(self._inference_function.call(
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/function.py", line 555, in call
    outputs = execute.execute(
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/execute.py", line 59, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
KeyboardInterrupt
Terminated
Sender: LSF System <lsfadmin@eu-g3-019>
Subject: Job 232243015: <python main_contrastive.py --config ../config.yml> in cluster <euler> Done

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-47> by user <goezsoy> in cluster <euler> at Sat Sep 24 11:07:46 2022
Job was executed on host(s) <4*eu-g3-019>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Sat Sep 24 11:08:13 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Sat Sep 24 11:08:13 2022
Terminated at Sat Sep 24 13:00:19 2022
Results reported at Sat Sep 24 13:00:19 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   7842.81 sec.
    Max Memory :                                 14226 MB
    Average Memory :                             10839.66 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               2158.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                23
    Run time :                                   6726 sec.
    Turnaround time :                            6753 sec.

The output (if any) follows:

2022-09-24 11:08:16.852095: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 11:08:35.421632: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-24 11:08:35.426215: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-24 11:08:35.467324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:81:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-24 11:08:35.467370: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 11:08:35.569006: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-24 11:08:35.569090: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-24 11:08:35.610233: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-24 11:08:35.646419: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-24 11:08:35.744411: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-24 11:08:35.786609: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-24 11:08:35.792452: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-24 11:08:35.797353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-24 11:08:39.475230: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-24 11:08:39.476462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:81:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-24 11:08:39.476504: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 11:08:39.476545: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-24 11:08:39.476565: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-24 11:08:39.476584: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-24 11:08:39.476603: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-24 11:08:39.476621: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-24 11:08:39.476640: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-24 11:08:39.476659: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-24 11:08:39.478340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-24 11:08:39.482050: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 11:08:41.765479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-24 11:08:41.765734: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-24 11:08:41.765742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-24 11:08:41.775247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:81:00.0, compute capability: 7.5)
2022-09-24 11:08:43.267611: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-24 11:08:56.165273: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-24 11:08:57.799452: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-24 11:08:58.361880: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-24 11:08:58.363275: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2249800000 Hz
cfg: {'experiment': {'name': '24_sep_layers6_s32_e256_latent20_temp01_onlycont', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 30, 'num_constrains': 6000, 'batch_size': 128, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 20, 'lrs': True}, 'model': {'latent_dim': 20, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/30
234/234 - 224s - loss: 23.2432 - cont_loss: 23.2432
Epoch 2/30
234/234 - 221s - loss: 12.9598 - cont_loss: 12.9598
Epoch 3/30
234/234 - 222s - loss: 9.7639 - cont_loss: 9.7639
Epoch 4/30
234/234 - 222s - loss: 7.4333 - cont_loss: 7.4333
Epoch 5/30
234/234 - 223s - loss: 7.2901 - cont_loss: 7.2901
Epoch 6/30
234/234 - 224s - loss: 6.5062 - cont_loss: 6.5062
Epoch 7/30
234/234 - 215s - loss: 6.3095 - cont_loss: 6.3095
Epoch 8/30
234/234 - 214s - loss: 5.7735 - cont_loss: 5.7735
Epoch 9/30
234/234 - 216s - loss: 5.3114 - cont_loss: 5.3114
Epoch 10/30
234/234 - 214s - loss: 4.7767 - cont_loss: 4.7767
Epoch 11/30
234/234 - 215s - loss: 4.5613 - cont_loss: 4.5613
Epoch 12/30
234/234 - 220s - loss: 4.7969 - cont_loss: 4.7969
Epoch 13/30
234/234 - 221s - loss: 4.5610 - cont_loss: 4.5610
Epoch 14/30
234/234 - 222s - loss: 3.9562 - cont_loss: 3.9562
Epoch 15/30
234/234 - 222s - loss: 4.2376 - cont_loss: 4.2376
Epoch 16/30
234/234 - 224s - loss: 3.8379 - cont_loss: 3.8379
Epoch 17/30
234/234 - 225s - loss: 3.7941 - cont_loss: 3.7941
Epoch 18/30
234/234 - 224s - loss: 3.3862 - cont_loss: 3.3862
Epoch 19/30
234/234 - 224s - loss: 3.7569 - cont_loss: 3.7569
Epoch 20/30
234/234 - 225s - loss: 3.3921 - cont_loss: 3.3921
Epoch 21/30
234/234 - 224s - loss: 3.4181 - cont_loss: 3.4181
Epoch 22/30
234/234 - 225s - loss: 3.2837 - cont_loss: 3.2837
Epoch 23/30
234/234 - 225s - loss: 3.0854 - cont_loss: 3.0854
Epoch 24/30
234/234 - 225s - loss: 3.2751 - cont_loss: 3.2751
Epoch 25/30
234/234 - 225s - loss: 3.1545 - cont_loss: 3.1545
Epoch 26/30
234/234 - 225s - loss: 3.1814 - cont_loss: 3.1814
Epoch 27/30
234/234 - 225s - loss: 2.9080 - cont_loss: 2.9080
Epoch 28/30
234/234 - 224s - loss: 2.9845 - cont_loss: 2.9845
Epoch 29/30
234/234 - 225s - loss: 2.9073 - cont_loss: 2.9073
Epoch 30/30
234/234 - 226s - loss: 2.7488 - cont_loss: 2.7488
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape_1:0", shape=(None,), dtype=int32), values=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape:0", shape=(None, None), dtype=float32), dense_shape=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
WARNING:tensorflow:Saver is deprecated, please switch to tf.train.Checkpoint or tf.keras.Model.save_weights for training checkpoints. When executing eagerly variables do not necessarily have unique names, and so the variable.name-based lookups Saver performs are error-prone.
finished pretraining
Sender: LSF System <lsfadmin@eu-g2-12>
Subject: Job 232246417: <python main_contrastive.py --config ../config.yml> in cluster <euler> Done

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-47> by user <goezsoy> in cluster <euler> at Sat Sep 24 12:19:15 2022
Job was executed on host(s) <4*eu-g2-12>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Sat Sep 24 12:19:28 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Sat Sep 24 12:19:28 2022
Terminated at Sat Sep 24 13:08:24 2022
Results reported at Sat Sep 24 13:08:24 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   3698.66 sec.
    Max Memory :                                 7250 MB
    Average Memory :                             5644.54 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               9134.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                31
    Run time :                                   2935 sec.
    Turnaround time :                            2949 sec.

The output (if any) follows:

2022-09-24 12:19:30.570347: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 12:19:36.968307: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-24 12:19:36.969644: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-24 12:19:37.008286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3e:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-24 12:19:37.008317: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 12:19:37.012468: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-24 12:19:37.012525: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-24 12:19:37.014426: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-24 12:19:37.015326: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-24 12:19:37.019318: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-24 12:19:37.020429: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-24 12:19:37.020867: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-24 12:19:37.022273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-24 12:19:38.929125: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-24 12:19:38.929815: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-24 12:19:38.930519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3e:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-24 12:19:38.930551: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 12:19:38.930588: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-24 12:19:38.930599: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-24 12:19:38.930610: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-24 12:19:38.930620: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-24 12:19:38.930631: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-24 12:19:38.930640: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-24 12:19:38.930651: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-24 12:19:38.931598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-24 12:19:38.931622: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 12:19:39.497860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-24 12:19:39.497895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-24 12:19:39.497902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-24 12:19:39.499694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:3e:00.0, compute capability: 7.5)
2022-09-24 12:19:41.134292: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-24 12:19:43.127214: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-24 12:19:43.549946: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-24 12:19:44.024372: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-24 12:19:44.025815: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
cfg: {'experiment': {'name': '24_sep_layers6_s32_e256_latent20_temp01_onlycont2', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 10, 'num_constrains': 6000, 'batch_size': 128, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 20, 'lrs': True}, 'model': {'latent_dim': 20, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/10
234/234 - 295s - loss: 22.5398 - cont_loss: 22.5398
Epoch 2/10
234/234 - 290s - loss: 11.7764 - cont_loss: 11.7764
Epoch 3/10
234/234 - 290s - loss: 9.6391 - cont_loss: 9.6391
Epoch 4/10
234/234 - 290s - loss: 8.7194 - cont_loss: 8.7194
Epoch 5/10
234/234 - 290s - loss: 6.9639 - cont_loss: 6.9639
Epoch 6/10
234/234 - 289s - loss: 6.1964 - cont_loss: 6.1964
Epoch 7/10
234/234 - 289s - loss: 5.8481 - cont_loss: 5.8481
Epoch 8/10
234/234 - 289s - loss: 5.5735 - cont_loss: 5.5735
Epoch 9/10
234/234 - 289s - loss: 5.6369 - cont_loss: 5.6369
Epoch 10/10
234/234 - 289s - loss: 4.9580 - cont_loss: 4.9580
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape_1:0", shape=(None,), dtype=int32), values=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape:0", shape=(None, None), dtype=float32), dense_shape=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
WARNING:tensorflow:Saver is deprecated, please switch to tf.train.Checkpoint or tf.keras.Model.save_weights for training checkpoints. When executing eagerly variables do not necessarily have unique names, and so the variable.name-based lookups Saver performs are error-prone.
finished pretraining
Sender: LSF System <lsfadmin@eu-g2-15>
Subject: Job 232240423: <python main_contrastive.py --config ../config.yml> in cluster <euler> Done

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-47> by user <goezsoy> in cluster <euler> at Sat Sep 24 09:46:33 2022
Job was executed on host(s) <4*eu-g2-15>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Sat Sep 24 09:46:39 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Sat Sep 24 09:46:39 2022
Terminated at Sat Sep 24 15:04:36 2022
Results reported at Sat Sep 24 15:04:36 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   22126.94 sec.
    Max Memory :                                 13744 MB
    Average Memory :                             10073.32 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               2640.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                31
    Run time :                                   19077 sec.
    Turnaround time :                            19083 sec.

The output (if any) follows:

2022-09-24 09:46:42.917191: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 09:46:54.208550: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-24 09:46:54.218600: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-24 09:46:54.279725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:da:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-24 09:46:54.279773: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 09:46:54.285232: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-24 09:46:54.285338: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-24 09:46:54.287550: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-24 09:46:54.288466: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-24 09:46:54.293001: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-24 09:46:54.294441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-24 09:46:54.297113: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-24 09:46:54.305058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-24 09:46:58.828208: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-24 09:46:58.833657: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-24 09:46:58.834439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:da:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-24 09:46:58.834475: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 09:46:58.834515: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-24 09:46:58.834527: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-24 09:46:58.834538: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-24 09:46:58.834549: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-24 09:46:58.834560: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-24 09:46:58.834571: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-24 09:46:58.834582: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-24 09:46:58.835731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-24 09:46:58.840381: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 09:47:00.816448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-24 09:47:00.816498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-24 09:47:00.816511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-24 09:47:00.819036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:da:00.0, compute capability: 7.5)
2022-09-24 09:47:02.778135: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-24 09:47:16.756319: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-24 09:47:18.696100: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-24 09:47:19.124953: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-24 09:47:19.127189: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
cfg: {'experiment': {'name': '24_sep_layers6_s32_e256_latent20_onlycont', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 30, 'num_constrains': 6000, 'batch_size': 64, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 20, 'lrs': True}, 'model': {'latent_dim': 20, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/30
468/468 - 639s - loss: 40.4282 - cont_loss: 40.4282
Epoch 2/30
468/468 - 630s - loss: 39.8367 - cont_loss: 39.8367
Epoch 3/30
468/468 - 638s - loss: 39.7092 - cont_loss: 39.7092
Epoch 4/30
468/468 - 635s - loss: 39.5933 - cont_loss: 39.5933
Epoch 5/30
468/468 - 636s - loss: 39.5633 - cont_loss: 39.5633
Epoch 6/30
468/468 - 633s - loss: 39.5045 - cont_loss: 39.5045
Epoch 7/30
468/468 - 630s - loss: 39.4276 - cont_loss: 39.4276
Epoch 8/30
468/468 - 632s - loss: 39.3828 - cont_loss: 39.3828
Epoch 9/30
468/468 - 630s - loss: 39.3917 - cont_loss: 39.3917
Epoch 10/30
468/468 - 631s - loss: 39.3032 - cont_loss: 39.3032
Epoch 11/30
468/468 - 629s - loss: 39.2575 - cont_loss: 39.2575
Epoch 12/30
468/468 - 633s - loss: 39.2523 - cont_loss: 39.2523
Epoch 13/30
468/468 - 635s - loss: 39.2502 - cont_loss: 39.2502
Epoch 14/30
468/468 - 637s - loss: 39.2440 - cont_loss: 39.2440
Epoch 15/30
468/468 - 635s - loss: 39.1690 - cont_loss: 39.1690
Epoch 16/30
468/468 - 635s - loss: 39.1689 - cont_loss: 39.1689
Epoch 17/30
468/468 - 632s - loss: 39.1540 - cont_loss: 39.1540
Epoch 18/30
468/468 - 633s - loss: 39.1504 - cont_loss: 39.1504
Epoch 19/30
468/468 - 632s - loss: 39.1380 - cont_loss: 39.1380
Epoch 20/30
468/468 - 635s - loss: 39.1467 - cont_loss: 39.1467
Epoch 21/30
468/468 - 634s - loss: 39.1341 - cont_loss: 39.1341
Epoch 22/30
468/468 - 638s - loss: 39.1089 - cont_loss: 39.1089
Epoch 23/30
468/468 - 638s - loss: 39.1073 - cont_loss: 39.1073
Epoch 24/30
468/468 - 636s - loss: 39.0905 - cont_loss: 39.0905
Epoch 25/30
468/468 - 635s - loss: 39.0985 - cont_loss: 39.0985
Epoch 26/30
468/468 - 633s - loss: 39.0734 - cont_loss: 39.0734
Epoch 27/30
468/468 - 638s - loss: 39.0831 - cont_loss: 39.0831
Epoch 28/30
468/468 - 631s - loss: 39.0748 - cont_loss: 39.0748
Epoch 29/30
468/468 - 629s - loss: 39.0688 - cont_loss: 39.0688
Epoch 30/30
468/468 - 634s - loss: 39.0555 - cont_loss: 39.0555
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape_1:0", shape=(None,), dtype=int32), values=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape:0", shape=(None, None), dtype=float32), dense_shape=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
WARNING:tensorflow:Saver is deprecated, please switch to tf.train.Checkpoint or tf.keras.Model.save_weights for training checkpoints. When executing eagerly variables do not necessarily have unique names, and so the variable.name-based lookups Saver performs are error-prone.
finished pretraining
Sender: LSF System <lsfadmin@eu-g3-032>
Subject: Job 232274759: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-47> by user <goezsoy> in cluster <euler> at Sat Sep 24 16:27:00 2022
Job was executed on host(s) <4*eu-g3-032>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Sat Sep 24 16:27:13 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Sat Sep 24 16:27:13 2022
Terminated at Sat Sep 24 16:27:21 2022
Results reported at Sat Sep 24 16:27:21 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   2.99 sec.
    Max Memory :                                 393 MB
    Average Memory :                             353.00 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               15991.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                4
    Run time :                                   8 sec.
    Turnaround time :                            21 sec.

The output (if any) follows:

2022-09-24 16:27:16.810845: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Traceback (most recent call last):
  File "<frozen importlib._bootstrap_external>", line 93, in _path_is_mode_type
  File "<frozen importlib._bootstrap_external>", line 87, in _path_stat
FileNotFoundError: [Errno 2] No such file or directory: '/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/_api/v2/compat/v1/random/__init__.abi3.so'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "main_contrastive.py", line 12, in <module>
    import tensorflow as tf
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/__init__.py", line 55, in <module>
    from ._api.v2 import compat
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/_api/v2/compat/__init__.py", line 39, in <module>
    from . import v1
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/_api/v2/compat/v1/__init__.py", line 34, in <module>
    from . import compat
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py", line 39, in <module>
    from . import v1
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/_api/v2/compat/v1/compat/v1/__init__.py", line 67, in <module>
    from tensorflow._api.v2.compat.v1 import random
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 914, in _find_spec
  File "<frozen importlib._bootstrap_external>", line 1342, in find_spec
  File "<frozen importlib._bootstrap_external>", line 1314, in _get_spec
  File "<frozen importlib._bootstrap_external>", line 1458, in find_spec
  File "<frozen importlib._bootstrap_external>", line 101, in _path_isfile
  File "<frozen importlib._bootstrap_external>", line 93, in _path_is_mode_type
KeyboardInterrupt
Sender: LSF System <lsfadmin@eu-g3-035>
Subject: Job 232280326: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-47> by user <goezsoy> in cluster <euler> at Sat Sep 24 17:00:26 2022
Job was executed on host(s) <4*eu-g3-035>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Sat Sep 24 17:00:41 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Sat Sep 24 17:00:41 2022
Terminated at Sat Sep 24 17:00:49 2022
Results reported at Sat Sep 24 17:00:49 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   4.24 sec.
    Max Memory :                                 188 MB
    Average Memory :                             130.00 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               16196.00 MB
    Max Swap :                                   1 MB
    Max Processes :                              3
    Max Threads :                                4
    Run time :                                   7 sec.
    Turnaround time :                            23 sec.

The output (if any) follows:

2022-09-24 17:00:43.526680: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
Traceback (most recent call last):
  File "main_contrastive.py", line 21, in <module>
    import utils
  File "/cluster/home/goezsoy/constrastive-DC-GMM/src/utils.py", line 24, in <module>
    from model import DCGMM
  File "/cluster/home/goezsoy/constrastive-DC-GMM/src/model.py", line 830
    VGGDeConvBlockAUX(256, 3),VGGDeConvBlock(256, 4),
    ^
SyntaxError: invalid syntax
Sender: LSF System <lsfadmin@eu-g3-035>
Subject: Job 232252279: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-47> by user <goezsoy> in cluster <euler> at Sat Sep 24 14:36:33 2022
Job was executed on host(s) <4*eu-g3-035>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Sat Sep 24 14:37:02 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Sat Sep 24 14:37:02 2022
Terminated at Sat Sep 24 17:41:59 2022
Results reported at Sat Sep 24 17:41:59 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   13024.59 sec.
    Max Memory :                                 16384 MB
    Average Memory :                             12631.03 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               0.00 MB
    Max Swap :                                   1 MB
    Max Processes :                              4
    Max Threads :                                24
    Run time :                                   11096 sec.
    Turnaround time :                            11126 sec.

The output (if any) follows:

2022-09-24 14:37:05.355671: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 14:37:23.762535: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-24 14:37:23.767885: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-24 14:37:23.812056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:c2:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.62GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-24 14:37:23.812106: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 14:37:23.913238: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-24 14:37:23.913342: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-24 14:37:23.957556: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-24 14:37:23.991952: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-24 14:37:24.090680: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-24 14:37:24.133433: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-24 14:37:24.139850: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-24 14:37:24.145171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-24 14:37:27.906967: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-24 14:37:27.908275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:c2:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.62GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-24 14:37:27.908318: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 14:37:27.908360: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-24 14:37:27.908381: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-24 14:37:27.908400: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-24 14:37:27.908419: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-24 14:37:27.908437: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-24 14:37:27.908455: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-24 14:37:27.908474: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-24 14:37:27.910289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-24 14:37:27.914043: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 14:37:29.787496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-24 14:37:29.787585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-24 14:37:29.787595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-24 14:37:29.797403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:c2:00.0, compute capability: 7.5)
2022-09-24 14:37:31.265533: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-24 14:37:44.103382: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-24 14:37:45.719896: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-24 14:37:46.271911: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-24 14:37:46.273299: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2249855000 Hz
cfg: {'experiment': {'name': '24_sep_layers6_s32_e256_latent128_temp01_onlycont3', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 55, 'num_constrains': 6000, 'batch_size': 128, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 30, 'lrs': True}, 'model': {'latent_dim': 128, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/55
234/234 - 208s - loss: 19.3005 - cont_loss: 19.3005
Epoch 2/55
234/234 - 200s - loss: 10.5562 - cont_loss: 10.5562
Epoch 3/55
234/234 - 203s - loss: 6.9519 - cont_loss: 6.9519
Epoch 4/55
234/234 - 201s - loss: 5.8913 - cont_loss: 5.8913
Epoch 5/55
234/234 - 204s - loss: 5.4202 - cont_loss: 5.4202
Epoch 6/55
234/234 - 201s - loss: 4.1943 - cont_loss: 4.1943
Epoch 7/55
234/234 - 201s - loss: 3.9874 - cont_loss: 3.9874
Epoch 8/55
234/234 - 201s - loss: 3.7039 - cont_loss: 3.7039
Epoch 9/55
234/234 - 200s - loss: 3.1904 - cont_loss: 3.1904
Epoch 10/55
234/234 - 204s - loss: 3.2926 - cont_loss: 3.2926
Epoch 11/55
234/234 - 198s - loss: 2.7278 - cont_loss: 2.7278
Epoch 12/55
234/234 - 200s - loss: 2.6689 - cont_loss: 2.6689
Epoch 13/55
234/234 - 201s - loss: 2.7040 - cont_loss: 2.7040
Epoch 14/55
234/234 - 200s - loss: 2.4140 - cont_loss: 2.4140
Epoch 15/55
234/234 - 199s - loss: 2.2591 - cont_loss: 2.2591
Epoch 16/55
234/234 - 199s - loss: 2.4692 - cont_loss: 2.4692
Epoch 17/55
234/234 - 200s - loss: 2.1169 - cont_loss: 2.1169
Epoch 18/55
234/234 - 198s - loss: 1.9851 - cont_loss: 1.9851
Epoch 19/55
234/234 - 203s - loss: 2.1354 - cont_loss: 2.1354
Epoch 20/55
234/234 - 197s - loss: 1.9776 - cont_loss: 1.9776
Epoch 21/55
234/234 - 201s - loss: 2.0834 - cont_loss: 2.0834
Epoch 22/55
234/234 - 199s - loss: 2.0176 - cont_loss: 2.0176
Epoch 23/55
234/234 - 199s - loss: 1.7095 - cont_loss: 1.7095
Epoch 24/55
234/234 - 198s - loss: 1.6204 - cont_loss: 1.6204
Epoch 25/55
234/234 - 198s - loss: 1.4755 - cont_loss: 1.4755
Epoch 26/55
234/234 - 198s - loss: 1.8052 - cont_loss: 1.8052
Epoch 27/55
234/234 - 197s - loss: 1.4745 - cont_loss: 1.4745
Epoch 28/55
234/234 - 202s - loss: 1.6483 - cont_loss: 1.6483
Epoch 29/55
234/234 - 198s - loss: 1.6537 - cont_loss: 1.6537
Epoch 30/55
234/234 - 198s - loss: 1.1977 - cont_loss: 1.1977
Epoch 31/55
234/234 - 197s - loss: 1.4076 - cont_loss: 1.4076
Epoch 32/55
234/234 - 199s - loss: 1.5682 - cont_loss: 1.5682
Epoch 33/55
234/234 - 199s - loss: 1.3908 - cont_loss: 1.3908
Epoch 34/55
234/234 - 197s - loss: 1.2767 - cont_loss: 1.2767
Epoch 35/55
234/234 - 207s - loss: 1.3147 - cont_loss: 1.3147
Epoch 36/55
234/234 - 201s - loss: 1.2508 - cont_loss: 1.2508
Epoch 37/55
234/234 - 203s - loss: 1.1489 - cont_loss: 1.1489
Epoch 38/55
234/234 - 200s - loss: 1.2035 - cont_loss: 1.2035
Epoch 39/55
234/234 - 199s - loss: 1.4231 - cont_loss: 1.4231
Epoch 40/55
234/234 - 199s - loss: 1.2460 - cont_loss: 1.2460
Epoch 41/55
234/234 - 199s - loss: 1.2156 - cont_loss: 1.2156
Epoch 42/55
234/234 - 195s - loss: 1.1130 - cont_loss: 1.1130
Epoch 43/55
234/234 - 206s - loss: 1.1207 - cont_loss: 1.1207
Epoch 44/55
234/234 - 197s - loss: 1.1149 - cont_loss: 1.1149
Epoch 45/55
234/234 - 202s - loss: 1.2241 - cont_loss: 1.2241
Epoch 46/55
234/234 - 200s - loss: 1.2403 - cont_loss: 1.2403
Epoch 47/55
234/234 - 201s - loss: 1.0852 - cont_loss: 1.0852
Epoch 48/55
234/234 - 197s - loss: 1.0342 - cont_loss: 1.0342
Epoch 49/55
234/234 - 200s - loss: 1.0549 - cont_loss: 1.0549
Epoch 50/55
234/234 - 203s - loss: 1.1445 - cont_loss: 1.1445
Epoch 51/55
234/234 - 203s - loss: 0.9373 - cont_loss: 0.9373
Epoch 52/55
234/234 - 205s - loss: 0.9801 - cont_loss: 0.9801
Epoch 53/55
234/234 - 206s - loss: 0.9177 - cont_loss: 0.9177
Epoch 54/55
234/234 - 205s - loss: 1.0479 - cont_loss: 1.0479
Epoch 55/55
234/234 - 210s - loss: 1.0800 - cont_loss: 1.0800
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape_1:0", shape=(None,), dtype=int32), values=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape:0", shape=(None, None), dtype=float32), dense_shape=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
Traceback (most recent call last):
  File "main_contrastive.py", line 131, in <module>
    run_experiment(cfg)
  File "main_contrastive.py", line 99, in run_experiment
    plt.savefig(plt_save_path)
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/matplotlib/pyplot.py", line 979, in savefig
    res = fig.savefig(*args, **kwargs)
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/matplotlib/figure.py", line 3046, in savefig
    self.canvas.print_figure(fname, **kwargs)
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/matplotlib/backend_bases.py", line 2319, in print_figure
    result = print_method(
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/matplotlib/backend_bases.py", line 1648, in wrapper
    return func(*args, **kwargs)
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/matplotlib/_api/deprecation.py", line 415, in wrapper
    return func(*inner_args, **inner_kwargs)
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py", line 541, in print_png
    mpl.image.imsave(
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/matplotlib/image.py", line 1675, in imsave
    image.save(fname, **pil_kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/PIL/Image.py", line 2232, in save
    fp = builtins.open(filename, "w+b")
FileNotFoundError: [Errno 2] No such file or directory: '../logs/CIFAR10/24_sep_layers6_s32_e256_latent128_temp01_onlycont3/embedding_space.png'
Sender: LSF System <lsfadmin@eu-g3-032>
Subject: Job 232274889: <python main_contrastive.py --config ../config.yml> in cluster <euler> Done

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-47> by user <goezsoy> in cluster <euler> at Sat Sep 24 16:27:37 2022
Job was executed on host(s) <4*eu-g3-032>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Sat Sep 24 16:27:43 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Sat Sep 24 16:27:43 2022
Terminated at Sat Sep 24 18:15:57 2022
Results reported at Sat Sep 24 18:15:57 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   7383.62 sec.
    Max Memory :                                 12716 MB
    Average Memory :                             9415.12 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               3668.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                25
    Run time :                                   6494 sec.
    Turnaround time :                            6500 sec.

The output (if any) follows:

2022-09-24 16:27:44.547191: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 16:27:51.778428: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-24 16:27:51.783821: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-24 16:27:51.828561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:c2:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.62GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-24 16:27:51.828611: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 16:27:51.844031: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-24 16:27:51.844142: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-24 16:27:51.850088: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-24 16:27:51.855090: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-24 16:27:51.867583: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-24 16:27:51.873345: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-24 16:27:51.877435: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-24 16:27:51.881167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-24 16:27:55.828695: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-24 16:27:55.833653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:c2:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.62GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-24 16:27:55.833763: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 16:27:55.833880: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-24 16:27:55.833903: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-24 16:27:55.833924: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-24 16:27:55.833943: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-24 16:27:55.833961: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-24 16:27:55.833979: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-24 16:27:55.833998: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-24 16:27:55.835864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-24 16:27:55.839647: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 16:27:58.043213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-24 16:27:58.043309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-24 16:27:58.043324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-24 16:27:58.051381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:c2:00.0, compute capability: 7.5)
2022-09-24 16:27:59.608020: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-24 16:28:12.605240: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-24 16:28:14.230628: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-24 16:28:14.777757: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-24 16:28:14.779139: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2250030000 Hz
cfg: {'experiment': {'name': '24_sep_layers6_s32_e256_latent128_temp005_onlycont', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 30, 'num_constrains': 6000, 'batch_size': 128, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 30, 'lrs': True}, 'model': {'latent_dim': 128, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/30
234/234 - 214s - loss: 20.7804 - cont_loss: 20.7804
Epoch 2/30
234/234 - 211s - loss: 7.6969 - cont_loss: 7.6969
Epoch 3/30
234/234 - 213s - loss: 6.2135 - cont_loss: 6.2135
Epoch 4/30
234/234 - 217s - loss: 4.9183 - cont_loss: 4.9183
Epoch 5/30
234/234 - 214s - loss: 4.3507 - cont_loss: 4.3507
Epoch 6/30
234/234 - 214s - loss: 3.2366 - cont_loss: 3.2366
Epoch 7/30
234/234 - 212s - loss: 2.9842 - cont_loss: 2.9842
Epoch 8/30
234/234 - 215s - loss: 2.3168 - cont_loss: 2.3168
Epoch 9/30
234/234 - 212s - loss: 1.7398 - cont_loss: 1.7398
Epoch 10/30
234/234 - 218s - loss: 1.6903 - cont_loss: 1.6903
Epoch 11/30
234/234 - 220s - loss: 1.8431 - cont_loss: 1.8431
Epoch 12/30
234/234 - 216s - loss: 1.7407 - cont_loss: 1.7407
Epoch 13/30
234/234 - 216s - loss: 1.2122 - cont_loss: 1.2122
Epoch 14/30
234/234 - 215s - loss: 1.4147 - cont_loss: 1.4147
Epoch 15/30
234/234 - 213s - loss: 1.2917 - cont_loss: 1.2917
Epoch 16/30
234/234 - 216s - loss: 1.3179 - cont_loss: 1.3179
Epoch 17/30
234/234 - 217s - loss: 1.1250 - cont_loss: 1.1250
Epoch 18/30
234/234 - 217s - loss: 1.2757 - cont_loss: 1.2757
Epoch 19/30
234/234 - 221s - loss: 1.1075 - cont_loss: 1.1075
Epoch 20/30
234/234 - 217s - loss: 1.1807 - cont_loss: 1.1807
Epoch 21/30
234/234 - 220s - loss: 0.6886 - cont_loss: 0.6886
Epoch 22/30
234/234 - 212s - loss: 0.6840 - cont_loss: 0.6840
Epoch 23/30
234/234 - 214s - loss: 0.7100 - cont_loss: 0.7100
Epoch 24/30
234/234 - 215s - loss: 1.1417 - cont_loss: 1.1417
Epoch 25/30
234/234 - 213s - loss: 0.7859 - cont_loss: 0.7859
Epoch 26/30
234/234 - 209s - loss: 0.9355 - cont_loss: 0.9355
Epoch 27/30
234/234 - 212s - loss: 0.7299 - cont_loss: 0.7299
Epoch 28/30
234/234 - 210s - loss: 0.7198 - cont_loss: 0.7198
Epoch 29/30
234/234 - 215s - loss: 0.6130 - cont_loss: 0.6130
Epoch 30/30
234/234 - 219s - loss: 0.6734 - cont_loss: 0.6734
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape_1:0", shape=(None,), dtype=int32), values=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape:0", shape=(None, None), dtype=float32), dense_shape=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
WARNING:tensorflow:Saver is deprecated, please switch to tf.train.Checkpoint or tf.keras.Model.save_weights for training checkpoints. When executing eagerly variables do not necessarily have unique names, and so the variable.name-based lookups Saver performs are error-prone.
finished pretraining
Sender: LSF System <lsfadmin@eu-g3-024>
Subject: Job 232314206: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-15> by user <goezsoy> in cluster <euler> at Sat Sep 24 21:31:23 2022
Job was executed on host(s) <4*eu-g3-024>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Sat Sep 24 21:31:44 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Sat Sep 24 21:31:44 2022
Terminated at Sat Sep 24 21:31:58 2022
Results reported at Sat Sep 24 21:31:58 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   5.01 sec.
    Max Memory :                                 624 MB
    Average Memory :                             273.00 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               15760.00 MB
    Max Swap :                                   6 MB
    Max Processes :                              3
    Max Threads :                                4
    Run time :                                   13 sec.
    Turnaround time :                            35 sec.

The output (if any) follows:

2022-09-24 21:31:47.948977: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
Traceback (most recent call last):
  File "main_contrastive.py", line 21, in <module>
    import utils
  File "/cluster/home/goezsoy/constrastive-DC-GMM/src/utils.py", line 24, in <module>
    from model import DCGMM
  File "/cluster/home/goezsoy/constrastive-DC-GMM/src/model.py", line 830
    VGGDeConvBlockAUX(256, 3),VGGDeConvBlock(256, 4),
    ^
SyntaxError: invalid syntax
Sender: LSF System <lsfadmin@eu-g2-19>
Subject: Job 232314236: <python main_contrastive.py --config ../config.yml> in cluster <euler> Done

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-15> by user <goezsoy> in cluster <euler> at Sat Sep 24 21:33:21 2022
Job was executed on host(s) <4*eu-g2-19>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Sat Sep 24 21:33:45 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Sat Sep 24 21:33:45 2022
Terminated at Sat Sep 24 22:00:42 2022
Results reported at Sat Sep 24 22:00:42 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   2180.35 sec.
    Max Memory :                                 11450 MB
    Average Memory :                             9105.93 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               4934.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                33
    Run time :                                   1617 sec.
    Turnaround time :                            1641 sec.

The output (if any) follows:

2022-09-24 21:33:47.911143: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 21:34:06.025374: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-24 21:34:06.027140: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-24 21:34:06.061288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:1a:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-24 21:34:06.061317: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 21:34:06.065297: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-24 21:34:06.065365: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-24 21:34:06.067152: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-24 21:34:06.067919: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-24 21:34:06.071650: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-24 21:34:06.072901: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-24 21:34:06.075576: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-24 21:34:06.079484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-24 21:34:10.589142: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-24 21:34:10.590056: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-24 21:34:10.591159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:1a:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-24 21:34:10.591212: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 21:34:10.591268: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-24 21:34:10.591293: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-24 21:34:10.591316: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-24 21:34:10.591339: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-24 21:34:10.591362: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-24 21:34:10.591385: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-24 21:34:10.591409: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-24 21:34:10.592991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-24 21:34:10.596979: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 21:34:11.169241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-24 21:34:11.169279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-24 21:34:11.169286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-24 21:34:11.176777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1a:00.0, compute capability: 7.5)
2022-09-24 21:34:13.190473: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-24 21:34:27.311632: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-24 21:34:29.254976: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-24 21:34:30.122056: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-24 21:34:30.123719: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
cfg: {'experiment': {'name': '24_sep_layers8_s32_e256_latent128_temp01_onlycont', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 10, 'num_constrains': 6000, 'batch_size': 256, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 30, 'lrs': True}, 'model': {'latent_dim': 128, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/10
117/117 - 163s - loss: 36.8224 - cont_loss: 36.8224
Epoch 2/10
117/117 - 154s - loss: 22.8131 - cont_loss: 22.8131
Epoch 3/10
117/117 - 156s - loss: 16.4755 - cont_loss: 16.4755
Epoch 4/10
117/117 - 155s - loss: 10.6569 - cont_loss: 10.6569
Epoch 5/10
117/117 - 156s - loss: 11.7518 - cont_loss: 11.7518
Epoch 6/10
117/117 - 154s - loss: 9.9894 - cont_loss: 9.9894
Epoch 7/10
117/117 - 153s - loss: 10.5457 - cont_loss: 10.5457
Epoch 8/10
117/117 - 154s - loss: 7.2203 - cont_loss: 7.2203
Epoch 9/10
117/117 - 152s - loss: 7.4754 - cont_loss: 7.4754
Epoch 10/10
117/117 - 154s - loss: 6.8045 - cont_loss: 6.8045
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape_1:0", shape=(None,), dtype=int32), values=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape:0", shape=(None, None), dtype=float32), dense_shape=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
WARNING:tensorflow:Saver is deprecated, please switch to tf.train.Checkpoint or tf.keras.Model.save_weights for training checkpoints. When executing eagerly variables do not necessarily have unique names, and so the variable.name-based lookups Saver performs are error-prone.
finished pretraining
Sender: LSF System <lsfadmin@eu-g3-040>
Subject: Job 232315904: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-15> by user <goezsoy> in cluster <euler> at Sat Sep 24 22:41:28 2022
Job was executed on host(s) <4*eu-g3-040>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Sat Sep 24 22:41:51 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Sat Sep 24 22:41:51 2022
Terminated at Sat Sep 24 22:50:36 2022
Results reported at Sat Sep 24 22:50:36 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 143.

Resource usage summary:

    CPU time :                                   622.32 sec.
    Max Memory :                                 10146 MB
    Average Memory :                             8290.05 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               6238.00 MB
    Max Swap :                                   5 MB
    Max Processes :                              3
    Max Threads :                                23
    Run time :                                   524 sec.
    Turnaround time :                            548 sec.

The output (if any) follows:

2022-09-24 22:41:54.766534: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 22:42:10.605176: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-24 22:42:10.615210: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-24 22:42:10.655268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:21:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.62GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-24 22:42:10.655314: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 22:42:10.737851: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-24 22:42:10.737937: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-24 22:42:10.773248: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-24 22:42:10.796390: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-24 22:42:10.868662: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-24 22:42:10.883291: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-24 22:42:10.889361: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-24 22:42:10.893716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-24 22:42:14.746907: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-24 22:42:14.748780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:21:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.62GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-24 22:42:14.748833: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 22:42:14.748884: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-24 22:42:14.748909: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-24 22:42:14.748932: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-24 22:42:14.748955: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-24 22:42:14.748977: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-24 22:42:14.748999: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-24 22:42:14.749022: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-24 22:42:14.750964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-24 22:42:14.757661: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 22:42:16.969755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-24 22:42:16.969821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-24 22:42:16.969835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-24 22:42:16.983203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:21:00.0, compute capability: 7.5)
2022-09-24 22:42:18.613232: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-24 22:42:31.828477: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-24 22:42:33.518846: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-24 22:42:34.361485: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-24 22:42:34.363529: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2249865000 Hz
cfg: {'experiment': {'name': '24_sep_layers10_s32_e256_latent128_temp01_onlycont', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 65, 'num_constrains': 6000, 'batch_size': 256, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 30, 'lrs': True}, 'model': {'latent_dim': 128, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/65
117/117 - 120s - loss: 46.6103 - cont_loss: 46.6103
Epoch 2/65
117/117 - 115s - loss: 33.9614 - cont_loss: 33.9614
Epoch 3/65
117/117 - 115s - loss: 27.2337 - cont_loss: 27.2337
Epoch 4/65
117/117 - 120s - loss: 25.2015 - cont_loss: 25.2015
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape_1:0", shape=(None,), dtype=int32), values=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape:0", shape=(None, None), dtype=float32), dense_shape=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
Epoch 5/65
Traceback (most recent call last):
  File "main_contrastive.py", line 131, in <module>
    parser = argparse.ArgumentParser()
  File "main_contrastive.py", line 80, in run_experiment
    
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 1100, in fit
    tmp_logs = self.train_function(iterator)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 828, in __call__
    result = self._call(*args, **kwds)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 855, in _call
    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/function.py", line 2942, in __call__
    return graph_function._call_flat(
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/function.py", line 1918, in _call_flat
    return self._build_call_outputs(self._inference_function.call(
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/function.py", line 555, in call
    outputs = execute.execute(
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/execute.py", line 59, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
KeyboardInterrupt
Terminated
Sender: LSF System <lsfadmin@eu-g2-19>
Subject: Job 232316258: <python main_contrastive.py --config ../config.yml> in cluster <euler> Done

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-15> by user <goezsoy> in cluster <euler> at Sat Sep 24 22:51:17 2022
Job was executed on host(s) <4*eu-g2-19>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Sat Sep 24 22:51:52 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Sat Sep 24 22:51:52 2022
Terminated at Sat Sep 24 23:08:59 2022
Results reported at Sat Sep 24 23:08:59 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   1111.02 sec.
    Max Memory :                                 9349 MB
    Average Memory :                             8350.71 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               7035.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                31
    Run time :                                   1026 sec.
    Turnaround time :                            1062 sec.

The output (if any) follows:

2022-09-24 22:51:56.083485: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 22:52:13.011050: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-24 22:52:13.012752: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-24 22:52:13.051013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:1a:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-24 22:52:13.051051: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 22:52:13.054735: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-24 22:52:13.054824: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-24 22:52:13.056448: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-24 22:52:13.057092: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-24 22:52:13.060513: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-24 22:52:13.061507: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-24 22:52:13.064020: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-24 22:52:13.066365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-24 22:52:17.535535: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-24 22:52:17.536322: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-24 22:52:17.537067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:1a:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-24 22:52:17.537101: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 22:52:17.537156: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-24 22:52:17.537168: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-24 22:52:17.537178: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-24 22:52:17.537188: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-24 22:52:17.537199: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-24 22:52:17.537208: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-24 22:52:17.537218: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-24 22:52:17.538208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-24 22:52:17.545415: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 22:52:18.116015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-24 22:52:18.116050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-24 22:52:18.116057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-24 22:52:18.123913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1a:00.0, compute capability: 7.5)
2022-09-24 22:52:20.419270: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-24 22:52:48.273834: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-24 22:52:50.175252: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-24 22:52:51.169942: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-24 22:52:51.171590: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
cfg: {'experiment': {'name': '24_sep_layers10_s32_e256_latent128_temp01_onlycont', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 2, 'num_constrains': 6000, 'batch_size': 256, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 30, 'lrs': True}, 'model': {'latent_dim': 128, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/2
117/117 - 160s - loss: 45.7926 - cont_loss: 45.7926
Epoch 2/2
117/117 - 152s - loss: 34.3529 - cont_loss: 34.3529
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape_1:0", shape=(None,), dtype=int32), values=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape:0", shape=(None, None), dtype=float32), dense_shape=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
WARNING:tensorflow:Saver is deprecated, please switch to tf.train.Checkpoint or tf.keras.Model.save_weights for training checkpoints. When executing eagerly variables do not necessarily have unique names, and so the variable.name-based lookups Saver performs are error-prone.
finished pretraining
Sender: LSF System <lsfadmin@eu-g3-033>
Subject: Job 232316352: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-15> by user <goezsoy> in cluster <euler> at Sat Sep 24 22:54:38 2022
Job was executed on host(s) <4*eu-g3-033>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Sat Sep 24 22:54:52 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Sat Sep 24 22:54:52 2022
Terminated at Sat Sep 24 23:33:50 2022
Results reported at Sat Sep 24 23:33:50 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

TERM_MEMLIMIT: job killed after reaching LSF memory usage limit.
Exited with exit code 137.

Resource usage summary:

    CPU time :                                   3704.62 sec.
    Max Memory :                                 16384 MB
    Average Memory :                             13092.00 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               0.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                23
    Run time :                                   2338 sec.
    Turnaround time :                            2352 sec.

The output (if any) follows:

2022-09-24 22:54:55.825072: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 22:55:14.379432: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-24 22:55:14.385727: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-24 22:55:14.430431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:a1:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.62GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-24 22:55:14.430478: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 22:55:14.532128: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-24 22:55:14.532212: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-24 22:55:14.573998: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-24 22:55:14.610996: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-24 22:55:14.710135: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-24 22:55:14.752745: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-24 22:55:14.759033: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-24 22:55:14.763862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-24 22:55:18.474656: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-24 22:55:18.475738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:a1:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.62GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-24 22:55:18.475770: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 22:55:18.475802: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-24 22:55:18.475815: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-24 22:55:18.475827: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-24 22:55:18.475838: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-24 22:55:18.475849: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-24 22:55:18.475860: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-24 22:55:18.475872: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-24 22:55:18.477122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-24 22:55:18.481097: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-24 22:55:20.690513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-24 22:55:20.690583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-24 22:55:20.690594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-24 22:55:20.698414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:a1:00.0, compute capability: 7.5)
2022-09-24 22:55:22.158295: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-24 22:55:35.010827: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-24 22:55:36.644987: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-24 22:55:37.976007: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-24 22:55:37.977400: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2250200000 Hz
2022-09-24 22:55:46.264738: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.36GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-24 22:55:46.265037: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.36GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-24 22:55:46.494896: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-24 22:55:46.495015: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-24 22:55:46.513036: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.64GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-24 22:55:46.513097: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.64GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-24 22:55:46.513139: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.70GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-24 22:55:46.513174: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.70GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-24 22:55:46.793481: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.97GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-24 22:55:46.793578: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.97GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
cfg: {'experiment': {'name': '24_sep_layers10_s32_e256_latent128_temp01_onlycont2', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 65, 'num_constrains': 6000, 'batch_size': 512, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 30, 'lrs': True}, 'model': {'latent_dim': 128, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/65
58/58 - 56s - loss: 56.8551 - cont_loss: 56.8551
Epoch 2/65
58/58 - 48s - loss: 48.6318 - cont_loss: 48.6318
Epoch 3/65
58/58 - 48s - loss: 45.2067 - cont_loss: 45.2067
Epoch 4/65
58/58 - 48s - loss: 42.4971 - cont_loss: 42.4971
Epoch 5/65
58/58 - 48s - loss: 35.9891 - cont_loss: 35.9891
Epoch 6/65
58/58 - 48s - loss: 34.1486 - cont_loss: 34.1486
Epoch 7/65
58/58 - 48s - loss: 30.7942 - cont_loss: 30.7942
Epoch 8/65
58/58 - 48s - loss: 30.0631 - cont_loss: 30.0631
Epoch 9/65
58/58 - 49s - loss: 23.1303 - cont_loss: 23.1303
Epoch 10/65
58/58 - 49s - loss: 23.6558 - cont_loss: 23.6558
Epoch 11/65
58/58 - 49s - loss: 21.5851 - cont_loss: 21.5851
Epoch 12/65
58/58 - 49s - loss: 19.1393 - cont_loss: 19.1393
Epoch 13/65
58/58 - 48s - loss: 16.0550 - cont_loss: 16.0550
Epoch 14/65
58/58 - 48s - loss: 17.2733 - cont_loss: 17.2733
Epoch 15/65
58/58 - 48s - loss: 16.1281 - cont_loss: 16.1281
Epoch 16/65
58/58 - 49s - loss: 15.3112 - cont_loss: 15.3112
Epoch 17/65
58/58 - 48s - loss: 14.6338 - cont_loss: 14.6338
Epoch 18/65
58/58 - 48s - loss: 15.3082 - cont_loss: 15.3082
Epoch 19/65
58/58 - 48s - loss: 14.0747 - cont_loss: 14.0747
Epoch 20/65
58/58 - 48s - loss: 14.2078 - cont_loss: 14.2078
Epoch 21/65
58/58 - 48s - loss: 13.1041 - cont_loss: 13.1041
Epoch 22/65
58/58 - 48s - loss: 10.7281 - cont_loss: 10.7281
Epoch 23/65
58/58 - 48s - loss: 13.7654 - cont_loss: 13.7654
Epoch 24/65
58/58 - 48s - loss: 9.7837 - cont_loss: 9.7837
Epoch 25/65
58/58 - 48s - loss: 11.0372 - cont_loss: 11.0372
Epoch 26/65
58/58 - 48s - loss: 9.1116 - cont_loss: 9.1116
Epoch 27/65
58/58 - 48s - loss: 10.5208 - cont_loss: 10.5208
Epoch 28/65
58/58 - 48s - loss: 11.8731 - cont_loss: 11.8731
Epoch 29/65
58/58 - 48s - loss: 9.4504 - cont_loss: 9.4504
Epoch 30/65
58/58 - 48s - loss: 9.3338 - cont_loss: 9.3338
Epoch 31/65
58/58 - 48s - loss: 10.3664 - cont_loss: 10.3664
Epoch 32/65
58/58 - 49s - loss: 9.4187 - cont_loss: 9.4187
Epoch 33/65
58/58 - 49s - loss: 9.0460 - cont_loss: 9.0460
Epoch 34/65
58/58 - 50s - loss: 8.6480 - cont_loss: 8.6480
Epoch 35/65
58/58 - 50s - loss: 9.6256 - cont_loss: 9.6256
Epoch 36/65
58/58 - 50s - loss: 8.1100 - cont_loss: 8.1100
Epoch 37/65
58/58 - 50s - loss: 8.3260 - cont_loss: 8.3260
Epoch 38/65
58/58 - 50s - loss: 7.5958 - cont_loss: 7.5958
Epoch 39/65
58/58 - 50s - loss: 8.2131 - cont_loss: 8.2131
Epoch 40/65
58/58 - 50s - loss: 7.1597 - cont_loss: 7.1597
Epoch 41/65
58/58 - 51s - loss: 6.7478 - cont_loss: 6.7478
Epoch 42/65
58/58 - 50s - loss: 7.3587 - cont_loss: 7.3587
Epoch 43/65
58/58 - 50s - loss: 7.6961 - cont_loss: 7.6961
Epoch 44/65
58/58 - 50s - loss: 6.6031 - cont_loss: 6.6031
Epoch 45/65
58/58 - 50s - loss: 5.9252 - cont_loss: 5.9252
Epoch 46/65
58/58 - 50s - loss: 7.2424 - cont_loss: 7.2424
/cluster/shadow/.lsbatch/1664052878.232316352: line 8:  4096 Killed                  python main_contrastive.py --config ../config.yml
Sender: LSF System <lsfadmin@eu-g3-019>
Subject: Job 232333578: <python main_contrastive.py --config ../config.yml> in cluster <euler> Done

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-08> by user <goezsoy> in cluster <euler> at Sun Sep 25 09:47:08 2022
Job was executed on host(s) <4*eu-g3-019>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Sun Sep 25 09:47:27 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Sun Sep 25 09:47:27 2022
Terminated at Sun Sep 25 10:52:27 2022
Results reported at Sun Sep 25 10:52:27 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   5240.30 sec.
    Max Memory :                                 16245 MB
    Average Memory :                             13829.41 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               139.00 MB
    Max Swap :                                   140 MB
    Max Processes :                              3
    Max Threads :                                23
    Run time :                                   3903 sec.
    Turnaround time :                            3919 sec.

The output (if any) follows:

2022-09-25 09:47:32.006672: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 09:47:51.616137: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-25 09:47:51.622747: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-25 09:47:51.675976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:21:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-25 09:47:51.676022: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 09:47:51.709825: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 09:47:51.709910: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 09:47:51.721259: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-25 09:47:51.734645: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-25 09:47:51.765709: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-25 09:47:51.775633: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-25 09:47:51.779863: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 09:47:51.784099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-25 09:47:55.702367: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-25 09:47:55.704131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:21:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-25 09:47:55.704174: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 09:47:55.704240: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 09:47:55.704264: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 09:47:55.704286: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-25 09:47:55.704305: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-25 09:47:55.704325: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-25 09:47:55.704346: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-25 09:47:55.704367: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 09:47:55.706735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-25 09:47:55.710162: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 09:47:57.974170: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-25 09:47:57.974228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-25 09:47:57.974236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-25 09:47:57.981540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:21:00.0, compute capability: 7.5)
2022-09-25 09:47:59.652286: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 09:48:12.600190: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 09:48:14.297066: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 09:48:15.692362: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-25 09:48:15.693779: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2249800000 Hz
2022-09-25 09:48:24.202373: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.36GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 09:48:24.202619: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.36GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 09:48:24.441924: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 09:48:24.441990: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 09:48:24.460634: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.64GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 09:48:24.460692: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.64GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 09:48:24.460732: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.70GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 09:48:24.460768: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.70GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 09:48:24.750277: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.97GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 09:48:24.750409: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.97GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
cfg: {'experiment': {'name': '25_sep_layers10_s32_e256_latent128_temp01_onlycont', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 45, 'num_constrains': 6000, 'batch_size': 512, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 30, 'lrs': True}, 'model': {'latent_dim': 128, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/45
58/58 - 66s - loss: 56.2393 - cont_loss: 56.2393
Epoch 2/45
58/58 - 60s - loss: 43.3712 - cont_loss: 43.3712
Epoch 3/45
58/58 - 58s - loss: 35.9798 - cont_loss: 35.9798
Epoch 4/45
58/58 - 57s - loss: 33.9114 - cont_loss: 33.9114
Epoch 5/45
58/58 - 60s - loss: 32.1822 - cont_loss: 32.1822
Epoch 6/45
58/58 - 56s - loss: 26.3422 - cont_loss: 26.3422
Epoch 7/45
58/58 - 55s - loss: 27.2456 - cont_loss: 27.2456
Epoch 8/45
58/58 - 54s - loss: 22.5015 - cont_loss: 22.5015
Epoch 9/45
58/58 - 53s - loss: 21.0923 - cont_loss: 21.0923
Epoch 10/45
58/58 - 54s - loss: 20.8264 - cont_loss: 20.8264
Epoch 11/45
58/58 - 55s - loss: 17.8391 - cont_loss: 17.8391
Epoch 12/45
58/58 - 55s - loss: 17.1330 - cont_loss: 17.1330
Epoch 13/45
58/58 - 54s - loss: 15.6514 - cont_loss: 15.6514
Epoch 14/45
58/58 - 54s - loss: 13.4242 - cont_loss: 13.4242
Epoch 15/45
58/58 - 54s - loss: 14.4548 - cont_loss: 14.4548
Epoch 16/45
58/58 - 55s - loss: 15.8046 - cont_loss: 15.8046
Epoch 17/45
58/58 - 55s - loss: 12.0141 - cont_loss: 12.0141
Epoch 18/45
58/58 - 55s - loss: 13.7550 - cont_loss: 13.7550
Epoch 19/45
58/58 - 55s - loss: 12.1548 - cont_loss: 12.1548
Epoch 20/45
58/58 - 54s - loss: 12.2641 - cont_loss: 12.2641
Epoch 21/45
58/58 - 54s - loss: 13.8504 - cont_loss: 13.8504
Epoch 22/45
58/58 - 54s - loss: 11.2693 - cont_loss: 11.2693
Epoch 23/45
58/58 - 54s - loss: 12.0359 - cont_loss: 12.0359
Epoch 24/45
58/58 - 54s - loss: 9.8483 - cont_loss: 9.8483
Epoch 25/45
58/58 - 54s - loss: 10.8561 - cont_loss: 10.8561
Epoch 26/45
58/58 - 53s - loss: 12.3015 - cont_loss: 12.3015
Epoch 27/45
58/58 - 53s - loss: 11.0687 - cont_loss: 11.0687
Epoch 28/45
58/58 - 53s - loss: 12.6890 - cont_loss: 12.6890
Epoch 29/45
58/58 - 54s - loss: 11.3330 - cont_loss: 11.3330
Epoch 30/45
58/58 - 53s - loss: 9.9216 - cont_loss: 9.9216
Epoch 31/45
58/58 - 53s - loss: 10.3417 - cont_loss: 10.3417
Epoch 32/45
58/58 - 53s - loss: 8.8652 - cont_loss: 8.8652
Epoch 33/45
58/58 - 54s - loss: 9.8094 - cont_loss: 9.8094
Epoch 34/45
58/58 - 54s - loss: 9.0424 - cont_loss: 9.0424
Epoch 35/45
58/58 - 51s - loss: 9.2423 - cont_loss: 9.2423
Epoch 36/45
58/58 - 52s - loss: 8.8352 - cont_loss: 8.8352
Epoch 37/45
58/58 - 50s - loss: 7.5906 - cont_loss: 7.5906
Epoch 38/45
58/58 - 50s - loss: 8.4962 - cont_loss: 8.4962
Epoch 39/45
58/58 - 51s - loss: 8.2421 - cont_loss: 8.2421
Epoch 40/45
58/58 - 51s - loss: 7.1712 - cont_loss: 7.1712
Epoch 41/45
58/58 - 51s - loss: 8.0593 - cont_loss: 8.0593
Epoch 42/45
58/58 - 51s - loss: 6.7350 - cont_loss: 6.7350
Epoch 43/45
58/58 - 51s - loss: 7.8852 - cont_loss: 7.8852
Epoch 44/45
58/58 - 51s - loss: 7.2032 - cont_loss: 7.2032
Epoch 45/45
58/58 - 51s - loss: 6.8241 - cont_loss: 6.8241
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape_1:0", shape=(None,), dtype=int32), values=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape:0", shape=(None, None), dtype=float32), dense_shape=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
WARNING:tensorflow:Saver is deprecated, please switch to tf.train.Checkpoint or tf.keras.Model.save_weights for training checkpoints. When executing eagerly variables do not necessarily have unique names, and so the variable.name-based lookups Saver performs are error-prone.
finished pretraining
Sender: LSF System <lsfadmin@eu-g3-035>
Subject: Job 232353456: <python main_contrastive.py --config ../config.yml> in cluster <euler> Done

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-08> by user <goezsoy> in cluster <euler> at Sun Sep 25 14:16:14 2022
Job was executed on host(s) <4*eu-g3-035>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Sun Sep 25 14:16:39 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Sun Sep 25 14:16:39 2022
Terminated at Sun Sep 25 15:25:32 2022
Results reported at Sun Sep 25 15:25:32 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4919.59 sec.
    Max Memory :                                 11510 MB
    Average Memory :                             9167.92 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               4874.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                25
    Run time :                                   4133 sec.
    Turnaround time :                            4158 sec.

The output (if any) follows:

2022-09-25 14:16:42.896576: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 14:17:01.606413: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-25 14:17:01.609392: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-25 14:17:01.653849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:22:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.62GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-25 14:17:01.653895: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 14:17:01.755751: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 14:17:01.755814: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 14:17:01.797627: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-25 14:17:01.834177: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-25 14:17:01.934346: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-25 14:17:01.975547: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-25 14:17:01.982299: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 14:17:01.987093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-25 14:17:05.643620: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-25 14:17:05.645641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:22:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.62GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-25 14:17:05.645696: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 14:17:05.645746: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 14:17:05.645775: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 14:17:05.645801: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-25 14:17:05.645826: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-25 14:17:05.645851: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-25 14:17:05.645875: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-25 14:17:05.645902: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 14:17:05.647957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-25 14:17:05.652104: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 14:17:07.491334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-25 14:17:07.491406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-25 14:17:07.491420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-25 14:17:07.499749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:22:00.0, compute capability: 7.5)
2022-09-25 14:17:09.779694: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 14:17:11.428945: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 14:17:19.909567: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 14:17:34.406374: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-25 14:17:34.407737: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2249855000 Hz
2022-09-25 14:17:43.018058: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.36GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 14:17:43.018673: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.36GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 14:17:43.259872: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 14:17:43.259934: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 14:17:43.278934: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.64GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 14:17:43.279010: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.64GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 14:17:43.279062: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.70GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 14:17:43.279107: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.70GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 14:17:43.567902: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.97GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 14:17:43.567952: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.97GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
cfg: {'experiment': {'name': '25_sep_layers10_s32_e128_latent2048_128_temp05_onlycont_newaug', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 10, 'num_constrains': 6000, 'batch_size': 512, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 30, 'lrs': True}, 'model': {'latent_dim': 128, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/10
58/58 - 352s - loss: 6.6118 - cont_loss: 6.6118
Epoch 2/10
58/58 - 349s - loss: 6.4310 - cont_loss: 6.4310
Epoch 3/10
58/58 - 348s - loss: 6.3746 - cont_loss: 6.3746
Epoch 4/10
58/58 - 347s - loss: 6.3384 - cont_loss: 6.3384
Epoch 5/10
58/58 - 348s - loss: 6.2897 - cont_loss: 6.2897
Epoch 6/10
58/58 - 346s - loss: 6.2474 - cont_loss: 6.2474
Epoch 7/10
58/58 - 348s - loss: 6.2152 - cont_loss: 6.2152
Epoch 8/10
58/58 - 348s - loss: 6.1965 - cont_loss: 6.1965
Epoch 9/10
58/58 - 348s - loss: 6.1762 - cont_loss: 6.1762
Epoch 10/10
58/58 - 348s - loss: 6.1512 - cont_loss: 6.1512
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape_1:0", shape=(None,), dtype=int32), values=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape:0", shape=(None, None), dtype=float32), dense_shape=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
WARNING:tensorflow:Saver is deprecated, please switch to tf.train.Checkpoint or tf.keras.Model.save_weights for training checkpoints. When executing eagerly variables do not necessarily have unique names, and so the variable.name-based lookups Saver performs are error-prone.
finished pretraining
Sender: LSF System <lsfadmin@eu-g3-039>
Subject: Job 232358291: <python main_contrastive.py --config ../config.yml> in cluster <euler> Done

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-08> by user <goezsoy> in cluster <euler> at Sun Sep 25 14:47:02 2022
Job was executed on host(s) <4*eu-g3-039>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Sun Sep 25 14:47:13 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Sun Sep 25 14:47:13 2022
Terminated at Sun Sep 25 15:55:11 2022
Results reported at Sun Sep 25 15:55:11 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4856.49 sec.
    Max Memory :                                 10640 MB
    Average Memory :                             8480.07 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               5744.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                23
    Run time :                                   4078 sec.
    Turnaround time :                            4089 sec.

The output (if any) follows:

2022-09-25 14:47:16.892190: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 14:47:28.687293: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-25 14:47:28.692435: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-25 14:47:28.736149: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:41:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.62GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-25 14:47:28.736193: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 14:47:28.837667: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 14:47:28.837942: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 14:47:28.878956: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-25 14:47:28.915520: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-25 14:47:29.012760: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-25 14:47:29.054143: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-25 14:47:29.059716: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 14:47:29.063778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-25 14:47:32.722457: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-25 14:47:32.723927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:41:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.62GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-25 14:47:32.723994: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 14:47:32.724049: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 14:47:32.724078: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 14:47:32.724104: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-25 14:47:32.724130: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-25 14:47:32.724155: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-25 14:47:32.724180: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-25 14:47:32.724206: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 14:47:32.726265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-25 14:47:32.731626: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 14:47:34.900374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-25 14:47:34.900771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-25 14:47:34.900780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-25 14:47:34.905160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:41:00.0, compute capability: 7.5)
2022-09-25 14:47:37.417532: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 14:47:39.028073: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 14:47:47.208357: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 14:48:01.490744: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-25 14:48:01.492287: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2250045000 Hz
2022-09-25 14:48:10.129806: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.36GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 14:48:10.130187: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.36GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 14:48:10.369274: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 14:48:10.369468: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 14:48:10.387870: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.64GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 14:48:10.387906: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.64GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 14:48:10.387932: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.70GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 14:48:10.387952: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.70GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 14:48:10.675240: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.97GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 14:48:10.675327: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.97GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
cfg: {'experiment': {'name': '25_sep_layers10_s32_e128_latent2048_128_temp01_onlycont_newaug', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 10, 'num_constrains': 6000, 'batch_size': 512, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 30, 'lrs': True}, 'model': {'latent_dim': 128, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/10
58/58 - 337s - loss: 6.5570 - cont_loss: 6.5570
Epoch 2/10
58/58 - 334s - loss: 6.2262 - cont_loss: 6.2262
Epoch 3/10
58/58 - 335s - loss: 6.0476 - cont_loss: 6.0476
Epoch 4/10
58/58 - 334s - loss: 5.9189 - cont_loss: 5.9189
Epoch 5/10
58/58 - 338s - loss: 5.7927 - cont_loss: 5.7927
Epoch 6/10
58/58 - 333s - loss: 5.6875 - cont_loss: 5.6875
Epoch 7/10
58/58 - 338s - loss: 5.6069 - cont_loss: 5.6069
Epoch 8/10
58/58 - 339s - loss: 5.5424 - cont_loss: 5.5424
Epoch 9/10
58/58 - 336s - loss: 5.4481 - cont_loss: 5.4481
Epoch 10/10
58/58 - 336s - loss: 5.3797 - cont_loss: 5.3797
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape_1:0", shape=(None,), dtype=int32), values=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape:0", shape=(None, None), dtype=float32), dense_shape=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
WARNING:tensorflow:Saver is deprecated, please switch to tf.train.Checkpoint or tf.keras.Model.save_weights for training checkpoints. When executing eagerly variables do not necessarily have unique names, and so the variable.name-based lookups Saver performs are error-prone.
finished pretraining
Sender: LSF System <lsfadmin@eu-g2-12>
Subject: Job 232358812: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-08> by user <goezsoy> in cluster <euler> at Sun Sep 25 14:50:00 2022
Job was executed on host(s) <4*eu-g2-12>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Sun Sep 25 14:50:13 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Sun Sep 25 14:50:13 2022
Terminated at Sun Sep 25 16:00:08 2022
Results reported at Sun Sep 25 16:00:08 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   5699.27 sec.
    Max Memory :                                 11408 MB
    Average Memory :                             8807.16 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               4976.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                31
    Run time :                                   4195 sec.
    Turnaround time :                            4208 sec.

The output (if any) follows:

2022-09-25 14:50:16.284731: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 14:50:34.501232: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-25 14:50:34.508380: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-25 14:50:34.552118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:b1:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-25 14:50:34.552157: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 14:50:34.578618: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 14:50:34.578769: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 14:50:34.586551: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-25 14:50:34.597922: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-25 14:50:34.626641: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-25 14:50:34.635138: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-25 14:50:34.637930: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 14:50:34.642352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-25 14:50:39.236854: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-25 14:50:39.245067: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-25 14:50:39.246522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:b1:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-25 14:50:39.246595: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 14:50:39.246665: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 14:50:39.246703: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 14:50:39.246739: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-25 14:50:39.246773: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-25 14:50:39.246806: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-25 14:50:39.246839: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-25 14:50:39.246874: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 14:50:39.248920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-25 14:50:39.252467: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 14:50:39.866752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-25 14:50:39.866793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-25 14:50:39.866800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-25 14:50:39.874735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:b1:00.0, compute capability: 7.5)
2022-09-25 14:50:42.553395: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 14:50:44.525094: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 14:50:53.057924: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 14:51:08.441680: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-25 14:51:08.444455: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
2022-09-25 14:51:17.658255: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.36GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 14:51:17.658570: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.36GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 14:51:17.895945: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 14:51:17.896050: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 14:51:17.915900: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.64GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 14:51:17.916017: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.64GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 14:51:17.916077: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.70GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 14:51:17.916123: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.70GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 14:51:18.219640: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.97GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 14:51:18.219735: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.97GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
cfg: {'experiment': {'name': '25_sep_layers10_s32_e128_latent2048_128_temp01_onlycont_newaug_lr03', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 10, 'num_constrains': 6000, 'batch_size': 512, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.3, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 30, 'lrs': True}, 'model': {'latent_dim': 128, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/10
58/58 - 378s - loss: 6.8707 - cont_loss: 6.8707
Epoch 2/10
58/58 - 374s - loss: 6.6323 - cont_loss: 6.6323
Epoch 3/10
58/58 - 373s - loss: 6.6372 - cont_loss: 6.6372
Epoch 4/10
58/58 - 377s - loss: 6.5918 - cont_loss: 6.5918
Epoch 5/10
58/58 - 377s - loss: 6.5893 - cont_loss: 6.5893
Epoch 6/10
58/58 - 376s - loss: 6.5776 - cont_loss: 6.5776
Epoch 7/10
58/58 - 376s - loss: 6.5762 - cont_loss: 6.5762
Epoch 8/10
58/58 - 375s - loss: 6.5496 - cont_loss: 6.5496
Epoch 9/10
58/58 - 376s - loss: 6.5667 - cont_loss: 6.5667
Epoch 10/10
58/58 - 376s - loss: 6.5627 - cont_loss: 6.5627
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape_1:0", shape=(None,), dtype=int32), values=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape:0", shape=(None, None), dtype=float32), dense_shape=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
Traceback (most recent call last):
  File "main_contrastive.py", line 140, in <module>
    run_experiment(cfg)
  File "main_contrastive.py", line 103, in run_experiment
    z_transformed_tsne = tsne.fit_transform(z)
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py", line 886, in fit_transform
    embedding = self._fit(X)
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py", line 795, in _fit
    return self._tsne(P, degrees_of_freedom, n_samples,
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py", line 851, in _tsne
    params, kl_divergence, it = _gradient_descent(obj_func, params,
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py", line 358, in _gradient_descent
    error, grad = objective(p, *args, **kwargs)
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py", line 258, in _kl_divergence_bh
    error = _barnes_hut_tsne.gradient(val_P, X_embedded, neighbors, indptr,
KeyboardInterrupt
Sender: LSF System <lsfadmin@eu-g2-04>
Subject: Job 232371504: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-08> by user <goezsoy> in cluster <euler> at Sun Sep 25 16:06:15 2022
Job was executed on host(s) <4*eu-g2-04>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Sun Sep 25 16:06:45 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Sun Sep 25 16:06:45 2022
Terminated at Sun Sep 25 16:07:14 2022
Results reported at Sun Sep 25 16:07:14 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   10.50 sec.
    Max Memory :                                 1911 MB
    Average Memory :                             256.00 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               14473.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                4
    Run time :                                   28 sec.
    Turnaround time :                            59 sec.

The output (if any) follows:

2022-09-25 16:06:49.127237: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
Traceback (most recent call last):
  File "main_contrastive.py", line 140, in <module>
    run_experiment(cfg)
  File "main_contrastive.py", line 42, in run_experiment
    Path(experiment_path).mkdir(parents=True)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/pathlib.py", line 1284, in mkdir
    self._accessor.mkdir(self, mode)
FileExistsError: [Errno 17] File exists: '../logs/CIFAR10/25_sep_layers10_s32_e128_latent512_128_temp01_onlycont_newaug'
Sender: LSF System <lsfadmin@eu-g2-20>
Subject: Job 232372561: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-08> by user <goezsoy> in cluster <euler> at Sun Sep 25 16:12:49 2022
Job was executed on host(s) <4*eu-g2-20>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Sun Sep 25 16:13:13 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Sun Sep 25 16:13:13 2022
Terminated at Sun Sep 25 19:58:05 2022
Results reported at Sun Sep 25 19:58:05 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

TERM_MEMLIMIT: job killed after reaching LSF memory usage limit.
Exited with exit code 137.

Resource usage summary:

    CPU time :                                   18424.29 sec.
    Max Memory :                                 16384 MB
    Average Memory :                             9870.19 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               0.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                31
    Run time :                                   13492 sec.
    Turnaround time :                            13516 sec.

The output (if any) follows:

2022-09-25 16:13:16.596588: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 16:13:23.487895: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-25 16:13:23.489384: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-25 16:13:23.724782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:1a:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-25 16:13:23.724844: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 16:13:23.731445: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 16:13:23.731565: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 16:13:23.734273: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-25 16:13:23.735315: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-25 16:13:23.740434: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-25 16:13:23.741847: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-25 16:13:23.742380: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 16:13:23.743691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-25 16:13:25.760633: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-25 16:13:25.761543: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-25 16:13:25.762433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:1a:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-25 16:13:25.762470: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 16:13:25.762507: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 16:13:25.762518: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 16:13:25.762529: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-25 16:13:25.762539: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-25 16:13:25.762550: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-25 16:13:25.762560: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-25 16:13:25.762570: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 16:13:25.763533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-25 16:13:25.763559: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 16:13:26.413794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-25 16:13:26.413834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-25 16:13:26.413842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-25 16:13:26.415950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1a:00.0, compute capability: 7.5)
2022-09-25 16:13:28.909356: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 16:13:29.418466: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 16:13:33.268500: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 16:13:36.225636: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-25 16:13:36.226995: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
cfg: {'experiment': {'name': '25_sep_layers10_s32_e128_latent512_128_temp01_onlycont_newaug2', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 100, 'num_constrains': 6000, 'batch_size': 256, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 30, 'lrs': True}, 'model': {'latent_dim': 128, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/100
117/117 - 431s - loss: 5.8468 - cont_loss: 5.8468
Epoch 2/100
117/117 - 426s - loss: 5.6014 - cont_loss: 5.6014
Epoch 3/100
117/117 - 428s - loss: 5.4461 - cont_loss: 5.4461
Epoch 4/100
117/117 - 442s - loss: 5.2999 - cont_loss: 5.2999
Epoch 5/100
117/117 - 442s - loss: 5.1597 - cont_loss: 5.1597
Epoch 6/100
117/117 - 442s - loss: 5.0469 - cont_loss: 5.0469
Epoch 7/100
117/117 - 449s - loss: 4.9564 - cont_loss: 4.9564
Epoch 8/100
117/117 - 439s - loss: 4.8721 - cont_loss: 4.8721
Epoch 9/100
117/117 - 438s - loss: 4.7859 - cont_loss: 4.7859
Epoch 10/100
117/117 - 439s - loss: 4.7306 - cont_loss: 4.7306
Epoch 11/100
117/117 - 440s - loss: 4.6627 - cont_loss: 4.6627
Epoch 12/100
117/117 - 441s - loss: 4.5860 - cont_loss: 4.5860
Epoch 13/100
117/117 - 439s - loss: 4.5698 - cont_loss: 4.5698
Epoch 14/100
117/117 - 440s - loss: 4.5164 - cont_loss: 4.5164
Epoch 15/100
117/117 - 436s - loss: 4.4906 - cont_loss: 4.4906
Epoch 16/100
117/117 - 436s - loss: 4.4436 - cont_loss: 4.4436
Epoch 17/100
117/117 - 434s - loss: 4.4486 - cont_loss: 4.4486
Epoch 18/100
117/117 - 433s - loss: 4.4033 - cont_loss: 4.4033
Epoch 19/100
117/117 - 435s - loss: 4.3899 - cont_loss: 4.3899
Epoch 20/100
117/117 - 440s - loss: 4.3450 - cont_loss: 4.3450
Epoch 21/100
117/117 - 440s - loss: 4.2149 - cont_loss: 4.2149
Epoch 22/100
117/117 - 441s - loss: 4.1317 - cont_loss: 4.1317
Epoch 23/100
117/117 - 437s - loss: 4.1075 - cont_loss: 4.1075
Epoch 24/100
117/117 - 444s - loss: 4.0768 - cont_loss: 4.0768
Epoch 25/100
117/117 - 445s - loss: 4.0288 - cont_loss: 4.0288
Epoch 26/100
117/117 - 447s - loss: 3.9928 - cont_loss: 3.9928
Epoch 27/100
117/117 - 448s - loss: 3.9660 - cont_loss: 3.9660
Epoch 28/100
117/117 - 450s - loss: 3.9516 - cont_loss: 3.9516
Epoch 29/100
117/117 - 448s - loss: 3.9305 - cont_loss: 3.9305
Epoch 30/100
117/117 - 450s - loss: 3.8943 - cont_loss: 3.8943
/cluster/shadow/.lsbatch/1664115169.232372561: line 8: 81427 Killed                  python main_contrastive.py --config ../config.yml
Sender: LSF System <lsfadmin@eu-g2-20>
Subject: Job 232370849: <python main_contrastive.py --config ../config.yml> in cluster <euler> Done

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-08> by user <goezsoy> in cluster <euler> at Sun Sep 25 16:02:13 2022
Job was executed on host(s) <4*eu-g2-20>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Sun Sep 25 16:02:44 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Sun Sep 25 16:02:44 2022
Terminated at Sun Sep 25 21:03:48 2022
Results reported at Sun Sep 25 21:03:48 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   24679.34 sec.
    Max Memory :                                 16384 MB
    Average Memory :                             12593.50 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               0.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                31
    Run time :                                   18064 sec.
    Turnaround time :                            18095 sec.

The output (if any) follows:

2022-09-25 16:02:47.081525: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 16:03:05.132367: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-25 16:03:05.140745: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-25 16:03:05.266987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:da:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-25 16:03:05.267039: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 16:03:05.372260: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 16:03:05.372454: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 16:03:05.414693: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-25 16:03:05.450353: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-25 16:03:05.534896: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-25 16:03:05.568709: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-25 16:03:05.574707: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 16:03:05.746342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-25 16:03:10.377468: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-25 16:03:10.378305: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-25 16:03:10.379047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:da:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-25 16:03:10.379084: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 16:03:10.379124: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 16:03:10.379135: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 16:03:10.379146: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-25 16:03:10.379156: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-25 16:03:10.379167: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-25 16:03:10.379177: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-25 16:03:10.379188: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 16:03:10.380185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-25 16:03:10.384903: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 16:03:11.544363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-25 16:03:11.544399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-25 16:03:11.544406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-25 16:03:11.550289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:da:00.0, compute capability: 7.5)
2022-09-25 16:03:14.439314: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 16:03:16.519445: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 16:03:24.190250: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 16:03:39.811609: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-25 16:03:39.832713: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
2022-09-25 16:03:49.081013: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.36GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 16:03:49.081320: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.36GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 16:03:49.316986: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 16:03:49.317066: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 16:03:49.335240: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.64GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 16:03:49.335311: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.64GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 16:03:49.335351: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.70GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 16:03:49.335381: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.70GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 16:03:49.633853: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.97GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-25 16:03:49.633960: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.97GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
cfg: {'experiment': {'name': '25_sep_layers10_s32_e128_latent512_128_temp01_onlycont_newaug', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 45, 'num_constrains': 6000, 'batch_size': 512, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 30, 'lrs': True}, 'model': {'latent_dim': 128, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/45
58/58 - 352s - loss: 6.6207 - cont_loss: 6.6207
Epoch 2/45
58/58 - 351s - loss: 6.3855 - cont_loss: 6.3855
Epoch 3/45
58/58 - 359s - loss: 6.2975 - cont_loss: 6.2975
Epoch 4/45
58/58 - 357s - loss: 6.1992 - cont_loss: 6.1992
Epoch 5/45
58/58 - 361s - loss: 6.0864 - cont_loss: 6.0864
Epoch 6/45
58/58 - 372s - loss: 6.0061 - cont_loss: 6.0061
Epoch 7/45
58/58 - 371s - loss: 5.8985 - cont_loss: 5.8985
Epoch 8/45
58/58 - 369s - loss: 5.8329 - cont_loss: 5.8329
Epoch 9/45
58/58 - 378s - loss: 5.7932 - cont_loss: 5.7932
Epoch 10/45
58/58 - 397s - loss: 5.6636 - cont_loss: 5.6636
Epoch 11/45
58/58 - 373s - loss: 5.5884 - cont_loss: 5.5884
Epoch 12/45
58/58 - 372s - loss: 5.4995 - cont_loss: 5.4995
Epoch 13/45
58/58 - 373s - loss: 5.4369 - cont_loss: 5.4369
Epoch 14/45
58/58 - 369s - loss: 5.4522 - cont_loss: 5.4522
Epoch 15/45
58/58 - 372s - loss: 5.3604 - cont_loss: 5.3604
Epoch 16/45
58/58 - 371s - loss: 5.2282 - cont_loss: 5.2282
Epoch 17/45
58/58 - 366s - loss: 5.0959 - cont_loss: 5.0959
Epoch 18/45
58/58 - 366s - loss: 5.0385 - cont_loss: 5.0385
Epoch 19/45
58/58 - 364s - loss: 5.0030 - cont_loss: 5.0030
Epoch 20/45
58/58 - 366s - loss: 4.9018 - cont_loss: 4.9018
Epoch 21/45
58/58 - 365s - loss: 4.8556 - cont_loss: 4.8556
Epoch 22/45
58/58 - 362s - loss: 4.8484 - cont_loss: 4.8484
Epoch 23/45
58/58 - 360s - loss: 4.7976 - cont_loss: 4.7976
Epoch 24/45
58/58 - 362s - loss: 4.7667 - cont_loss: 4.7667
Epoch 25/45
58/58 - 383s - loss: 4.7000 - cont_loss: 4.7000
Epoch 26/45
58/58 - 366s - loss: 4.5975 - cont_loss: 4.5975
Epoch 27/45
58/58 - 365s - loss: 4.5227 - cont_loss: 4.5227
Epoch 28/45
58/58 - 368s - loss: 4.5016 - cont_loss: 4.5016
Epoch 29/45
58/58 - 365s - loss: 4.4575 - cont_loss: 4.4575
Epoch 30/45
58/58 - 371s - loss: 4.3841 - cont_loss: 4.3841
Epoch 31/45
58/58 - 377s - loss: 4.3005 - cont_loss: 4.3005
Epoch 32/45
58/58 - 372s - loss: 4.2731 - cont_loss: 4.2731
Epoch 33/45
58/58 - 372s - loss: 4.2200 - cont_loss: 4.2200
Epoch 34/45
58/58 - 374s - loss: 4.1365 - cont_loss: 4.1365
Epoch 35/45
58/58 - 372s - loss: 4.1163 - cont_loss: 4.1163
Epoch 36/45
58/58 - 374s - loss: 4.0590 - cont_loss: 4.0590
Epoch 37/45
58/58 - 375s - loss: 4.0260 - cont_loss: 4.0260
Epoch 38/45
58/58 - 380s - loss: 4.0048 - cont_loss: 4.0048
Epoch 39/45
58/58 - 389s - loss: 4.0042 - cont_loss: 4.0042
Epoch 40/45
58/58 - 394s - loss: 3.9624 - cont_loss: 3.9624
Epoch 41/45
58/58 - 372s - loss: 3.9319 - cont_loss: 3.9319
Epoch 42/45
58/58 - 374s - loss: 3.9258 - cont_loss: 3.9258
Epoch 43/45
58/58 - 372s - loss: 3.8780 - cont_loss: 3.8780
Epoch 44/45
58/58 - 377s - loss: 3.8921 - cont_loss: 3.8921
Epoch 45/45
58/58 - 387s - loss: 3.8729 - cont_loss: 3.8729
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape_1:0", shape=(None,), dtype=int32), values=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape:0", shape=(None, None), dtype=float32), dense_shape=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
WARNING:tensorflow:Saver is deprecated, please switch to tf.train.Checkpoint or tf.keras.Model.save_weights for training checkpoints. When executing eagerly variables do not necessarily have unique names, and so the variable.name-based lookups Saver performs are error-prone.
finished pretraining
Sender: LSF System <lsfadmin@eu-g3-033>
Subject: Job 232405321: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-10> by user <goezsoy> in cluster <euler> at Sun Sep 25 22:27:15 2022
Job was executed on host(s) <4*eu-g3-033>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Sun Sep 25 22:27:26 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Sun Sep 25 22:27:26 2022
Terminated at Sun Sep 25 22:28:04 2022
Results reported at Sun Sep 25 22:28:04 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   16.85 sec.
    Max Memory :                                 4955 MB
    Average Memory :                             2122.00 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               11429.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                20
    Run time :                                   62 sec.
    Turnaround time :                            49 sec.

The output (if any) follows:

2022-09-25 22:27:30.820282: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 22:27:45.586888: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-25 22:27:45.595490: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-25 22:27:45.667297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:81:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.62GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-25 22:27:45.667343: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 22:27:45.895374: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 22:27:45.895456: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 22:27:45.967382: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-25 22:27:46.034794: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-25 22:27:46.244912: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-25 22:27:46.327097: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-25 22:27:46.340136: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 22:27:46.357224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-25 22:27:51.449773: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-25 22:27:51.451206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:81:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.62GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-25 22:27:51.451258: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 22:27:51.451309: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 22:27:51.451337: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 22:27:51.451364: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-25 22:27:51.451389: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-25 22:27:51.451413: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-25 22:27:51.451438: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-25 22:27:51.451464: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 22:27:51.455201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-25 22:27:51.467489: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 22:27:54.769756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-25 22:27:54.769826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-25 22:27:54.769837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-25 22:27:54.782313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:81:00.0, compute capability: 7.5)
2022-09-25 22:27:57.162248: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 22:27:58.772123: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
cfg: {'experiment': {'name': '26_sep_layers10_s32_e128_latent512_128_temp01_onlycont_newaug0', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 200, 'num_constrains': 6000, 'batch_size': 256, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 50, 'lrs': True}, 'model': {'latent_dim': 128, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Traceback (most recent call last):
  File "main_contrastive.py", line 140, in <module>
    run_experiment(cfg)
  File "main_contrastive.py", line 81, in run_experiment
    model.fit(train_generator, steps_per_epoch=int(len(Y)/(2*cfg['training']['batch_size'])), epochs=cfg['training']['epochs'], callbacks=callback_list, verbose=2)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 1050, in fit
    data_handler = data_adapter.DataHandler(
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py", line 1100, in __init__
    self._adapter = adapter_cls(
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py", line 786, in __init__
    model.distribute_strategy.run(
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py", line 1259, in run
    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2730, in call_for_each_replica
    return self._call_for_each_replica(fn, args, kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3417, in _call_for_each_replica
    return fn(*args, **kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/autograph/impl/api.py", line 572, in wrapper
    return func(*args, **kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py", line 787, in <lambda>
    lambda x: model(x, training=False), args=(concrete_x,))
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py", line 1012, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File "/cluster/home/goezsoy/constrastive-DC-GMM/src/model.py", line 901, in call
    z_mu = self.encoder(inputs)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py", line 1012, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File "/cluster/home/goezsoy/constrastive-DC-GMM/src/model.py", line 802, in call
    for block in self.layers:
AttributeError: 'VGGEncoderAE' object has no attribute 'layers'
Sender: LSF System <lsfadmin@eu-g2-15>
Subject: Job 232373936: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-08> by user <goezsoy> in cluster <euler> at Sun Sep 25 16:20:58 2022
Job was executed on host(s) <4*eu-g2-15>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Sun Sep 25 16:21:14 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Sun Sep 25 16:21:14 2022
Terminated at Sun Sep 25 22:28:31 2022
Results reported at Sun Sep 25 22:28:31 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 143.

Resource usage summary:

    CPU time :                                   30144.23 sec.
    Max Memory :                                 12826 MB
    Average Memory :                             9193.07 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               3558.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                31
    Run time :                                   22036 sec.
    Turnaround time :                            22053 sec.

The output (if any) follows:

2022-09-25 16:21:17.476739: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 16:21:26.704829: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-25 16:21:26.715323: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-25 16:21:26.775521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:b1:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-25 16:21:26.775549: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 16:21:26.782467: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 16:21:26.782538: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 16:21:26.784516: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-25 16:21:26.785318: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-25 16:21:26.789437: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-25 16:21:26.790756: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-25 16:21:26.792714: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 16:21:26.802654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-25 16:21:31.310160: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-25 16:21:31.311006: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-25 16:21:31.311925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:b1:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-25 16:21:31.311973: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 16:21:31.312025: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 16:21:31.312044: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 16:21:31.312062: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-25 16:21:31.312080: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-25 16:21:31.312098: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-25 16:21:31.312115: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-25 16:21:31.312133: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 16:21:31.313433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-25 16:21:31.319021: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 16:21:33.272592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-25 16:21:33.277102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-25 16:21:33.277126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-25 16:21:33.279500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:b1:00.0, compute capability: 7.5)
2022-09-25 16:21:35.885701: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 16:21:37.789824: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 16:21:41.589770: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 16:21:56.264073: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-25 16:21:56.265661: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
cfg: {'experiment': {'name': '25_sep_layers10_s32_e128_latent512_128_temp01_onlycont_newaug_lr1', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 200, 'num_constrains': 6000, 'batch_size': 256, 'alpha': 10000.0, 'q': 0, 'learning_rate': 1.0, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 30, 'lrs': True}, 'model': {'latent_dim': 128, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/200
117/117 - 434s - loss: 6.2363 - cont_loss: 6.2363
Epoch 2/200
117/117 - 430s - loss: 6.1760 - cont_loss: 6.1760
Epoch 3/200
117/117 - 429s - loss: 6.0529 - cont_loss: 6.0529
Epoch 4/200
117/117 - 429s - loss: 5.9276 - cont_loss: 5.9276
Epoch 5/200
117/117 - 431s - loss: 5.8814 - cont_loss: 5.8814
Epoch 6/200
117/117 - 428s - loss: 5.8693 - cont_loss: 5.8693
Epoch 7/200
117/117 - 428s - loss: 5.8590 - cont_loss: 5.8590
Epoch 8/200
117/117 - 426s - loss: 5.8506 - cont_loss: 5.8506
Epoch 9/200
117/117 - 429s - loss: 5.8523 - cont_loss: 5.8523
Epoch 10/200
117/117 - 428s - loss: 5.8465 - cont_loss: 5.8465
Epoch 11/200
117/117 - 429s - loss: 5.8441 - cont_loss: 5.8441
Epoch 12/200
117/117 - 425s - loss: 5.8465 - cont_loss: 5.8465
Epoch 13/200
117/117 - 465s - loss: 5.8338 - cont_loss: 5.8338
Epoch 14/200
117/117 - 478s - loss: 5.8364 - cont_loss: 5.8364
Epoch 15/200
117/117 - 469s - loss: 5.8196 - cont_loss: 5.8196
Epoch 16/200
117/117 - 438s - loss: 5.8412 - cont_loss: 5.8412
Epoch 17/200
117/117 - 429s - loss: 5.8232 - cont_loss: 5.8232
Epoch 18/200
117/117 - 427s - loss: 5.8159 - cont_loss: 5.8159
Epoch 19/200
117/117 - 426s - loss: 5.8243 - cont_loss: 5.8243
Epoch 20/200
117/117 - 430s - loss: 5.8093 - cont_loss: 5.8093
Epoch 21/200
117/117 - 429s - loss: 5.8183 - cont_loss: 5.8183
Epoch 22/200
117/117 - 429s - loss: 5.7742 - cont_loss: 5.7742
Epoch 23/200
117/117 - 430s - loss: 5.6730 - cont_loss: 5.6730
Epoch 24/200
117/117 - 432s - loss: 5.6179 - cont_loss: 5.6179
Epoch 25/200
117/117 - 429s - loss: 5.5849 - cont_loss: 5.5849
Epoch 26/200
117/117 - 428s - loss: 5.5610 - cont_loss: 5.5610
Epoch 27/200
117/117 - 430s - loss: 5.5517 - cont_loss: 5.5517
Epoch 28/200
117/117 - 429s - loss: 5.5235 - cont_loss: 5.5235
Epoch 29/200
117/117 - 431s - loss: 5.5075 - cont_loss: 5.5075
Epoch 30/200
117/117 - 431s - loss: 5.5597 - cont_loss: 5.5597
Epoch 31/200
117/117 - 428s - loss: 5.4991 - cont_loss: 5.4991
Epoch 32/200
117/117 - 429s - loss: 5.4833 - cont_loss: 5.4833
Epoch 33/200
117/117 - 429s - loss: 5.4854 - cont_loss: 5.4854
Epoch 34/200
117/117 - 427s - loss: 5.5055 - cont_loss: 5.5055
Epoch 35/200
117/117 - 429s - loss: 5.6442 - cont_loss: 5.6442
Epoch 36/200
117/117 - 443s - loss: 5.5928 - cont_loss: 5.5928
Epoch 37/200
117/117 - 464s - loss: 5.5562 - cont_loss: 5.5562
Epoch 38/200
117/117 - 473s - loss: 5.5492 - cont_loss: 5.5492
Epoch 39/200
117/117 - 453s - loss: 5.5313 - cont_loss: 5.5313
Epoch 40/200
117/117 - 436s - loss: 5.5059 - cont_loss: 5.5059
Epoch 41/200
117/117 - 427s - loss: 5.5030 - cont_loss: 5.5030
Epoch 42/200
117/117 - 429s - loss: 5.4855 - cont_loss: 5.4855
Epoch 43/200
117/117 - 428s - loss: 5.4563 - cont_loss: 5.4563
Epoch 44/200
117/117 - 427s - loss: 5.4594 - cont_loss: 5.4594
Epoch 45/200
117/117 - 427s - loss: 5.4382 - cont_loss: 5.4382
Epoch 46/200
117/117 - 427s - loss: 5.4286 - cont_loss: 5.4286
Epoch 47/200
117/117 - 426s - loss: 5.4391 - cont_loss: 5.4391
Epoch 48/200
117/117 - 427s - loss: 5.4357 - cont_loss: 5.4357
Epoch 49/200
117/117 - 430s - loss: 5.3992 - cont_loss: 5.3992
Epoch 50/200
117/117 - 431s - loss: 5.4675 - cont_loss: 5.4675
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape_1:0", shape=(None,), dtype=int32), values=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape:0", shape=(None, None), dtype=float32), dense_shape=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
Epoch 51/200
Traceback (most recent call last):
  File "main_contrastive.py", line 140, in <module>
    run_experiment(cfg)
  File "main_contrastive.py", line 81, in run_experiment
    model.fit(train_generator, steps_per_epoch=int(len(Y)/(2*cfg['training']['batch_size'])), epochs=cfg['training']['epochs'], callbacks=callback_list, verbose=2)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 1100, in fit
    tmp_logs = self.train_function(iterator)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 828, in __call__
    result = self._call(*args, **kwds)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 855, in _call
    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/function.py", line 2942, in __call__
    return graph_function._call_flat(
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/function.py", line 1918, in _call_flat
    return self._build_call_outputs(self._inference_function.call(
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/function.py", line 555, in call
    outputs = execute.execute(
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/execute.py", line 59, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
KeyboardInterrupt
Terminated
Sender: LSF System <lsfadmin@eu-g2-19>
Subject: Job 232405369: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-10> by user <goezsoy> in cluster <euler> at Sun Sep 25 22:30:29 2022
Job was executed on host(s) <4*eu-g2-19>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Sun Sep 25 22:30:56 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Sun Sep 25 22:30:56 2022
Terminated at Mon Sep 26 02:16:03 2022
Results reported at Mon Sep 26 02:16:03 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

TERM_MEMLIMIT: job killed after reaching LSF memory usage limit.
Exited with exit code 137.

Resource usage summary:

    CPU time :                                   18383.96 sec.
    Max Memory :                                 16384 MB
    Average Memory :                             12340.51 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               0.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                31
    Run time :                                   13506 sec.
    Turnaround time :                            13534 sec.

The output (if any) follows:

2022-09-25 22:30:58.960321: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 22:31:16.867032: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-25 22:31:16.869088: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-25 22:31:16.916107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:1a:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-25 22:31:16.916148: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 22:31:16.920935: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 22:31:16.921006: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 22:31:16.922896: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-25 22:31:16.923750: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-25 22:31:16.927878: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-25 22:31:16.929213: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-25 22:31:16.931578: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 22:31:16.934710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-25 22:31:21.412004: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-25 22:31:21.412601: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-25 22:31:21.413509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:1a:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-25 22:31:21.413555: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 22:31:21.413604: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 22:31:21.413615: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 22:31:21.413625: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-25 22:31:21.413635: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-25 22:31:21.413645: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-25 22:31:21.413654: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-25 22:31:21.413665: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 22:31:21.414855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-25 22:31:21.418685: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 22:31:22.003928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-25 22:31:22.003965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-25 22:31:22.003971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-25 22:31:22.010545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1a:00.0, compute capability: 7.5)
2022-09-25 22:31:24.707394: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 22:31:26.714766: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 22:31:30.705979: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 22:31:45.773706: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-25 22:31:45.775235: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
cfg: {'experiment': {'name': '26_sep_layers10_s32_e128_latent512_128_temp01_onlycont_newaug0', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 200, 'num_constrains': 6000, 'batch_size': 256, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 50, 'lrs': True}, 'model': {'latent_dim': 128, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/200
117/117 - 445s - loss: 5.8310 - cont_loss: 5.8310
Epoch 2/200
117/117 - 446s - loss: 5.6264 - cont_loss: 5.6264
Epoch 3/200
117/117 - 455s - loss: 5.5058 - cont_loss: 5.5058
Epoch 4/200
117/117 - 453s - loss: 5.3975 - cont_loss: 5.3975
Epoch 5/200
117/117 - 452s - loss: 5.3040 - cont_loss: 5.3040
Epoch 6/200
117/117 - 450s - loss: 5.2351 - cont_loss: 5.2351
Epoch 7/200
117/117 - 449s - loss: 5.1726 - cont_loss: 5.1726
Epoch 8/200
117/117 - 449s - loss: 5.0953 - cont_loss: 5.0953
Epoch 9/200
117/117 - 444s - loss: 5.0371 - cont_loss: 5.0371
Epoch 10/200
117/117 - 444s - loss: 4.9815 - cont_loss: 4.9815
Epoch 11/200
117/117 - 449s - loss: 4.9236 - cont_loss: 4.9236
Epoch 12/200
117/117 - 445s - loss: 4.8943 - cont_loss: 4.8943
Epoch 13/200
117/117 - 445s - loss: 4.8393 - cont_loss: 4.8393
Epoch 14/200
117/117 - 445s - loss: 4.8076 - cont_loss: 4.8076
Epoch 15/200
117/117 - 444s - loss: 4.7959 - cont_loss: 4.7959
Epoch 16/200
117/117 - 444s - loss: 4.7855 - cont_loss: 4.7855
Epoch 17/200
117/117 - 442s - loss: 4.7501 - cont_loss: 4.7501
Epoch 18/200
117/117 - 446s - loss: 4.7341 - cont_loss: 4.7341
Epoch 19/200
117/117 - 445s - loss: 4.7258 - cont_loss: 4.7258
Epoch 20/200
117/117 - 440s - loss: 4.6738 - cont_loss: 4.6738
Epoch 21/200
117/117 - 425s - loss: 4.6635 - cont_loss: 4.6635
Epoch 22/200
117/117 - 437s - loss: 4.6671 - cont_loss: 4.6671
Epoch 23/200
117/117 - 430s - loss: 4.6275 - cont_loss: 4.6275
Epoch 24/200
117/117 - 429s - loss: 4.4816 - cont_loss: 4.4816
Epoch 25/200
117/117 - 431s - loss: 4.4164 - cont_loss: 4.4164
Epoch 26/200
117/117 - 430s - loss: 4.3465 - cont_loss: 4.3465
Epoch 27/200
117/117 - 433s - loss: 4.3056 - cont_loss: 4.3056
Epoch 28/200
117/117 - 428s - loss: 4.3066 - cont_loss: 4.3066
Epoch 29/200
117/117 - 429s - loss: 4.2766 - cont_loss: 4.2766
Epoch 30/200
117/117 - 467s - loss: 4.2649 - cont_loss: 4.2649
/cluster/shadow/.lsbatch/1664137829.232405369: line 8: 276617 Killed                  python main_contrastive.py --config ../config.yml
Sender: LSF System <lsfadmin@eu-g2-07>
Subject: Job 232405807: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-10> by user <goezsoy> in cluster <euler> at Sun Sep 25 22:49:25 2022
Job was executed on host(s) <4*eu-g2-07>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Sun Sep 25 22:49:32 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Sun Sep 25 22:49:32 2022
Terminated at Mon Sep 26 02:35:30 2022
Results reported at Mon Sep 26 02:35:30 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

TERM_MEMLIMIT: job killed after reaching LSF memory usage limit.
Exited with exit code 137.

Resource usage summary:

    CPU time :                                   18135.72 sec.
    Max Memory :                                 16384 MB
    Average Memory :                             12779.45 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               0.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                31
    Run time :                                   13557 sec.
    Turnaround time :                            13565 sec.

The output (if any) follows:

2022-09-25 22:49:35.953492: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 22:49:56.440317: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-25 22:49:56.446666: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-25 22:49:56.493787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:1b:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-25 22:49:56.493815: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 22:49:56.541875: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 22:49:56.542013: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 22:49:56.557086: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-25 22:49:56.564585: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-25 22:49:56.601485: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-25 22:49:56.609801: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-25 22:49:56.612858: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 22:49:56.616874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-25 22:50:01.118343: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-25 22:50:01.119132: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-25 22:50:01.120502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:1b:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-25 22:50:01.120568: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 22:50:01.120640: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 22:50:01.120675: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 22:50:01.120708: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-25 22:50:01.120741: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-25 22:50:01.120775: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-25 22:50:01.120808: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-25 22:50:01.120875: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 22:50:01.122915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-25 22:50:01.127207: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 22:50:03.718664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-25 22:50:03.718705: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-25 22:50:03.718716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-25 22:50:03.725463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1b:00.0, compute capability: 7.5)
2022-09-25 22:50:06.445180: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 22:50:08.402891: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 22:50:12.304393: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 22:50:27.113357: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-25 22:50:27.114777: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
cfg: {'experiment': {'name': '26_sep_layers10_s32_e128_latent512_128_temp01_onlycont_newaug2', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 200, 'num_constrains': 6000, 'batch_size': 256, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 50, 'lrs': True}, 'model': {'latent_dim': 128, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/200
117/117 - 425s - loss: 5.7880 - cont_loss: 5.7880
Epoch 2/200
117/117 - 421s - loss: 5.5095 - cont_loss: 5.5095
Epoch 3/200
117/117 - 422s - loss: 5.3247 - cont_loss: 5.3247
Epoch 4/200
117/117 - 422s - loss: 5.1962 - cont_loss: 5.1962
Epoch 5/200
117/117 - 420s - loss: 5.0920 - cont_loss: 5.0920
Epoch 6/200
117/117 - 420s - loss: 5.0099 - cont_loss: 5.0099
Epoch 7/200
117/117 - 419s - loss: 4.9355 - cont_loss: 4.9355
Epoch 8/200
117/117 - 420s - loss: 4.8291 - cont_loss: 4.8291
Epoch 9/200
117/117 - 419s - loss: 4.7753 - cont_loss: 4.7753
Epoch 10/200
117/117 - 419s - loss: 4.7265 - cont_loss: 4.7265
Epoch 11/200
117/117 - 419s - loss: 4.6725 - cont_loss: 4.6725
Epoch 12/200
117/117 - 420s - loss: 4.6045 - cont_loss: 4.6045
Epoch 13/200
117/117 - 419s - loss: 4.5055 - cont_loss: 4.5055
Epoch 14/200
117/117 - 419s - loss: 4.3894 - cont_loss: 4.3894
Epoch 15/200
117/117 - 420s - loss: 4.3317 - cont_loss: 4.3317
Epoch 16/200
117/117 - 419s - loss: 4.2825 - cont_loss: 4.2825
Epoch 17/200
117/117 - 420s - loss: 4.2332 - cont_loss: 4.2332
Epoch 18/200
117/117 - 425s - loss: 4.1550 - cont_loss: 4.1550
Epoch 19/200
117/117 - 425s - loss: 4.1515 - cont_loss: 4.1515
Epoch 20/200
117/117 - 426s - loss: 4.1033 - cont_loss: 4.1033
Epoch 21/200
117/117 - 427s - loss: 4.0886 - cont_loss: 4.0886
Epoch 22/200
117/117 - 430s - loss: 4.0423 - cont_loss: 4.0423
Epoch 23/200
117/117 - 434s - loss: 4.0237 - cont_loss: 4.0237
Epoch 24/200
117/117 - 432s - loss: 4.0084 - cont_loss: 4.0084
Epoch 25/200
117/117 - 434s - loss: 3.9634 - cont_loss: 3.9634
Epoch 26/200
117/117 - 434s - loss: 3.9695 - cont_loss: 3.9695
Epoch 27/200
117/117 - 437s - loss: 3.9315 - cont_loss: 3.9315
Epoch 28/200
117/117 - 436s - loss: 3.8994 - cont_loss: 3.8994
Epoch 29/200
117/117 - 438s - loss: 3.8963 - cont_loss: 3.8963
Epoch 30/200
117/117 - 436s - loss: 3.8850 - cont_loss: 3.8850
Epoch 31/200
117/117 - 436s - loss: 3.8433 - cont_loss: 3.8433
/cluster/shadow/.lsbatch/1664138965.232405807: line 8: 123501 Killed                  python main_contrastive.py --config ../config.yml
Sender: LSF System <lsfadmin@eu-g3-032>
Subject: Job 232406204: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-10> by user <goezsoy> in cluster <euler> at Sun Sep 25 23:03:10 2022
Job was executed on host(s) <4*eu-g3-032>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Sun Sep 25 23:03:31 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Sun Sep 25 23:03:31 2022
Terminated at Mon Sep 26 02:38:41 2022
Results reported at Mon Sep 26 02:38:41 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

TERM_MEMLIMIT: job killed after reaching LSF memory usage limit.
Exited with exit code 137.

Resource usage summary:

    CPU time :                                   14277.42 sec.
    Max Memory :                                 16384 MB
    Average Memory :                             12417.86 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               0.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                23
    Run time :                                   12910 sec.
    Turnaround time :                            12931 sec.

The output (if any) follows:

2022-09-25 23:03:33.957012: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 23:03:53.116125: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-25 23:03:53.122073: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-25 23:03:53.171706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:c1:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.62GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-25 23:03:53.171748: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 23:03:53.206729: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 23:03:53.206824: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 23:03:53.218536: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-25 23:03:53.232184: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-25 23:03:53.264507: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-25 23:03:53.275701: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-25 23:03:53.279909: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 23:03:53.286338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-25 23:03:57.261489: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-25 23:03:57.262642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:c1:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.62GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-25 23:03:57.262677: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 23:03:57.262711: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 23:03:57.262724: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 23:03:57.262736: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-25 23:03:57.262748: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-25 23:03:57.262759: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-25 23:03:57.262771: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-25 23:03:57.262783: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 23:03:57.264242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-25 23:03:57.267409: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 23:03:59.567961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-25 23:03:59.568040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-25 23:03:59.568052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-25 23:03:59.575804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:c1:00.0, compute capability: 7.5)
2022-09-25 23:04:02.041516: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 23:04:03.845526: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 23:04:07.600980: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 23:04:21.956049: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-25 23:04:21.957510: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2250030000 Hz
cfg: {'experiment': {'name': '26_sep_layers10_s32_e128_latent512_128_temp01_onlycont_newaug4', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 100, 'num_constrains': 6000, 'batch_size': 256, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 100, 'lrs': True}, 'model': {'latent_dim': 128, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/100
117/117 - 429s - loss: 5.8586 - cont_loss: 5.8586
Epoch 2/100
117/117 - 433s - loss: 5.6077 - cont_loss: 5.6077
Epoch 3/100
117/117 - 434s - loss: 5.4898 - cont_loss: 5.4898
Epoch 4/100
117/117 - 434s - loss: 5.3843 - cont_loss: 5.3843
Epoch 5/100
117/117 - 427s - loss: 5.3225 - cont_loss: 5.3225
Epoch 6/100
117/117 - 423s - loss: 5.2519 - cont_loss: 5.2519
Epoch 7/100
117/117 - 431s - loss: 5.1791 - cont_loss: 5.1791
Epoch 8/100
117/117 - 429s - loss: 5.1255 - cont_loss: 5.1255
Epoch 9/100
117/117 - 436s - loss: 5.0719 - cont_loss: 5.0719
Epoch 10/100
117/117 - 435s - loss: 5.0172 - cont_loss: 5.0172
Epoch 11/100
117/117 - 420s - loss: 4.9964 - cont_loss: 4.9964
Epoch 12/100
117/117 - 426s - loss: 4.9816 - cont_loss: 4.9816
Epoch 13/100
117/117 - 429s - loss: 4.9555 - cont_loss: 4.9555
Epoch 14/100
117/117 - 421s - loss: 4.9302 - cont_loss: 4.9302
Epoch 15/100
117/117 - 403s - loss: 4.9116 - cont_loss: 4.9116
Epoch 16/100
117/117 - 416s - loss: 4.7932 - cont_loss: 4.7932
Epoch 17/100
117/117 - 413s - loss: 4.7238 - cont_loss: 4.7238
Epoch 18/100
117/117 - 405s - loss: 4.6408 - cont_loss: 4.6408
Epoch 19/100
117/117 - 407s - loss: 4.5643 - cont_loss: 4.5643
Epoch 20/100
117/117 - 413s - loss: 4.5342 - cont_loss: 4.5342
Epoch 21/100
117/117 - 407s - loss: 4.4681 - cont_loss: 4.4681
Epoch 22/100
117/117 - 406s - loss: 4.4202 - cont_loss: 4.4202
Epoch 23/100
117/117 - 403s - loss: 4.2964 - cont_loss: 4.2964
Epoch 24/100
117/117 - 424s - loss: 4.2150 - cont_loss: 4.2150
Epoch 25/100
117/117 - 412s - loss: 4.1578 - cont_loss: 4.1578
Epoch 26/100
117/117 - 416s - loss: 4.1154 - cont_loss: 4.1154
Epoch 27/100
117/117 - 409s - loss: 4.0842 - cont_loss: 4.0842
Epoch 28/100
117/117 - 409s - loss: 4.0491 - cont_loss: 4.0491
Epoch 29/100
117/117 - 404s - loss: 4.0001 - cont_loss: 4.0001
Epoch 30/100
117/117 - 414s - loss: 3.9948 - cont_loss: 3.9948
/cluster/shadow/.lsbatch/1664139790.232406204: line 8: 68099 Killed                  python main_contrastive.py --config ../config.yml
Sender: LSF System <lsfadmin@eu-g2-20>
Subject: Job 232405687: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-10> by user <goezsoy> in cluster <euler> at Sun Sep 25 22:43:39 2022
Job was executed on host(s) <4*eu-g2-20>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Sun Sep 25 22:44:03 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Sun Sep 25 22:44:03 2022
Terminated at Mon Sep 26 02:47:49 2022
Results reported at Mon Sep 26 02:47:49 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

TERM_MEMLIMIT: job killed after reaching LSF memory usage limit.
Exited with exit code 137.

Resource usage summary:

    CPU time :                                   19186.04 sec.
    Max Memory :                                 16384 MB
    Average Memory :                             12128.60 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               0.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                31
    Run time :                                   14625 sec.
    Turnaround time :                            14650 sec.

The output (if any) follows:

2022-09-25 22:44:06.213359: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 22:44:20.699434: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-25 22:44:20.706829: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-25 22:44:20.747047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:da:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-25 22:44:20.747086: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 22:44:20.844229: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 22:44:20.844428: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 22:44:20.884545: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-25 22:44:20.919902: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-25 22:44:21.001326: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-25 22:44:21.034296: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-25 22:44:21.038994: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 22:44:21.043694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-25 22:44:25.627051: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-25 22:44:25.628186: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-25 22:44:25.629578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:da:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-25 22:44:25.629651: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 22:44:25.629723: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 22:44:25.629759: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 22:44:25.629809: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-25 22:44:25.629843: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-25 22:44:25.629877: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-25 22:44:25.629911: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-25 22:44:25.629946: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 22:44:25.631998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-25 22:44:25.640931: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 22:44:26.256121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-25 22:44:26.256156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-25 22:44:26.256163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-25 22:44:26.262879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:da:00.0, compute capability: 7.5)
2022-09-25 22:44:29.346970: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 22:44:31.363135: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 22:44:35.643623: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 22:44:50.735424: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-25 22:44:50.758424: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
cfg: {'experiment': {'name': '26_sep_layers10_s32_e128_latent512_128_temp01_onlycont_newaug1', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 150, 'num_constrains': 6000, 'batch_size': 256, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 50, 'lrs': True}, 'model': {'latent_dim': 128, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/150
117/117 - 476s - loss: 5.8729 - cont_loss: 5.8729
Epoch 2/150
117/117 - 472s - loss: 5.6132 - cont_loss: 5.6132
Epoch 3/150
117/117 - 469s - loss: 5.4909 - cont_loss: 5.4909
Epoch 4/150
117/117 - 465s - loss: 5.4087 - cont_loss: 5.4087
Epoch 5/150
117/117 - 467s - loss: 5.3513 - cont_loss: 5.3513
Epoch 6/150
117/117 - 470s - loss: 5.2847 - cont_loss: 5.2847
Epoch 7/150
117/117 - 469s - loss: 5.2103 - cont_loss: 5.2103
Epoch 8/150
117/117 - 467s - loss: 5.1431 - cont_loss: 5.1431
Epoch 9/150
117/117 - 467s - loss: 5.0830 - cont_loss: 5.0830
Epoch 10/150
117/117 - 470s - loss: 5.0646 - cont_loss: 5.0646
Epoch 11/150
117/117 - 470s - loss: 5.0164 - cont_loss: 5.0164
Epoch 12/150
117/117 - 467s - loss: 4.9820 - cont_loss: 4.9820
Epoch 13/150
117/117 - 468s - loss: 4.9614 - cont_loss: 4.9614
Epoch 14/150
117/117 - 468s - loss: 4.8745 - cont_loss: 4.8745
Epoch 15/150
117/117 - 468s - loss: 4.7485 - cont_loss: 4.7485
Epoch 16/150
117/117 - 464s - loss: 4.6395 - cont_loss: 4.6395
Epoch 17/150
117/117 - 471s - loss: 4.5867 - cont_loss: 4.5867
Epoch 18/150
117/117 - 469s - loss: 4.5433 - cont_loss: 4.5433
Epoch 19/150
117/117 - 472s - loss: 4.4675 - cont_loss: 4.4675
Epoch 20/150
117/117 - 471s - loss: 4.4505 - cont_loss: 4.4505
Epoch 21/150
117/117 - 468s - loss: 4.4214 - cont_loss: 4.4214
Epoch 22/150
117/117 - 467s - loss: 4.4040 - cont_loss: 4.4040
Epoch 23/150
117/117 - 468s - loss: 4.3518 - cont_loss: 4.3518
Epoch 24/150
117/117 - 467s - loss: 4.3300 - cont_loss: 4.3300
Epoch 25/150
117/117 - 470s - loss: 4.3115 - cont_loss: 4.3115
Epoch 26/150
117/117 - 466s - loss: 4.2689 - cont_loss: 4.2689
Epoch 27/150
117/117 - 467s - loss: 4.2530 - cont_loss: 4.2530
Epoch 28/150
117/117 - 472s - loss: 4.2257 - cont_loss: 4.2257
Epoch 29/150
117/117 - 471s - loss: 4.1740 - cont_loss: 4.1740
Epoch 30/150
117/117 - 464s - loss: 4.0466 - cont_loss: 4.0466
Epoch 31/150
117/117 - 468s - loss: 3.9891 - cont_loss: 3.9891
/cluster/shadow/.lsbatch/1664138619.232405687: line 8: 149919 Killed                  python main_contrastive.py --config ../config.yml
Sender: LSF System <lsfadmin@eu-g2-13>
Subject: Job 232407914: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-10> by user <goezsoy> in cluster <euler> at Sun Sep 25 23:19:32 2022
Job was executed on host(s) <4*eu-g2-13>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Sun Sep 25 23:20:01 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Sun Sep 25 23:20:01 2022
Terminated at Mon Sep 26 03:07:05 2022
Results reported at Mon Sep 26 03:07:05 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

TERM_MEMLIMIT: job killed after reaching LSF memory usage limit.
Exited with exit code 137.

Resource usage summary:

    CPU time :                                   18291.52 sec.
    Max Memory :                                 16384 MB
    Average Memory :                             11778.55 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               0.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                31
    Run time :                                   13623 sec.
    Turnaround time :                            13653 sec.

The output (if any) follows:

2022-09-25 23:20:04.057182: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 23:20:15.574600: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-25 23:20:15.600176: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-25 23:20:15.686936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:da:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-25 23:20:15.687040: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 23:20:15.708361: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 23:20:15.708526: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 23:20:15.724429: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-25 23:20:15.736484: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-25 23:20:15.760495: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-25 23:20:15.763156: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-25 23:20:15.766312: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 23:20:15.770703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-25 23:20:20.592636: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-25 23:20:20.596984: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-25 23:20:20.598559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:da:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-25 23:20:20.598644: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 23:20:20.598722: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 23:20:20.598758: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 23:20:20.598793: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-25 23:20:20.598828: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-25 23:20:20.598862: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-25 23:20:20.598894: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-25 23:20:20.598928: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 23:20:20.601218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-25 23:20:20.606094: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 23:20:21.213509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-25 23:20:21.213554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-25 23:20:21.213565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-25 23:20:21.229229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:da:00.0, compute capability: 7.5)
2022-09-25 23:20:24.104374: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 23:20:26.196649: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 23:20:30.287628: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 23:20:45.241677: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-25 23:20:45.256233: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
cfg: {'experiment': {'name': '26_sep_layers10_s32_e128_latent512_128_temp01_onlycont_newaug7', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 200, 'num_constrains': 6000, 'batch_size': 256, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 150, 'lrs': True}, 'model': {'latent_dim': 128, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/200
117/117 - 431s - loss: 5.7643 - cont_loss: 5.7643
Epoch 2/200
117/117 - 429s - loss: 5.4416 - cont_loss: 5.4416
Epoch 3/200
117/117 - 427s - loss: 5.2796 - cont_loss: 5.2796
Epoch 4/200
117/117 - 428s - loss: 5.1031 - cont_loss: 5.1031
Epoch 5/200
117/117 - 427s - loss: 4.9496 - cont_loss: 4.9496
Epoch 6/200
117/117 - 424s - loss: 4.7968 - cont_loss: 4.7968
Epoch 7/200
117/117 - 423s - loss: 4.6737 - cont_loss: 4.6737
Epoch 8/200
117/117 - 422s - loss: 4.5887 - cont_loss: 4.5887
Epoch 9/200
117/117 - 420s - loss: 4.5170 - cont_loss: 4.5170
Epoch 10/200
117/117 - 426s - loss: 4.4323 - cont_loss: 4.4323
Epoch 11/200
117/117 - 428s - loss: 4.3990 - cont_loss: 4.3990
Epoch 12/200
117/117 - 431s - loss: 4.3241 - cont_loss: 4.3241
Epoch 13/200
117/117 - 434s - loss: 4.2367 - cont_loss: 4.2367
Epoch 14/200
117/117 - 432s - loss: 4.1272 - cont_loss: 4.1272
Epoch 15/200
117/117 - 428s - loss: 4.0494 - cont_loss: 4.0494
Epoch 16/200
117/117 - 433s - loss: 4.0134 - cont_loss: 4.0134
Epoch 17/200
117/117 - 433s - loss: 3.9876 - cont_loss: 3.9876
Epoch 18/200
117/117 - 430s - loss: 3.9335 - cont_loss: 3.9335
Epoch 19/200
117/117 - 434s - loss: 3.9007 - cont_loss: 3.9007
Epoch 20/200
117/117 - 429s - loss: 3.8610 - cont_loss: 3.8610
Epoch 21/200
117/117 - 428s - loss: 3.7908 - cont_loss: 3.7908
Epoch 22/200
117/117 - 427s - loss: 3.7831 - cont_loss: 3.7831
Epoch 23/200
117/117 - 429s - loss: 3.7659 - cont_loss: 3.7659
Epoch 24/200
117/117 - 426s - loss: 3.7332 - cont_loss: 3.7332
Epoch 25/200
117/117 - 428s - loss: 3.6941 - cont_loss: 3.6941
Epoch 26/200
117/117 - 427s - loss: 3.6682 - cont_loss: 3.6682
Epoch 27/200
117/117 - 427s - loss: 3.6634 - cont_loss: 3.6634
Epoch 28/200
117/117 - 427s - loss: 3.6363 - cont_loss: 3.6363
Epoch 29/200
117/117 - 422s - loss: 3.6009 - cont_loss: 3.6009
Epoch 30/200
117/117 - 423s - loss: 3.6081 - cont_loss: 3.6081
Epoch 31/200
117/117 - 423s - loss: 3.5814 - cont_loss: 3.5814
/cluster/shadow/.lsbatch/1664140772.232407914: line 8: 192095 Killed                  python main_contrastive.py --config ../config.yml
Sender: LSF System <lsfadmin@eu-g2-20>
Subject: Job 232406988: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-10> by user <goezsoy> in cluster <euler> at Sun Sep 25 23:12:07 2022
Job was executed on host(s) <4*eu-g2-20>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Sun Sep 25 23:12:30 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Sun Sep 25 23:12:30 2022
Terminated at Mon Sep 26 03:12:43 2022
Results reported at Mon Sep 26 03:12:43 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

TERM_MEMLIMIT: job killed after reaching LSF memory usage limit.
Exited with exit code 137.

Resource usage summary:

    CPU time :                                   18955.24 sec.
    Max Memory :                                 16384 MB
    Average Memory :                             9851.96 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               0.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                31
    Run time :                                   14413 sec.
    Turnaround time :                            14436 sec.

The output (if any) follows:

2022-09-25 23:12:33.639504: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 23:12:40.883086: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-25 23:12:40.884768: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-25 23:12:40.921516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:db:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-25 23:12:40.921551: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 23:12:40.925803: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 23:12:40.925889: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 23:12:40.927754: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-25 23:12:40.928566: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-25 23:12:40.932187: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-25 23:12:40.933363: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-25 23:12:40.933861: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 23:12:40.934964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-25 23:12:43.029041: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-25 23:12:43.030016: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-25 23:12:43.030750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:db:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-25 23:12:43.030793: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 23:12:43.030831: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 23:12:43.030842: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 23:12:43.030852: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-25 23:12:43.030863: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-25 23:12:43.030873: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-25 23:12:43.030882: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-25 23:12:43.030893: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 23:12:43.031860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-25 23:12:43.031890: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 23:12:43.617726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-25 23:12:43.617768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-25 23:12:43.617776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-25 23:12:43.620213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:db:00.0, compute capability: 7.5)
2022-09-25 23:12:46.149939: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 23:12:46.710141: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 23:12:51.137956: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 23:12:54.199689: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-25 23:12:54.201116: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
cfg: {'experiment': {'name': '26_sep_layers10_s32_e128_latent512_128_temp01_onlycont_newaug5', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 120, 'num_constrains': 6000, 'batch_size': 256, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 100, 'lrs': True}, 'model': {'latent_dim': 128, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/120
117/117 - 476s - loss: 5.8074 - cont_loss: 5.8074
Epoch 2/120
117/117 - 475s - loss: 5.5680 - cont_loss: 5.5680
Epoch 3/120
117/117 - 473s - loss: 5.4686 - cont_loss: 5.4686
Epoch 4/120
117/117 - 473s - loss: 5.3601 - cont_loss: 5.3601
Epoch 5/120
117/117 - 472s - loss: 5.2702 - cont_loss: 5.2702
Epoch 6/120
117/117 - 472s - loss: 5.2229 - cont_loss: 5.2229
Epoch 7/120
117/117 - 470s - loss: 5.1373 - cont_loss: 5.1373
Epoch 8/120
117/117 - 471s - loss: 5.0968 - cont_loss: 5.0968
Epoch 9/120
117/117 - 473s - loss: 5.0749 - cont_loss: 5.0749
Epoch 10/120
117/117 - 472s - loss: 4.8657 - cont_loss: 4.8657
Epoch 11/120
117/117 - 469s - loss: 4.7923 - cont_loss: 4.7923
Epoch 12/120
117/117 - 474s - loss: 4.7058 - cont_loss: 4.7058
Epoch 13/120
117/117 - 472s - loss: 4.6428 - cont_loss: 4.6428
Epoch 14/120
117/117 - 474s - loss: 4.5752 - cont_loss: 4.5752
Epoch 15/120
117/117 - 477s - loss: 4.5394 - cont_loss: 4.5394
Epoch 16/120
117/117 - 477s - loss: 4.4968 - cont_loss: 4.4968
Epoch 17/120
117/117 - 470s - loss: 4.4516 - cont_loss: 4.4516
Epoch 18/120
117/117 - 470s - loss: 4.4303 - cont_loss: 4.4303
Epoch 19/120
117/117 - 473s - loss: 4.3823 - cont_loss: 4.3823
Epoch 20/120
117/117 - 472s - loss: 4.3506 - cont_loss: 4.3506
Epoch 21/120
117/117 - 469s - loss: 4.2668 - cont_loss: 4.2668
Epoch 22/120
117/117 - 469s - loss: 4.1552 - cont_loss: 4.1552
Epoch 23/120
117/117 - 473s - loss: 4.1078 - cont_loss: 4.1078
Epoch 24/120
117/117 - 471s - loss: 4.0529 - cont_loss: 4.0529
Epoch 25/120
117/117 - 471s - loss: 4.0476 - cont_loss: 4.0476
Epoch 26/120
117/117 - 469s - loss: 3.9854 - cont_loss: 3.9854
Epoch 27/120
117/117 - 472s - loss: 3.9756 - cont_loss: 3.9756
Epoch 28/120
117/117 - 480s - loss: 3.9305 - cont_loss: 3.9305
Epoch 29/120
117/117 - 477s - loss: 3.9356 - cont_loss: 3.9356
Epoch 30/120
117/117 - 472s - loss: 3.8993 - cont_loss: 3.8993
/cluster/shadow/.lsbatch/1664140327.232406988: line 8: 161993 Killed                  python main_contrastive.py --config ../config.yml
Sender: LSF System <lsfadmin@eu-g2-15>
Subject: Job 232406133: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-10> by user <goezsoy> in cluster <euler> at Sun Sep 25 22:57:42 2022
Job was executed on host(s) <4*eu-g2-15>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Sun Sep 25 22:58:01 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Sun Sep 25 22:58:01 2022
Terminated at Mon Sep 26 03:33:12 2022
Results reported at Mon Sep 26 03:33:12 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

TERM_MEMLIMIT: job killed after reaching LSF memory usage limit.
Exited with exit code 137.

Resource usage summary:

    CPU time :                                   22982.88 sec.
    Max Memory :                                 16384 MB
    Average Memory :                             10226.90 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               0.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                31
    Run time :                                   16510 sec.
    Turnaround time :                            16530 sec.

The output (if any) follows:

2022-09-25 22:58:04.723249: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 22:58:15.853046: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-25 22:58:15.854784: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-25 22:58:15.889916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:1a:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-25 22:58:15.889942: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 22:58:15.893736: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 22:58:15.893795: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 22:58:15.895504: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-25 22:58:15.896315: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-25 22:58:15.899829: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-25 22:58:15.900980: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-25 22:58:15.901441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 22:58:15.902486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-25 22:58:17.987257: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-25 22:58:17.987859: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-25 22:58:17.988605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:1a:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-25 22:58:17.988642: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 22:58:17.988683: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 22:58:17.988695: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 22:58:17.988705: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-25 22:58:17.988715: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-25 22:58:17.988726: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-25 22:58:17.988735: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-25 22:58:17.988746: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 22:58:17.989950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-25 22:58:17.989977: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 22:58:18.529117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-25 22:58:18.529156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-25 22:58:18.529163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-25 22:58:18.530904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1a:00.0, compute capability: 7.5)
2022-09-25 22:58:20.901196: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 22:58:21.406270: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 22:58:28.966574: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 22:58:32.505397: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-25 22:58:32.506782: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
cfg: {'experiment': {'name': '26_sep_layers10_s32_e128_latent512_128_temp01_onlycont_newaug3', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 200, 'num_constrains': 6000, 'batch_size': 512, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 50, 'lrs': True}, 'model': {'latent_dim': 128, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/200
58/58 - 347s - loss: 6.5478 - cont_loss: 6.5478
Epoch 2/200
58/58 - 344s - loss: 6.1931 - cont_loss: 6.1931
Epoch 3/200
58/58 - 344s - loss: 5.9640 - cont_loss: 5.9640
Epoch 4/200
58/58 - 345s - loss: 5.7875 - cont_loss: 5.7875
Epoch 5/200
58/58 - 346s - loss: 5.6565 - cont_loss: 5.6565
Epoch 6/200
58/58 - 362s - loss: 5.5196 - cont_loss: 5.5196
Epoch 7/200
58/58 - 372s - loss: 5.3507 - cont_loss: 5.3507
Epoch 8/200
58/58 - 384s - loss: 5.2479 - cont_loss: 5.2479
Epoch 9/200
58/58 - 382s - loss: 5.1264 - cont_loss: 5.1264
Epoch 10/200
58/58 - 354s - loss: 5.0232 - cont_loss: 5.0232
Epoch 11/200
58/58 - 352s - loss: 4.8972 - cont_loss: 4.8972
Epoch 12/200
58/58 - 343s - loss: 4.8119 - cont_loss: 4.8119
Epoch 13/200
58/58 - 344s - loss: 4.7011 - cont_loss: 4.7011
Epoch 14/200
58/58 - 341s - loss: 4.5987 - cont_loss: 4.5987
Epoch 15/200
58/58 - 343s - loss: 4.4829 - cont_loss: 4.4829
Epoch 16/200
58/58 - 344s - loss: 4.4340 - cont_loss: 4.4340
Epoch 17/200
58/58 - 344s - loss: 4.3626 - cont_loss: 4.3626
Epoch 18/200
58/58 - 344s - loss: 4.2783 - cont_loss: 4.2783
Epoch 19/200
58/58 - 345s - loss: 4.2207 - cont_loss: 4.2207
Epoch 20/200
58/58 - 347s - loss: 4.1848 - cont_loss: 4.1848
Epoch 21/200
58/58 - 345s - loss: 4.1143 - cont_loss: 4.1143
Epoch 22/200
58/58 - 349s - loss: 4.1049 - cont_loss: 4.1049
Epoch 23/200
58/58 - 345s - loss: 4.0746 - cont_loss: 4.0746
Epoch 24/200
58/58 - 352s - loss: 3.9810 - cont_loss: 3.9810
Epoch 25/200
58/58 - 356s - loss: 3.9545 - cont_loss: 3.9545
Epoch 26/200
58/58 - 357s - loss: 3.9539 - cont_loss: 3.9539
Epoch 27/200
58/58 - 356s - loss: 3.8677 - cont_loss: 3.8677
Epoch 28/200
58/58 - 354s - loss: 3.8589 - cont_loss: 3.8589
Epoch 29/200
58/58 - 356s - loss: 3.8410 - cont_loss: 3.8410
Epoch 30/200
58/58 - 355s - loss: 3.7983 - cont_loss: 3.7983
Epoch 31/200
58/58 - 357s - loss: 3.7732 - cont_loss: 3.7732
Epoch 32/200
58/58 - 355s - loss: 3.7398 - cont_loss: 3.7398
Epoch 33/200
58/58 - 356s - loss: 3.7148 - cont_loss: 3.7148
Epoch 34/200
58/58 - 356s - loss: 3.7179 - cont_loss: 3.7179
Epoch 35/200
58/58 - 369s - loss: 3.6695 - cont_loss: 3.6695
Epoch 36/200
58/58 - 388s - loss: 3.6374 - cont_loss: 3.6374
Epoch 37/200
58/58 - 399s - loss: 3.6370 - cont_loss: 3.6370
Epoch 38/200
58/58 - 397s - loss: 3.6084 - cont_loss: 3.6084
Epoch 39/200
58/58 - 370s - loss: 3.5500 - cont_loss: 3.5500
Epoch 40/200
58/58 - 367s - loss: 3.5167 - cont_loss: 3.5167
Epoch 41/200
58/58 - 355s - loss: 3.4806 - cont_loss: 3.4806
Epoch 42/200
58/58 - 359s - loss: 3.4850 - cont_loss: 3.4850
Epoch 43/200
58/58 - 355s - loss: 3.4268 - cont_loss: 3.4268
Epoch 44/200
58/58 - 358s - loss: 3.4420 - cont_loss: 3.4420
Epoch 45/200
58/58 - 354s - loss: 3.3781 - cont_loss: 3.3781
Epoch 46/200
58/58 - 357s - loss: 3.3905 - cont_loss: 3.3905
/cluster/shadow/.lsbatch/1664139462.232406133: line 8: 197862 Killed                  python main_contrastive.py --config ../config.yml
Sender: LSF System <lsfadmin@eu-g2-15>
Subject: Job 232407096: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-10> by user <goezsoy> in cluster <euler> at Sun Sep 25 23:15:28 2022
Job was executed on host(s) <4*eu-g2-15>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Sun Sep 25 23:16:02 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Sun Sep 25 23:16:02 2022
Terminated at Mon Sep 26 04:01:52 2022
Results reported at Mon Sep 26 04:01:52 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

TERM_MEMLIMIT: job killed after reaching LSF memory usage limit.
Exited with exit code 137.

Resource usage summary:

    CPU time :                                   23801.60 sec.
    Max Memory :                                 16384 MB
    Average Memory :                             9802.84 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               0.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                31
    Run time :                                   17150 sec.
    Turnaround time :                            17184 sec.

The output (if any) follows:

2022-09-25 23:16:04.621355: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 23:16:11.734395: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-25 23:16:11.735715: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-25 23:16:11.774696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:b1:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-25 23:16:11.774725: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 23:16:11.778674: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 23:16:11.778729: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 23:16:11.782824: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-25 23:16:11.784244: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-25 23:16:11.792941: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-25 23:16:11.794844: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-25 23:16:11.795514: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 23:16:11.797242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-25 23:16:13.899454: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-25 23:16:13.900656: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-25 23:16:13.902074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:b1:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-25 23:16:13.902150: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 23:16:13.902259: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 23:16:13.902299: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 23:16:13.902337: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-25 23:16:13.902374: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-25 23:16:13.902410: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-25 23:16:13.902446: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-25 23:16:13.902483: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 23:16:13.905137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-25 23:16:13.905218: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-25 23:16:14.466002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-25 23:16:14.466040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-25 23:16:14.466048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-25 23:16:14.467871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:b1:00.0, compute capability: 7.5)
2022-09-25 23:16:16.854683: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-25 23:16:17.346451: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-25 23:16:25.644065: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-25 23:16:29.215128: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-25 23:16:29.216500: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
cfg: {'experiment': {'name': '26_sep_layers10_s32_e128_latent512_128_temp01_onlycont_newaug6', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 200, 'num_constrains': 6000, 'batch_size': 512, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 150, 'lrs': True}, 'model': {'latent_dim': 128, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/200
58/58 - 363s - loss: 6.5884 - cont_loss: 6.5884
Epoch 2/200
58/58 - 357s - loss: 6.2955 - cont_loss: 6.2955
Epoch 3/200
58/58 - 367s - loss: 6.1827 - cont_loss: 6.1827
Epoch 4/200
58/58 - 378s - loss: 6.1433 - cont_loss: 6.1433
Epoch 5/200
58/58 - 408s - loss: 6.0426 - cont_loss: 6.0426
Epoch 6/200
58/58 - 405s - loss: 5.9945 - cont_loss: 5.9945
Epoch 7/200
58/58 - 394s - loss: 5.9173 - cont_loss: 5.9173
Epoch 8/200
58/58 - 362s - loss: 5.8836 - cont_loss: 5.8836
Epoch 9/200
58/58 - 356s - loss: 5.8196 - cont_loss: 5.8196
Epoch 10/200
58/58 - 361s - loss: 5.7760 - cont_loss: 5.7760
Epoch 11/200
58/58 - 358s - loss: 5.7118 - cont_loss: 5.7118
Epoch 12/200
58/58 - 355s - loss: 5.5979 - cont_loss: 5.5979
Epoch 13/200
58/58 - 358s - loss: 5.4628 - cont_loss: 5.4628
Epoch 14/200
58/58 - 356s - loss: 5.4248 - cont_loss: 5.4248
Epoch 15/200
58/58 - 362s - loss: 5.3496 - cont_loss: 5.3496
Epoch 16/200
58/58 - 361s - loss: 5.2800 - cont_loss: 5.2800
Epoch 17/200
58/58 - 358s - loss: 5.2234 - cont_loss: 5.2234
Epoch 18/200
58/58 - 357s - loss: 5.1090 - cont_loss: 5.1090
Epoch 19/200
58/58 - 367s - loss: 5.0246 - cont_loss: 5.0246
Epoch 20/200
58/58 - 376s - loss: 4.9565 - cont_loss: 4.9565
Epoch 21/200
58/58 - 363s - loss: 4.9209 - cont_loss: 4.9209
Epoch 22/200
58/58 - 365s - loss: 4.8535 - cont_loss: 4.8535
Epoch 23/200
58/58 - 366s - loss: 4.8280 - cont_loss: 4.8280
Epoch 24/200
58/58 - 365s - loss: 4.7484 - cont_loss: 4.7484
Epoch 25/200
58/58 - 363s - loss: 4.6782 - cont_loss: 4.6782
Epoch 26/200
58/58 - 367s - loss: 4.6338 - cont_loss: 4.6338
Epoch 27/200
58/58 - 361s - loss: 4.5792 - cont_loss: 4.5792
Epoch 28/200
58/58 - 365s - loss: 4.5198 - cont_loss: 4.5198
Epoch 29/200
58/58 - 367s - loss: 4.4427 - cont_loss: 4.4427
Epoch 30/200
58/58 - 362s - loss: 4.3936 - cont_loss: 4.3936
Epoch 31/200
58/58 - 375s - loss: 4.4092 - cont_loss: 4.4092
Epoch 32/200
58/58 - 375s - loss: 4.3920 - cont_loss: 4.3920
Epoch 33/200
58/58 - 412s - loss: 4.3655 - cont_loss: 4.3655
Epoch 34/200
58/58 - 412s - loss: 4.3267 - cont_loss: 4.3267
Epoch 35/200
58/58 - 401s - loss: 4.3049 - cont_loss: 4.3049
Epoch 36/200
58/58 - 377s - loss: 4.2659 - cont_loss: 4.2659
Epoch 37/200
58/58 - 366s - loss: 4.2463 - cont_loss: 4.2463
Epoch 38/200
58/58 - 365s - loss: 4.2288 - cont_loss: 4.2288
Epoch 39/200
58/58 - 364s - loss: 4.2298 - cont_loss: 4.2298
Epoch 40/200
58/58 - 365s - loss: 4.1775 - cont_loss: 4.1775
Epoch 41/200
58/58 - 366s - loss: 4.1796 - cont_loss: 4.1796
Epoch 42/200
58/58 - 368s - loss: 4.1679 - cont_loss: 4.1679
Epoch 43/200
58/58 - 370s - loss: 4.1523 - cont_loss: 4.1523
Epoch 44/200
58/58 - 360s - loss: 4.1275 - cont_loss: 4.1275
Epoch 45/200
58/58 - 372s - loss: 4.1149 - cont_loss: 4.1149
Epoch 46/200
58/58 - 363s - loss: 4.1053 - cont_loss: 4.1053
/cluster/shadow/.lsbatch/1664140528.232407096: line 8: 201157 Killed                  python main_contrastive.py --config ../config.yml
Sender: LSF System <lsfadmin@eu-g2-20>
Subject: Job 232430706: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-45> by user <goezsoy> in cluster <euler> at Mon Sep 26 14:18:42 2022
Job was executed on host(s) <4*eu-g2-20>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Mon Sep 26 14:18:47 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Mon Sep 26 14:18:47 2022
Terminated at Mon Sep 26 14:18:58 2022
Results reported at Mon Sep 26 14:18:58 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 143.

Resource usage summary:

    CPU time :                                   4.75 sec.
    Max Memory :                                 338 MB
    Average Memory :                             168.00 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               16046.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                4
    Run time :                                   10 sec.
    Turnaround time :                            16 sec.

The output (if any) follows:

2022-09-26 14:18:51.135508: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Terminated
Sender: LSF System <lsfadmin@eu-g2-07>
Subject: Job 232434162: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-45> by user <goezsoy> in cluster <euler> at Mon Sep 26 14:51:34 2022
Job was executed on host(s) <4*eu-g2-07>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Mon Sep 26 14:51:54 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Mon Sep 26 14:51:54 2022
Terminated at Mon Sep 26 20:21:09 2022
Results reported at Mon Sep 26 20:21:09 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   24284.82 sec.
    Max Memory :                                 14270 MB
    Average Memory :                             10977.00 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               2114.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                31
    Run time :                                   19754 sec.
    Turnaround time :                            19775 sec.

The output (if any) follows:

2022-09-26 14:51:58.752158: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-26 14:52:18.526651: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-26 14:52:18.532989: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-26 14:52:18.580738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:1b:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-26 14:52:18.580805: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-26 14:52:18.629332: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-26 14:52:18.629477: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-26 14:52:18.643391: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-26 14:52:18.651495: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-26 14:52:18.687107: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-26 14:52:18.695652: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-26 14:52:18.698409: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-26 14:52:18.701873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-26 14:52:23.238798: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-26 14:52:23.239492: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-26 14:52:23.241121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:1b:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-26 14:52:23.241188: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-26 14:52:23.241254: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-26 14:52:23.241290: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-26 14:52:23.241325: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-26 14:52:23.241358: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-26 14:52:23.241393: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-26 14:52:23.241427: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-26 14:52:23.241462: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-26 14:52:23.243515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-26 14:52:23.247365: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-26 14:52:25.881245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-26 14:52:25.881302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-26 14:52:25.881317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-26 14:52:25.888651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1b:00.0, compute capability: 7.5)
2022-09-26 14:52:28.608212: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-26 14:52:30.535956: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-26 14:52:32.503456: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-26 14:52:46.965486: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-26 14:52:46.967200: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
cfg: {'experiment': {'name': '26_sep_layers7_s32_e128_latent128_128_temp01_onlycont_newaug4', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 30, 'num_constrains': 6000, 'batch_size': 128, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 100, 'lrs': True}, 'model': {'latent_dim': 128, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/30
234/234 - 579s - loss: 4.8721 - cont_loss: 4.8721
Epoch 2/30
234/234 - 581s - loss: 4.4299 - cont_loss: 4.4299
Epoch 3/30
234/234 - 586s - loss: 4.1327 - cont_loss: 4.1327
Epoch 4/30
234/234 - 586s - loss: 3.9035 - cont_loss: 3.9035
Epoch 5/30
234/234 - 581s - loss: 3.6894 - cont_loss: 3.6894
Epoch 6/30
234/234 - 582s - loss: 3.5122 - cont_loss: 3.5122
Epoch 7/30
234/234 - 579s - loss: 3.3915 - cont_loss: 3.3915
Epoch 8/30
234/234 - 586s - loss: 3.2398 - cont_loss: 3.2398
Epoch 9/30
234/234 - 598s - loss: 3.0887 - cont_loss: 3.0887
Epoch 10/30
234/234 - 594s - loss: 2.9980 - cont_loss: 2.9980
Epoch 11/30
234/234 - 590s - loss: 2.8875 - cont_loss: 2.8875
Epoch 12/30
234/234 - 588s - loss: 2.7815 - cont_loss: 2.7815
Epoch 13/30
234/234 - 582s - loss: 2.7053 - cont_loss: 2.7053
Epoch 14/30
234/234 - 576s - loss: 2.6215 - cont_loss: 2.6215
Epoch 15/30
234/234 - 580s - loss: 2.5433 - cont_loss: 2.5433
Epoch 16/30
234/234 - 583s - loss: 2.4791 - cont_loss: 2.4791
Epoch 17/30
234/234 - 580s - loss: 2.4276 - cont_loss: 2.4276
Epoch 18/30
234/234 - 580s - loss: 2.4043 - cont_loss: 2.4043
Epoch 19/30
234/234 - 587s - loss: 2.3377 - cont_loss: 2.3377
Epoch 20/30
234/234 - 589s - loss: 2.3022 - cont_loss: 2.3022
Epoch 21/30
234/234 - 587s - loss: 2.2707 - cont_loss: 2.2707
Epoch 22/30
234/234 - 588s - loss: 2.2147 - cont_loss: 2.2147
Epoch 23/30
234/234 - 581s - loss: 2.1868 - cont_loss: 2.1868
Epoch 24/30
234/234 - 587s - loss: 2.1559 - cont_loss: 2.1559
Epoch 25/30
234/234 - 589s - loss: 2.1095 - cont_loss: 2.1095
Epoch 26/30
234/234 - 592s - loss: 2.0701 - cont_loss: 2.0701
Epoch 27/30
234/234 - 591s - loss: 2.0804 - cont_loss: 2.0804
Epoch 28/30
234/234 - 591s - loss: 2.0373 - cont_loss: 2.0373
Epoch 29/30
234/234 - 592s - loss: 2.0263 - cont_loss: 2.0263
Epoch 30/30
234/234 - 590s - loss: 1.9897 - cont_loss: 1.9897
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape_1:0", shape=(None,), dtype=int32), values=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape:0", shape=(None, None), dtype=float32), dense_shape=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
WARNING:tensorflow:Saver is deprecated, please switch to tf.train.Checkpoint or tf.keras.Model.save_weights for training checkpoints. When executing eagerly variables do not necessarily have unique names, and so the variable.name-based lookups Saver performs are error-prone.
Traceback (most recent call last):
  File "main_contrastive.py", line 140, in <module>
    run_experiment(cfg)
  File "main_contrastive.py", line 115, in run_experiment
    rec = model.predict(temp_X)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 1629, in predict
    tmp_batch_outputs = self.predict_function(iterator)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 828, in __call__
    result = self._call(*args, **kwds)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 871, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 725, in _initialize
    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/function.py", line 2969, in _get_concrete_function_internal_garbage_collected
    graph_function, _ = self._maybe_define_function(args, kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/function.py", line 3361, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/function.py", line 3196, in _create_graph_function
    func_graph_module.func_graph_from_py_func(
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/func_graph.py", line 990, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 634, in wrapped_fn
    out = weak_wrapped_fn().__wrapped__(*args, **kwds)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/func_graph.py", line 977, in wrapper
    raise e.ag_error_metadata.to_exception(e)
TypeError: in user code:

    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *
        return step_function(self, iterator)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica
        return fn(*args, **kwargs)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1463 run_step  **
        with ops.control_dependencies(_minimum_control_deps(outputs)):
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/ops.py:5359 control_dependencies
        return get_default_graph().control_dependencies(control_inputs)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/func_graph.py:362 control_dependencies
        return super(FuncGraph, self).control_dependencies(filtered_control_inputs)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/ops.py:4815 control_dependencies
        c = self.as_graph_element(c)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/ops.py:3726 as_graph_element
        return self._as_graph_element_locked(obj, allow_tensor, allow_operation)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/ops.py:3814 _as_graph_element_locked
        raise TypeError("Can not convert a %s into a %s." %

    TypeError: Can not convert a NoneType into a Tensor or Operation.

Sender: LSF System <lsfadmin@eu-g2-11>
Subject: Job 232430959: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-45> by user <goezsoy> in cluster <euler> at Mon Sep 26 14:20:25 2022
Job was executed on host(s) <4*eu-g2-11>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Mon Sep 26 14:20:46 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Mon Sep 26 14:20:46 2022
Terminated at Mon Sep 26 21:38:41 2022
Results reported at Mon Sep 26 21:38:41 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   32477.32 sec.
    Max Memory :                                 15079 MB
    Average Memory :                             10898.58 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               1305.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                31
    Run time :                                   26268 sec.
    Turnaround time :                            26296 sec.

The output (if any) follows:

2022-09-26 14:20:53.937165: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-26 14:21:06.302601: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-26 14:21:06.308420: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-26 14:21:06.350028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:db:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-26 14:21:06.350083: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-26 14:21:06.353923: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-26 14:21:06.353988: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-26 14:21:06.355816: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-26 14:21:06.356594: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-26 14:21:06.360293: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-26 14:21:06.361393: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-26 14:21:06.363790: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-26 14:21:06.366136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-26 14:21:10.820268: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-26 14:21:10.821164: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-26 14:21:10.822000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:db:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-26 14:21:10.822039: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-26 14:21:10.822094: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-26 14:21:10.822109: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-26 14:21:10.822123: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-26 14:21:10.822136: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-26 14:21:10.822148: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-26 14:21:10.822161: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-26 14:21:10.822174: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-26 14:21:10.823299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-26 14:21:10.827051: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-26 14:21:12.017702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-26 14:21:12.017746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-26 14:21:12.017756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-26 14:21:12.024137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:db:00.0, compute capability: 7.5)
2022-09-26 14:21:14.960358: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-26 14:21:17.818055: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-26 14:21:19.831860: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-26 14:21:34.312541: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-26 14:21:34.314186: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
cfg: {'experiment': {'name': '26_sep_layers7_s32_e128_latent128_128_temp01_onlycont_newaug3', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 20, 'num_constrains': 6000, 'batch_size': 128, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 100, 'lrs': True}, 'model': {'latent_dim': 128, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/20
468/468 - 1195s - loss: 4.6901 - cont_loss: 4.6901
Epoch 2/20
468/468 - 1193s - loss: 4.0754 - cont_loss: 4.0754
Epoch 3/20
468/468 - 1184s - loss: 3.6144 - cont_loss: 3.6144
Epoch 4/20
468/468 - 1186s - loss: 3.2441 - cont_loss: 3.2441
Epoch 5/20
468/468 - 1185s - loss: 2.9652 - cont_loss: 2.9652
Epoch 6/20
468/468 - 1184s - loss: 2.7646 - cont_loss: 2.7646
Epoch 7/20
468/468 - 1184s - loss: 2.6168 - cont_loss: 2.6168
Epoch 8/20
468/468 - 1199s - loss: 2.4549 - cont_loss: 2.4549
Epoch 9/20
468/468 - 1223s - loss: 2.3524 - cont_loss: 2.3524
Epoch 10/20
468/468 - 1208s - loss: 2.2595 - cont_loss: 2.2595
Epoch 11/20
468/468 - 1211s - loss: 2.1861 - cont_loss: 2.1861
Epoch 12/20
468/468 - 1190s - loss: 2.1300 - cont_loss: 2.1300
Epoch 13/20
468/468 - 1185s - loss: 2.0603 - cont_loss: 2.0603
Epoch 14/20
468/468 - 1216s - loss: 2.0231 - cont_loss: 2.0231
Epoch 15/20
468/468 - 1235s - loss: 1.9745 - cont_loss: 1.9745
Epoch 16/20
468/468 - 1231s - loss: 1.9194 - cont_loss: 1.9194
Epoch 17/20
468/468 - 1233s - loss: 1.8981 - cont_loss: 1.8981
Epoch 18/20
468/468 - 1253s - loss: 1.8268 - cont_loss: 1.8268
Epoch 19/20
468/468 - 1222s - loss: 1.8171 - cont_loss: 1.8171
Epoch 20/20
468/468 - 1192s - loss: 1.7867 - cont_loss: 1.7867
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape_1:0", shape=(None,), dtype=int32), values=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape:0", shape=(None, None), dtype=float32), dense_shape=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
WARNING:tensorflow:Saver is deprecated, please switch to tf.train.Checkpoint or tf.keras.Model.save_weights for training checkpoints. When executing eagerly variables do not necessarily have unique names, and so the variable.name-based lookups Saver performs are error-prone.
Traceback (most recent call last):
  File "main_contrastive.py", line 140, in <module>
    run_experiment(cfg)
  File "main_contrastive.py", line 115, in run_experiment
    rec = model.predict(temp_X)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 1629, in predict
    tmp_batch_outputs = self.predict_function(iterator)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 828, in __call__
    result = self._call(*args, **kwds)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 871, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 725, in _initialize
    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/function.py", line 2969, in _get_concrete_function_internal_garbage_collected
    graph_function, _ = self._maybe_define_function(args, kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/function.py", line 3361, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/function.py", line 3196, in _create_graph_function
    func_graph_module.func_graph_from_py_func(
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/func_graph.py", line 990, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 634, in wrapped_fn
    out = weak_wrapped_fn().__wrapped__(*args, **kwds)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/func_graph.py", line 977, in wrapper
    raise e.ag_error_metadata.to_exception(e)
TypeError: in user code:

    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *
        return step_function(self, iterator)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica
        return fn(*args, **kwargs)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1463 run_step  **
        with ops.control_dependencies(_minimum_control_deps(outputs)):
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/ops.py:5359 control_dependencies
        return get_default_graph().control_dependencies(control_inputs)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/func_graph.py:362 control_dependencies
        return super(FuncGraph, self).control_dependencies(filtered_control_inputs)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/ops.py:4815 control_dependencies
        c = self.as_graph_element(c)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/ops.py:3726 as_graph_element
        return self._as_graph_element_locked(obj, allow_tensor, allow_operation)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/ops.py:3814 _as_graph_element_locked
        raise TypeError("Can not convert a %s into a %s." %

    TypeError: Can not convert a NoneType into a Tensor or Operation.

Sender: LSF System <lsfadmin@eu-g3-044>
Subject: Job 232426647: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-45> by user <goezsoy> in cluster <euler> at Mon Sep 26 12:52:23 2022
Job was executed on host(s) <4*eu-g3-044>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Mon Sep 26 12:52:42 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Mon Sep 26 12:52:42 2022
Terminated at Mon Sep 26 21:38:54 2022
Results reported at Mon Sep 26 21:38:54 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

TERM_MEMLIMIT: job killed after reaching LSF memory usage limit.
Exited with exit code 137.

Resource usage summary:

    CPU time :                                   36373.58 sec.
    Max Memory :                                 16384 MB
    Average Memory :                             11997.47 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               0.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                23
    Run time :                                   31572 sec.
    Turnaround time :                            31591 sec.

The output (if any) follows:

2022-09-26 12:52:45.796108: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-26 12:52:56.891482: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-26 12:52:56.897324: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-26 12:52:56.946171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:41:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-26 12:52:56.946233: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-26 12:52:57.049372: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-26 12:52:57.049459: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-26 12:52:57.091048: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-26 12:52:57.128806: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-26 12:52:57.228773: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-26 12:52:57.269684: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-26 12:52:57.276428: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-26 12:52:57.281246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-26 12:53:01.239375: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-26 12:53:01.241189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:41:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-26 12:53:01.241243: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-26 12:53:01.241305: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-26 12:53:01.241334: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-26 12:53:01.241360: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-26 12:53:01.241385: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-26 12:53:01.241410: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-26 12:53:01.241435: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-26 12:53:01.241460: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-26 12:53:01.244091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-26 12:53:01.247964: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-26 12:53:03.592866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-26 12:53:03.592950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-26 12:53:03.592964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-26 12:53:03.601448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:41:00.0, compute capability: 7.5)
2022-09-26 12:53:05.908904: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-26 12:53:07.601057: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-26 12:53:09.607175: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-26 12:53:23.338510: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-26 12:53:23.340158: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2250000000 Hz
cfg: {'experiment': {'name': '26_sep_layers7_s32_e128_latent128_128_temp01_onlycont_newaug', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 100, 'num_constrains': 6000, 'batch_size': 128, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 100, 'lrs': True}, 'model': {'latent_dim': 128, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/100
234/234 - 514s - loss: 4.8864 - cont_loss: 4.8864
Epoch 2/100
234/234 - 517s - loss: 4.4994 - cont_loss: 4.4994
Epoch 3/100
234/234 - 521s - loss: 4.1885 - cont_loss: 4.1885
Epoch 4/100
234/234 - 518s - loss: 3.8810 - cont_loss: 3.8810
Epoch 5/100
234/234 - 517s - loss: 3.6500 - cont_loss: 3.6500
Epoch 6/100
234/234 - 516s - loss: 3.4860 - cont_loss: 3.4860
Epoch 7/100
234/234 - 513s - loss: 3.2962 - cont_loss: 3.2962
Epoch 8/100
234/234 - 511s - loss: 3.1851 - cont_loss: 3.1851
Epoch 9/100
234/234 - 513s - loss: 3.0355 - cont_loss: 3.0355
Epoch 10/100
234/234 - 513s - loss: 2.9133 - cont_loss: 2.9133
Epoch 11/100
234/234 - 510s - loss: 2.8409 - cont_loss: 2.8409
Epoch 12/100
234/234 - 508s - loss: 2.7308 - cont_loss: 2.7308
Epoch 13/100
234/234 - 511s - loss: 2.6516 - cont_loss: 2.6516
Epoch 14/100
234/234 - 490s - loss: 2.5943 - cont_loss: 2.5943
Epoch 15/100
234/234 - 486s - loss: 2.5465 - cont_loss: 2.5465
Epoch 16/100
234/234 - 483s - loss: 2.4813 - cont_loss: 2.4813
Epoch 17/100
234/234 - 491s - loss: 2.4152 - cont_loss: 2.4152
Epoch 18/100
234/234 - 493s - loss: 2.3862 - cont_loss: 2.3862
Epoch 19/100
234/234 - 497s - loss: 2.3207 - cont_loss: 2.3207
Epoch 20/100
234/234 - 499s - loss: 2.2692 - cont_loss: 2.2692
Epoch 21/100
234/234 - 496s - loss: 2.2390 - cont_loss: 2.2390
Epoch 22/100
234/234 - 496s - loss: 2.2118 - cont_loss: 2.2118
Epoch 23/100
234/234 - 489s - loss: 2.1900 - cont_loss: 2.1900
Epoch 24/100
234/234 - 485s - loss: 2.1609 - cont_loss: 2.1609
Epoch 25/100
234/234 - 488s - loss: 2.1402 - cont_loss: 2.1402
Epoch 26/100
234/234 - 494s - loss: 2.1107 - cont_loss: 2.1107
Epoch 27/100
234/234 - 489s - loss: 2.0564 - cont_loss: 2.0564
Epoch 28/100
234/234 - 483s - loss: 1.9975 - cont_loss: 1.9975
Epoch 29/100
234/234 - 496s - loss: 2.0149 - cont_loss: 2.0149
Epoch 30/100
234/234 - 500s - loss: 1.9987 - cont_loss: 1.9987
Epoch 31/100
234/234 - 486s - loss: 1.9671 - cont_loss: 1.9671
Epoch 32/100
234/234 - 481s - loss: 1.9336 - cont_loss: 1.9336
Epoch 33/100
234/234 - 503s - loss: 1.9229 - cont_loss: 1.9229
Epoch 34/100
234/234 - 496s - loss: 1.9241 - cont_loss: 1.9241
Epoch 35/100
234/234 - 496s - loss: 1.8869 - cont_loss: 1.8869
Epoch 36/100
234/234 - 502s - loss: 1.8694 - cont_loss: 1.8694
Epoch 37/100
234/234 - 503s - loss: 1.8272 - cont_loss: 1.8272
Epoch 38/100
234/234 - 504s - loss: 1.8250 - cont_loss: 1.8250
Epoch 39/100
234/234 - 503s - loss: 1.8215 - cont_loss: 1.8215
Epoch 40/100
234/234 - 504s - loss: 1.8035 - cont_loss: 1.8035
Epoch 41/100
234/234 - 507s - loss: 1.7749 - cont_loss: 1.7749
Epoch 42/100
234/234 - 509s - loss: 1.7595 - cont_loss: 1.7595
Epoch 43/100
234/234 - 514s - loss: 1.7370 - cont_loss: 1.7370
Epoch 44/100
234/234 - 512s - loss: 1.7575 - cont_loss: 1.7575
Epoch 45/100
234/234 - 516s - loss: 1.7358 - cont_loss: 1.7358
Epoch 46/100
234/234 - 520s - loss: 1.7266 - cont_loss: 1.7266
Epoch 47/100
234/234 - 518s - loss: 1.7126 - cont_loss: 1.7126
Epoch 48/100
234/234 - 518s - loss: 1.6695 - cont_loss: 1.6695
Epoch 49/100
234/234 - 516s - loss: 1.6816 - cont_loss: 1.6816
Epoch 50/100
234/234 - 509s - loss: 1.6585 - cont_loss: 1.6585
Epoch 51/100
234/234 - 504s - loss: 1.6675 - cont_loss: 1.6675
Epoch 52/100
234/234 - 507s - loss: 1.6474 - cont_loss: 1.6474
Epoch 53/100
234/234 - 510s - loss: 1.6410 - cont_loss: 1.6410
Epoch 54/100
234/234 - 508s - loss: 1.6399 - cont_loss: 1.6399
Epoch 55/100
234/234 - 503s - loss: 1.6157 - cont_loss: 1.6157
Epoch 56/100
234/234 - 501s - loss: 1.6327 - cont_loss: 1.6327
Epoch 57/100
234/234 - 501s - loss: 1.6103 - cont_loss: 1.6103
Epoch 58/100
234/234 - 501s - loss: 1.6031 - cont_loss: 1.6031
Epoch 59/100
234/234 - 506s - loss: 1.5889 - cont_loss: 1.5889
Epoch 60/100
234/234 - 506s - loss: 1.5926 - cont_loss: 1.5926
Epoch 61/100
234/234 - 504s - loss: 1.5703 - cont_loss: 1.5703
Epoch 62/100
234/234 - 495s - loss: 1.5671 - cont_loss: 1.5671
/cluster/shadow/.lsbatch/1664189543.232426647: line 8: 44653 Killed                  python main_contrastive.py --config ../config.yml
Sender: LSF System <lsfadmin@eu-g2-11>
Subject: Job 232462384: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-30> by user <goezsoy> in cluster <euler> at Mon Sep 26 23:46:08 2022
Job was executed on host(s) <4*eu-g2-11>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Mon Sep 26 23:46:36 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Mon Sep 26 23:46:36 2022
Terminated at Mon Sep 26 23:46:48 2022
Results reported at Mon Sep 26 23:46:48 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   6.01 sec.
    Max Memory :                                 546 MB
    Average Memory :                             450.00 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               15838.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                4
    Run time :                                   12 sec.
    Turnaround time :                            40 sec.

The output (if any) follows:

2022-09-26 23:46:39.990250: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
Traceback (most recent call last):
  File "main_contrastive.py", line 21, in <module>
    import utils
  File "/cluster/home/goezsoy/constrastive-DC-GMM/src/utils.py", line 24, in <module>
    from model import DCGMM
  File "/cluster/home/goezsoy/constrastive-DC-GMM/src/model.py", line 2, in <module>
    import tensorflow_probability as tfp
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow_probability/__init__.py", line 20, in <module>
    from tensorflow_probability import substrates
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow_probability/substrates/__init__.py", line 21, in <module>
    from tensorflow_probability.python.internal import all_util
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow_probability/python/__init__.py", line 142, in <module>
    dir(globals()[pkg_name])  # Forces loading the package from its lazy loader.
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow_probability/python/internal/lazy_loader.py", line 61, in __dir__
    module = self._load()
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow_probability/python/internal/lazy_loader.py", line 41, in _load
    self._on_first_access()
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow_probability/python/__init__.py", line 42, in _validate_tf_environment
    import tensorflow.compat.v1 as tf
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/_api/v2/compat/__init__.py", line 39, in <module>
    from . import v1
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/_api/v2/compat/v1/__init__.py", line 52, in <module>
    from . import logging
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 874, in get_code
  File "<frozen importlib._bootstrap_external>", line 972, in get_data
KeyboardInterrupt
Sender: LSF System <lsfadmin@eu-g2-20>
Subject: Job 232462385: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-30> by user <goezsoy> in cluster <euler> at Mon Sep 26 23:46:08 2022
Job was executed on host(s) <4*eu-g2-20>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Mon Sep 26 23:46:36 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Mon Sep 26 23:46:36 2022
Terminated at Mon Sep 26 23:46:52 2022
Results reported at Mon Sep 26 23:46:52 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   8.50 sec.
    Max Memory :                                 780 MB
    Average Memory :                             568.67 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               15604.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                5
    Run time :                                   16 sec.
    Turnaround time :                            44 sec.

The output (if any) follows:

2022-09-26 23:46:40.066412: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-26 23:46:50.502637: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-26 23:46:50.504923: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-26 23:46:50.550381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:db:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-26 23:46:50.550417: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-26 23:46:50.646567: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-26 23:46:50.646777: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-26 23:46:50.686558: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-26 23:46:50.721466: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-26 23:46:50.802828: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-26 23:46:50.835410: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-26 23:46:50.839856: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-26 23:46:50.845918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
cfg: {'experiment': {'name': '27_sep_layers7_s32_e128_latent128_128_temp01_onlycont_newaug', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 20, 'num_constrains': 6000, 'batch_size': 64, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 100, 'lrs': True}, 'model': {'latent_dim': 128, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Traceback (most recent call last):
  File "main_contrastive.py", line 162, in <module>
    run_experiment(cfg)
  File "main_contrastive.py", line 52, in run_experiment
    x_train, x_test, y_train, y_test = utils.get_data(cfg)
  File "/cluster/home/goezsoy/constrastive-DC-GMM/src/utils.py", line 96, in get_data
    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/datasets/cifar10.py", line 52, in load_data
    path = get_file(
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/utils/data_utils.py", line 247, in get_file
    if not validate_file(fpath, file_hash, algorithm=hash_algorithm):
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/utils/data_utils.py", line 359, in validate_file
    if str(_hash_file(fpath, hasher, chunk_size)) == str(file_hash):
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/utils/data_utils.py", line 334, in _hash_file
    for chunk in iter(lambda: fpath_file.read(chunk_size), b''):
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/utils/data_utils.py", line 334, in <lambda>
    for chunk in iter(lambda: fpath_file.read(chunk_size), b''):
KeyboardInterrupt
Sender: LSF System <lsfadmin@eu-g2-15>
Subject: Job 232462379: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-30> by user <goezsoy> in cluster <euler> at Mon Sep 26 23:46:08 2022
Job was executed on host(s) <4*eu-g2-15>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Mon Sep 26 23:46:36 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Mon Sep 26 23:46:36 2022
Terminated at Mon Sep 26 23:46:53 2022
Results reported at Mon Sep 26 23:46:53 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   7.96 sec.
    Max Memory :                                 971 MB
    Average Memory :                             146.00 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               15413.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                4
    Run time :                                   16 sec.
    Turnaround time :                            45 sec.

The output (if any) follows:

2022-09-26 23:46:39.933909: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
Traceback (most recent call last):
  File "main_contrastive.py", line 162, in <module>
    run_experiment(cfg)
  File "main_contrastive.py", line 42, in run_experiment
    Path(experiment_path).mkdir(parents=True)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/pathlib.py", line 1284, in mkdir
    self._accessor.mkdir(self, mode)
FileExistsError: [Errno 17] File exists: '../logs/CIFAR10/27_sep_layers7_s32_e128_latent128_128_temp01_onlycont_newaug'
Sender: LSF System <lsfadmin@eu-g3-039>
Subject: Job 232467656: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-30> by user <goezsoy> in cluster <euler> at Tue Sep 27 00:04:04 2022
Job was executed on host(s) <4*eu-g3-039>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Tue Sep 27 00:04:35 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Tue Sep 27 00:04:35 2022
Terminated at Tue Sep 27 00:24:31 2022
Results reported at Tue Sep 27 00:24:31 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   1178.20 sec.
    Max Memory :                                 7583 MB
    Average Memory :                             6978.88 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               8801.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                23
    Run time :                                   1196 sec.
    Turnaround time :                            1227 sec.

The output (if any) follows:

2022-09-27 00:04:38.928181: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-27 00:04:56.205624: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-27 00:04:56.212066: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-27 00:04:56.261388: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:21:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-27 00:04:56.261449: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-27 00:04:56.265813: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-27 00:04:56.265852: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-27 00:04:56.268093: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-27 00:04:56.269483: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-27 00:04:56.363810: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-27 00:04:56.376324: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-27 00:04:56.377607: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-27 00:04:56.384396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-27 00:05:00.137998: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-27 00:05:00.141776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:21:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-27 00:05:00.141820: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-27 00:05:00.141862: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-27 00:05:00.141884: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-27 00:05:00.141903: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-27 00:05:00.141922: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-27 00:05:00.141940: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-27 00:05:00.141959: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-27 00:05:00.141977: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-27 00:05:00.143680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-27 00:05:00.147348: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-27 00:05:02.340970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-27 00:05:02.341039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-27 00:05:02.341052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-27 00:05:02.348747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:21:00.0, compute capability: 7.5)
2022-09-27 00:05:04.575863: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-27 00:05:04.934837: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-27 00:05:06.974375: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-27 00:05:10.672684: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-27 00:05:10.674864: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2250045000 Hz
cfg: {'experiment': {'name': '27_sep_layers7_s32_e128_latent128_128_temp01_onlycont_newaug_perf', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 1, 'num_constrains': 6000, 'batch_size': 128, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 100, 'lrs': True}, 'model': {'latent_dim': 128, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
5/5 - 11s - loss: 5.5362 - cont_loss: 5.5362
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape_1:0", shape=(None,), dtype=int32), values=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape:0", shape=(None, None), dtype=float32), dense_shape=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:124: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
WARNING:tensorflow:Saver is deprecated, please switch to tf.train.Checkpoint or tf.keras.Model.save_weights for training checkpoints. When executing eagerly variables do not necessarily have unique names, and so the variable.name-based lookups Saver performs are error-prone.
pretrain accuracy: 0.14888333333333334
Traceback (most recent call last):
  File "main_contrastive.py", line 155, in <module>
    run_experiment(cfg)
  File "main_contrastive.py", line 130, in run_experiment
    rec = model.predict(temp_X)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 1629, in predict
    tmp_batch_outputs = self.predict_function(iterator)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 828, in __call__
    result = self._call(*args, **kwds)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 871, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 725, in _initialize
    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/function.py", line 2969, in _get_concrete_function_internal_garbage_collected
    graph_function, _ = self._maybe_define_function(args, kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/function.py", line 3361, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/function.py", line 3196, in _create_graph_function
    func_graph_module.func_graph_from_py_func(
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/func_graph.py", line 990, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 634, in wrapped_fn
    out = weak_wrapped_fn().__wrapped__(*args, **kwds)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/func_graph.py", line 977, in wrapper
    raise e.ag_error_metadata.to_exception(e)
TypeError: in user code:

    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *
        return step_function(self, iterator)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica
        return fn(*args, **kwargs)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1463 run_step  **
        with ops.control_dependencies(_minimum_control_deps(outputs)):
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/ops.py:5359 control_dependencies
        return get_default_graph().control_dependencies(control_inputs)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/func_graph.py:362 control_dependencies
        return super(FuncGraph, self).control_dependencies(filtered_control_inputs)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/ops.py:4815 control_dependencies
        c = self.as_graph_element(c)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/ops.py:3726 as_graph_element
        return self._as_graph_element_locked(obj, allow_tensor, allow_operation)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/ops.py:3814 _as_graph_element_locked
        raise TypeError("Can not convert a %s into a %s." %

    TypeError: Can not convert a NoneType into a Tensor or Operation.

Sender: LSF System <lsfadmin@eu-g3-021>
Subject: Job 232472207: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-30> by user <goezsoy> in cluster <euler> at Tue Sep 27 00:26:04 2022
Job was executed on host(s) <4*eu-g3-021>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Tue Sep 27 00:26:36 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Tue Sep 27 00:26:36 2022
Terminated at Tue Sep 27 00:51:26 2022
Results reported at Tue Sep 27 00:51:26 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   1502.10 sec.
    Max Memory :                                 7577 MB
    Average Memory :                             6408.96 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               8807.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                23
    Run time :                                   1490 sec.
    Turnaround time :                            1522 sec.

The output (if any) follows:

2022-09-27 00:26:39.008281: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-27 00:26:55.940153: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-27 00:26:55.945343: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-27 00:26:55.993514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:c2:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-27 00:26:55.993569: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-27 00:26:56.037679: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-27 00:26:56.037772: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-27 00:26:56.079940: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-27 00:26:56.117356: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-27 00:26:56.216066: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-27 00:26:56.258435: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-27 00:26:56.262807: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-27 00:26:56.269005: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-27 00:27:00.262606: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-27 00:27:00.263847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:c2:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-27 00:27:00.263889: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-27 00:27:00.263929: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-27 00:27:00.263956: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-27 00:27:00.263973: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-27 00:27:00.263989: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-27 00:27:00.264005: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-27 00:27:00.264020: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-27 00:27:00.264036: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-27 00:27:00.265685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-27 00:27:00.269352: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-27 00:27:02.513915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-27 00:27:02.513999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-27 00:27:02.514010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-27 00:27:02.518829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:c2:00.0, compute capability: 7.5)
2022-09-27 00:27:05.512847: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-27 00:27:07.179383: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-27 00:27:10.329301: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-27 00:27:14.042635: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-27 00:27:14.044616: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2250025000 Hz
cfg: {'experiment': {'name': '27_sep_layers7_s32_e128_latent128_128_temp01_onlycont_newaug_perf', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 15, 'num_constrains': 6000, 'batch_size': 128, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 100, 'lrs': True}, 'model': {'latent_dim': 128, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/15
5/5 - 15s - loss: 5.5835 - cont_loss: 5.5835
Epoch 2/15
5/5 - 14s - loss: 5.2545 - cont_loss: 5.2545
Epoch 3/15
5/5 - 14s - loss: 5.2711 - cont_loss: 5.2711
Epoch 4/15
5/5 - 14s - loss: 5.1786 - cont_loss: 5.1786
Epoch 5/15
5/5 - 14s - loss: 5.1554 - cont_loss: 5.1554
Epoch 6/15
5/5 - 14s - loss: 5.1206 - cont_loss: 5.1206
Epoch 7/15
5/5 - 14s - loss: 4.9956 - cont_loss: 4.9956
Epoch 8/15
5/5 - 14s - loss: 5.0171 - cont_loss: 5.0171
Epoch 9/15
5/5 - 14s - loss: 5.0322 - cont_loss: 5.0322
Epoch 10/15
5/5 - 14s - loss: 5.0110 - cont_loss: 5.0110
Epoch 11/15
5/5 - 14s - loss: 5.0311 - cont_loss: 5.0311
Epoch 12/15
5/5 - 14s - loss: 4.9350 - cont_loss: 4.9350
Epoch 13/15
5/5 - 14s - loss: 4.9452 - cont_loss: 4.9452
Epoch 14/15
5/5 - 14s - loss: 4.8930 - cont_loss: 4.8930
Epoch 15/15
5/5 - 14s - loss: 4.9917 - cont_loss: 4.9917
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape_1:0", shape=(None,), dtype=int32), values=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape:0", shape=(None, None), dtype=float32), dense_shape=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:124: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
WARNING:tensorflow:Saver is deprecated, please switch to tf.train.Checkpoint or tf.keras.Model.save_weights for training checkpoints. When executing eagerly variables do not necessarily have unique names, and so the variable.name-based lookups Saver performs are error-prone.
pretrain accuracy: 0.20605
Traceback (most recent call last):
  File "main_contrastive.py", line 155, in <module>
    run_experiment(cfg)
  File "main_contrastive.py", line 130, in run_experiment
    rec = model.predict(temp_X)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 1629, in predict
    tmp_batch_outputs = self.predict_function(iterator)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 828, in __call__
    result = self._call(*args, **kwds)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 871, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 725, in _initialize
    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/function.py", line 2969, in _get_concrete_function_internal_garbage_collected
    graph_function, _ = self._maybe_define_function(args, kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/function.py", line 3361, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/function.py", line 3196, in _create_graph_function
    func_graph_module.func_graph_from_py_func(
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/func_graph.py", line 990, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 634, in wrapped_fn
    out = weak_wrapped_fn().__wrapped__(*args, **kwds)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/func_graph.py", line 977, in wrapper
    raise e.ag_error_metadata.to_exception(e)
TypeError: in user code:

    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *
        return step_function(self, iterator)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica
        return fn(*args, **kwargs)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1463 run_step  **
        with ops.control_dependencies(_minimum_control_deps(outputs)):
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/ops.py:5359 control_dependencies
        return get_default_graph().control_dependencies(control_inputs)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/func_graph.py:362 control_dependencies
        return super(FuncGraph, self).control_dependencies(filtered_control_inputs)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/ops.py:4815 control_dependencies
        c = self.as_graph_element(c)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/ops.py:3726 as_graph_element
        return self._as_graph_element_locked(obj, allow_tensor, allow_operation)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/ops.py:3814 _as_graph_element_locked
        raise TypeError("Can not convert a %s into a %s." %

    TypeError: Can not convert a NoneType into a Tensor or Operation.

Sender: LSF System <lsfadmin@eu-g2-04>
Subject: Job 232427890: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-45> by user <goezsoy> in cluster <euler> at Mon Sep 26 13:33:19 2022
Job was executed on host(s) <4*eu-g2-04>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Mon Sep 26 13:33:42 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Mon Sep 26 13:33:42 2022
Terminated at Tue Sep 27 03:39:14 2022
Results reported at Tue Sep 27 03:39:14 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

TERM_MEMLIMIT: job killed after reaching LSF memory usage limit.
Exited with exit code 137.

Resource usage summary:

    CPU time :                                   59723.31 sec.
    Max Memory :                                 16384 MB
    Average Memory :                             12100.58 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               0.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                31
    Run time :                                   50731 sec.
    Turnaround time :                            50755 sec.

The output (if any) follows:

2022-09-26 13:33:44.978965: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-26 13:33:54.245110: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-26 13:33:54.246710: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-26 13:33:54.290553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:db:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-26 13:33:54.290597: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-26 13:33:54.367551: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-26 13:33:54.367748: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-26 13:33:54.390554: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-26 13:33:54.415282: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-26 13:33:54.467907: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-26 13:33:54.491755: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-26 13:33:54.494658: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-26 13:33:54.498290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-26 13:33:59.063047: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-26 13:33:59.067604: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-26 13:33:59.068413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:db:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-26 13:33:59.068453: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-26 13:33:59.068506: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-26 13:33:59.068519: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-26 13:33:59.068531: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-26 13:33:59.068543: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-26 13:33:59.068555: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-26 13:33:59.068567: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-26 13:33:59.068580: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-26 13:33:59.069675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-26 13:33:59.073411: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-26 13:34:01.651108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-26 13:34:01.651154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-26 13:34:01.651164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-26 13:34:01.657996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:db:00.0, compute capability: 7.5)
2022-09-26 13:34:04.490683: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-26 13:34:06.450346: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-26 13:34:07.540408: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-26 13:34:22.067718: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-26 13:34:22.069453: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
cfg: {'experiment': {'name': '26_sep_layers7_s32_e128_latent128_128_temp01_onlycont_newaug2', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 50, 'num_constrains': 6000, 'batch_size': 64, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 100, 'lrs': True}, 'model': {'latent_dim': 128, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/50
937/937 - 1883s - loss: 4.0711 - cont_loss: 4.0711
Epoch 2/50
937/937 - 1895s - loss: 3.5251 - cont_loss: 3.5251
Epoch 3/50
937/937 - 1904s - loss: 3.1510 - cont_loss: 3.1510
Epoch 4/50
937/937 - 1895s - loss: 2.8150 - cont_loss: 2.8150
Epoch 5/50
937/937 - 1896s - loss: 2.6213 - cont_loss: 2.6213
Epoch 6/50
937/937 - 1894s - loss: 2.4275 - cont_loss: 2.4275
Epoch 7/50
937/937 - 1895s - loss: 2.2816 - cont_loss: 2.2816
Epoch 8/50
937/937 - 1892s - loss: 2.1495 - cont_loss: 2.1495
Epoch 9/50
937/937 - 1887s - loss: 2.0539 - cont_loss: 2.0539
Epoch 10/50
937/937 - 1887s - loss: 1.9607 - cont_loss: 1.9607
Epoch 11/50
937/937 - 1889s - loss: 1.8740 - cont_loss: 1.8740
Epoch 12/50
937/937 - 1893s - loss: 1.7942 - cont_loss: 1.7942
Epoch 13/50
937/937 - 1890s - loss: 1.7510 - cont_loss: 1.7510
Epoch 14/50
937/937 - 1893s - loss: 1.6959 - cont_loss: 1.6959
Epoch 15/50
937/937 - 1892s - loss: 1.6461 - cont_loss: 1.6461
Epoch 16/50
937/937 - 1991s - loss: 1.6297 - cont_loss: 1.6297
Epoch 17/50
937/937 - 1998s - loss: 1.5792 - cont_loss: 1.5792
Epoch 18/50
937/937 - 1994s - loss: 1.5418 - cont_loss: 1.5418
Epoch 19/50
937/937 - 1995s - loss: 1.5224 - cont_loss: 1.5224
Epoch 20/50
937/937 - 1995s - loss: 1.4811 - cont_loss: 1.4811
Epoch 21/50
937/937 - 1977s - loss: 1.4671 - cont_loss: 1.4671
Epoch 22/50
937/937 - 1951s - loss: 1.4284 - cont_loss: 1.4284
Epoch 23/50
937/937 - 1948s - loss: 1.4267 - cont_loss: 1.4267
Epoch 24/50
937/937 - 1950s - loss: 1.3975 - cont_loss: 1.3975
Epoch 25/50
937/937 - 1951s - loss: 1.3666 - cont_loss: 1.3666
Epoch 26/50
937/937 - 1954s - loss: 1.3547 - cont_loss: 1.3547
/cluster/shadow/.lsbatch/1664191999.232427890: line 8: 87669 Killed                  python main_contrastive.py --config ../config.yml
Sender: LSF System <lsfadmin@eu-g3-003>
Subject: Job 232462701: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-30> by user <goezsoy> in cluster <euler> at Mon Sep 26 23:47:12 2022
Job was executed on host(s) <4*eu-g3-003>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Mon Sep 26 23:47:34 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Mon Sep 26 23:47:34 2022
Terminated at Tue Sep 27 08:22:04 2022
Results reported at Tue Sep 27 08:22:04 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   33681.18 sec.
    Max Memory :                                 16384 MB
    Average Memory :                             12370.28 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               0.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                23
    Run time :                                   30870 sec.
    Turnaround time :                            30892 sec.

The output (if any) follows:

2022-09-26 23:47:37.820651: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-26 23:47:55.790022: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-26 23:47:55.795073: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-26 23:47:55.840966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-26 23:47:55.841022: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-26 23:47:55.942840: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-26 23:47:55.943010: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-26 23:47:55.948114: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-26 23:47:55.982045: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-26 23:47:56.079833: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-26 23:47:56.122957: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-26 23:47:56.128562: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-26 23:47:56.133520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-26 23:47:59.863439: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-26 23:47:59.865041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-26 23:47:59.865096: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-26 23:47:59.865146: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-26 23:47:59.865176: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-26 23:47:59.865202: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-26 23:47:59.865228: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-26 23:47:59.865253: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-26 23:47:59.865279: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-26 23:47:59.865306: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-26 23:47:59.867715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-26 23:47:59.871914: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-26 23:48:02.116717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-26 23:48:02.116930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-26 23:48:02.116938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-26 23:48:02.124948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
2022-09-26 23:48:03.799017: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-26 23:48:05.500519: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-26 23:48:07.227684: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-26 23:48:20.584159: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-26 23:48:20.585765: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2250000000 Hz
cfg: {'experiment': {'name': '27_sep_layers7_s32_e128_latent128_128_temp01_onlycont_newaug', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 20, 'num_constrains': 6000, 'batch_size': 64, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 100, 'lrs': True}, 'model': {'latent_dim': 128, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/20
937/937 - 1393s - loss: 4.1131 - cont_loss: 4.1131
Epoch 2/20
937/937 - 1411s - loss: 3.6286 - cont_loss: 3.6286
Epoch 3/20
937/937 - 1439s - loss: 3.2308 - cont_loss: 3.2308
Epoch 4/20
937/937 - 1448s - loss: 2.9091 - cont_loss: 2.9091
Epoch 5/20
937/937 - 1431s - loss: 2.6932 - cont_loss: 2.6932
Epoch 6/20
937/937 - 1418s - loss: 2.5030 - cont_loss: 2.5030
Epoch 7/20
937/937 - 1428s - loss: 2.3498 - cont_loss: 2.3498
Epoch 8/20
937/937 - 1509s - loss: 2.2201 - cont_loss: 2.2201
Epoch 9/20
937/937 - 1469s - loss: 2.0912 - cont_loss: 2.0912
Epoch 10/20
937/937 - 1465s - loss: 2.0094 - cont_loss: 2.0094
Epoch 11/20
937/937 - 1521s - loss: 1.9316 - cont_loss: 1.9316
Epoch 12/20
937/937 - 1482s - loss: 1.8608 - cont_loss: 1.8608
Epoch 13/20
937/937 - 1479s - loss: 1.8044 - cont_loss: 1.8044
Epoch 14/20
937/937 - 1477s - loss: 1.7466 - cont_loss: 1.7466
Epoch 15/20
937/937 - 1479s - loss: 1.7059 - cont_loss: 1.7059
Epoch 16/20
937/937 - 1465s - loss: 1.6604 - cont_loss: 1.6604
Epoch 17/20
937/937 - 1462s - loss: 1.6162 - cont_loss: 1.6162
Epoch 18/20
937/937 - 1464s - loss: 1.5839 - cont_loss: 1.5839
Epoch 19/20
937/937 - 1452s - loss: 1.5270 - cont_loss: 1.5270
Epoch 20/20
937/937 - 1425s - loss: 1.5130 - cont_loss: 1.5130
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape_1:0", shape=(None,), dtype=int32), values=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape:0", shape=(None, None), dtype=float32), dense_shape=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
Traceback (most recent call last):
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/matplotlib/axes/_axes.py", line 4214, in _parse_scatter_color_args
    colors = mcolors.to_rgba_array(c)
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/matplotlib/colors.py", line 377, in to_rgba_array
    rgba = np.array([to_rgba(cc) for cc in c])
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/matplotlib/colors.py", line 377, in <listcomp>
    rgba = np.array([to_rgba(cc) for cc in c])
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/matplotlib/colors.py", line 187, in to_rgba
    rgba = _to_rgba_no_colorcycle(c, alpha)
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/matplotlib/colors.py", line 269, in _to_rgba_no_colorcycle
    raise ValueError(f"Invalid RGBA argument: {orig_c!r}")
ValueError: Invalid RGBA argument: 6.0

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main_contrastive.py", line 162, in <module>
  File "main_contrastive.py", line 118, in run_experiment
    yy = estimator.predict(z)
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/matplotlib/pyplot.py", line 2819, in scatter
    __ret = gca().scatter(
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/matplotlib/__init__.py", line 1412, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/matplotlib/axes/_axes.py", line 4380, in scatter
    self._parse_scatter_color_args(
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/matplotlib/axes/_axes.py", line 4220, in _parse_scatter_color_args
    raise invalid_shape_exception(c.size, xsize) from err
ValueError: 'c' argument has 60000 elements, which is inconsistent with 'x' and 'y' with size 10000.
Sender: LSF System <lsfadmin@eu-g2-15>
Subject: Job 232463583: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-30> by user <goezsoy> in cluster <euler> at Mon Sep 26 23:50:37 2022
Job was executed on host(s) <4*eu-g2-15>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Mon Sep 26 23:51:05 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Mon Sep 26 23:51:05 2022
Terminated at Tue Sep 27 10:15:15 2022
Results reported at Tue Sep 27 10:15:15 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46729.34 sec.
    Max Memory :                                 16384 MB
    Average Memory :                             10636.36 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               0.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                33
    Run time :                                   37449 sec.
    Turnaround time :                            37478 sec.

The output (if any) follows:

2022-09-26 23:51:07.824246: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-26 23:51:19.105926: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-26 23:51:19.108145: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-26 23:51:19.146483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:da:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-26 23:51:19.146515: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-26 23:51:19.152332: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-26 23:51:19.152394: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-26 23:51:19.155081: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-26 23:51:19.156703: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-26 23:51:19.161244: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-26 23:51:19.163202: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-26 23:51:19.165154: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-26 23:51:19.166208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-26 23:51:21.199322: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-26 23:51:21.200169: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-26 23:51:21.201576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:da:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-26 23:51:21.201646: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-26 23:51:21.201715: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-26 23:51:21.201752: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-26 23:51:21.201786: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-26 23:51:21.201819: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-26 23:51:21.201853: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-26 23:51:21.201887: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-26 23:51:21.201922: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-26 23:51:21.203976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-26 23:51:21.204045: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-26 23:51:21.769181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-26 23:51:21.769226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-26 23:51:21.769233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-26 23:51:21.770914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:da:00.0, compute capability: 7.5)
2022-09-26 23:51:24.023897: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-26 23:51:24.548180: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-26 23:51:26.609518: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-26 23:51:29.990155: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-26 23:51:29.991602: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
cfg: {'experiment': {'name': '27_sep_layers7_s32_e128_latent128_128_temp01_onlycont_newaug2', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '../checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 30, 'num_constrains': 6000, 'batch_size': 128, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 100, 'lrs': True}, 'model': {'latent_dim': 128, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/30
468/468 - 1171s - loss: 4.6933 - cont_loss: 4.6933
Epoch 2/30
468/468 - 1169s - loss: 4.0240 - cont_loss: 4.0240
Epoch 3/30
468/468 - 1171s - loss: 3.5664 - cont_loss: 3.5664
Epoch 4/30
468/468 - 1226s - loss: 3.2477 - cont_loss: 3.2477
Epoch 5/30
468/468 - 1227s - loss: 2.9736 - cont_loss: 2.9736
Epoch 6/30
468/468 - 1189s - loss: 2.7794 - cont_loss: 2.7794
Epoch 7/30
468/468 - 1180s - loss: 2.6098 - cont_loss: 2.6098
Epoch 8/30
468/468 - 1184s - loss: 2.4846 - cont_loss: 2.4846
Epoch 9/30
468/468 - 1186s - loss: 2.3784 - cont_loss: 2.3784
Epoch 10/30
468/468 - 1179s - loss: 2.2843 - cont_loss: 2.2843
Epoch 11/30
468/468 - 1192s - loss: 2.1985 - cont_loss: 2.1985
Epoch 12/30
468/468 - 1182s - loss: 2.1267 - cont_loss: 2.1267
Epoch 13/30
468/468 - 1182s - loss: 2.0671 - cont_loss: 2.0671
Epoch 14/30
468/468 - 1178s - loss: 2.0170 - cont_loss: 2.0170
Epoch 15/30
468/468 - 1184s - loss: 1.9858 - cont_loss: 1.9858
Epoch 16/30
468/468 - 1203s - loss: 1.9414 - cont_loss: 1.9414
Epoch 17/30
468/468 - 1183s - loss: 1.9054 - cont_loss: 1.9054
Epoch 18/30
468/468 - 1167s - loss: 1.8661 - cont_loss: 1.8661
Epoch 19/30
468/468 - 1173s - loss: 1.8265 - cont_loss: 1.8265
Epoch 20/30
468/468 - 1191s - loss: 1.8125 - cont_loss: 1.8125
Epoch 21/30
468/468 - 1176s - loss: 1.7717 - cont_loss: 1.7717
Epoch 22/30
468/468 - 1168s - loss: 1.7405 - cont_loss: 1.7405
Epoch 23/30
468/468 - 1167s - loss: 1.7297 - cont_loss: 1.7297
Epoch 24/30
468/468 - 1167s - loss: 1.7079 - cont_loss: 1.7079
Epoch 25/30
468/468 - 1164s - loss: 1.6864 - cont_loss: 1.6864
Epoch 26/30
468/468 - 1181s - loss: 1.6744 - cont_loss: 1.6744
Epoch 27/30
468/468 - 1193s - loss: 1.6343 - cont_loss: 1.6343
Epoch 28/30
468/468 - 1177s - loss: 1.6171 - cont_loss: 1.6171
Epoch 29/30
468/468 - 1172s - loss: 1.6171 - cont_loss: 1.6171
Epoch 30/30
468/468 - 1175s - loss: 1.5884 - cont_loss: 1.5884
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape_1:0", shape=(None,), dtype=int32), values=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape:0", shape=(None, None), dtype=float32), dense_shape=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
Traceback (most recent call last):
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/matplotlib/axes/_axes.py", line 4214, in _parse_scatter_color_args
    colors = mcolors.to_rgba_array(c)
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/matplotlib/colors.py", line 377, in to_rgba_array
    rgba = np.array([to_rgba(cc) for cc in c])
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/matplotlib/colors.py", line 377, in <listcomp>
    rgba = np.array([to_rgba(cc) for cc in c])
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/matplotlib/colors.py", line 187, in to_rgba
    rgba = _to_rgba_no_colorcycle(c, alpha)
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/matplotlib/colors.py", line 269, in _to_rgba_no_colorcycle
    raise ValueError(f"Invalid RGBA argument: {orig_c!r}")
ValueError: Invalid RGBA argument: 6.0

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main_contrastive.py", line 162, in <module>
  File "main_contrastive.py", line 118, in run_experiment
    yy = estimator.predict(z)
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/matplotlib/pyplot.py", line 2819, in scatter
    __ret = gca().scatter(
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/matplotlib/__init__.py", line 1412, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/matplotlib/axes/_axes.py", line 4380, in scatter
    self._parse_scatter_color_args(
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/matplotlib/axes/_axes.py", line 4220, in _parse_scatter_color_args
    raise invalid_shape_exception(c.size, xsize) from err
ValueError: 'c' argument has 60000 elements, which is inconsistent with 'x' and 'y' with size 10000.
Sender: LSF System <lsfadmin@eu-g3-037>
Subject: Job 232505762: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-05> by user <goezsoy> in cluster <euler> at Tue Sep 27 13:50:18 2022
Job was executed on host(s) <4*eu-g3-037>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Tue Sep 27 13:50:42 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Tue Sep 27 13:50:42 2022
Terminated at Tue Sep 27 13:50:46 2022
Results reported at Tue Sep 27 13:50:46 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   0.32 sec.
    Max Memory :                                 14 MB
    Average Memory :                             -
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               16370.00 MB
    Max Swap :                                   -
    Max Processes :                              -
    Max Threads :                                -
    Run time :                                   4 sec.
    Turnaround time :                            28 sec.

The output (if any) follows:

  File "main_contrastive.py", line 81
    save_weights_only=True, save_best_only=True))
    ^
SyntaxError: invalid syntax
Sender: LSF System <lsfadmin@eu-g3-037>
Subject: Job 232505783: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-05> by user <goezsoy> in cluster <euler> at Tue Sep 27 13:52:29 2022
Job was executed on host(s) <4*eu-g3-037>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Tue Sep 27 13:52:44 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Tue Sep 27 13:52:44 2022
Terminated at Tue Sep 27 13:53:59 2022
Results reported at Tue Sep 27 13:53:59 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 143.

Resource usage summary:

    CPU time :                                   45.50 sec.
    Max Memory :                                 8001 MB
    Average Memory :                             5484.80 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               8383.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                23
    Run time :                                   75 sec.
    Turnaround time :                            90 sec.

The output (if any) follows:

2022-09-27 13:52:49.427094: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-27 13:53:01.731035: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-27 13:53:01.754985: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-27 13:53:01.838579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:a1:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.62GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-27 13:53:01.838718: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-27 13:53:01.947213: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-27 13:53:01.947423: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-27 13:53:01.991413: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-27 13:53:02.028940: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-27 13:53:02.127357: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-27 13:53:02.171482: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-27 13:53:02.178147: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-27 13:53:02.188825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-27 13:53:06.476607: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-27 13:53:06.480488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:a1:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.62GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-27 13:53:06.480549: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-27 13:53:06.480603: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-27 13:53:06.480629: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-27 13:53:06.480653: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-27 13:53:06.480676: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-27 13:53:06.480700: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-27 13:53:06.480737: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-27 13:53:06.480765: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-27 13:53:06.482802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-27 13:53:06.487633: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-27 13:53:07.024323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-27 13:53:07.024385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-27 13:53:07.024393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-27 13:53:07.042029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:a1:00.0, compute capability: 7.5)
2022-09-27 13:53:09.910237: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-27 13:53:11.612821: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-27 13:53:13.965414: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-27 13:53:28.133816: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-27 13:53:28.148561: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2249985000 Hz
cfg: {'experiment': {'name': '27_sep_layers7_s32_e128_latent128_128_temp01_onlycont_newaug_TEST', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': False, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '/cluster/scratch/goezsoy/dcgmm_checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 2, 'num_constrains': 6000, 'batch_size': 128, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 100, 'lrs': True}, 'model': {'latent_dim': 128, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/2
5/5 - 12s - loss: 5.5561 - cont_loss: 5.5561
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape_1:0", shape=(None,), dtype=int32), values=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape:0", shape=(None, None), dtype=float32), dense_shape=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
Epoch 2/2
Traceback (most recent call last):
  File "main_contrastive.py", line 180, in <module>
    run_experiment(cfg)
  File "main_contrastive.py", line 88, in run_experiment
    model.fit(train_generator, steps_per_epoch=5, epochs=cfg['training']['epochs'], callbacks=callback_list, verbose=2)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 1100, in fit
    tmp_logs = self.train_function(iterator)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 828, in __call__
    result = self._call(*args, **kwds)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 855, in _call
    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/function.py", line 2942, in __call__
    return graph_function._call_flat(
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/function.py", line 1918, in _call_flat
    return self._build_call_outputs(self._inference_function.call(
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/function.py", line 555, in call
    outputs = execute.execute(
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/execute.py", line 59, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
KeyboardInterrupt
Terminated
Sender: LSF System <lsfadmin@eu-g3-039>
Subject: Job 232505805: <python main_contrastive.py --config ../config.yml> in cluster <euler> Exited

Job <python main_contrastive.py --config ../config.yml> was submitted from host <eu-login-05> by user <goezsoy> in cluster <euler> at Tue Sep 27 13:54:00 2022
Job was executed on host(s) <4*eu-g3-039>, in queue <gpu.24h>, as user <goezsoy> in cluster <euler> at Tue Sep 27 13:54:11 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/constrastive-DC-GMM/src> was used as the working directory.
Started at Tue Sep 27 13:54:11 2022
Terminated at Tue Sep 27 14:13:30 2022
Results reported at Tue Sep 27 14:13:30 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main_contrastive.py --config ../config.yml
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   1135.58 sec.
    Max Memory :                                 9489 MB
    Average Memory :                             9040.51 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               6895.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                23
    Run time :                                   1159 sec.
    Turnaround time :                            1170 sec.

The output (if any) follows:

2022-09-27 13:54:14.814551: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-27 13:54:32.598371: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-27 13:54:32.604750: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-09-27 13:54:32.663376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:81:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-27 13:54:32.663420: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-27 13:54:32.697096: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-27 13:54:32.697182: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-27 13:54:32.708284: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-27 13:54:32.721305: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-27 13:54:32.751497: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-27 13:54:32.762258: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-27 13:54:32.765764: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-27 13:54:32.771484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-27 13:54:36.520978: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-27 13:54:36.522296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:81:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-09-27 13:54:36.522340: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-27 13:54:36.522382: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-27 13:54:36.522403: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-27 13:54:36.522422: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-09-27 13:54:36.522450: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-09-27 13:54:36.522471: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-09-27 13:54:36.522490: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-09-27 13:54:36.522509: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-27 13:54:36.524323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-09-27 13:54:36.528031: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-09-27 13:54:38.738472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-27 13:54:38.738542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-09-27 13:54:38.738552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-09-27 13:54:38.746155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:81:00.0, compute capability: 7.5)
2022-09-27 13:54:40.957605: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-09-27 13:54:42.608911: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-09-27 13:54:44.769953: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-09-27 13:54:58.231881: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-27 13:54:58.233505: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2250045000 Hz
cfg: {'experiment': {'name': '27_sep_layers7_s32_e128_latent128_128_temp01_onlycont_newaug_TEST', 'runs': 1, 'pretrain': False, 'epochs_pretrain': 10, 'lr_pretrain': 0.001, 'save_model': True, 'save_embedding': True, 'seed': 42}, 'dataset': {'name': 'CIFAR10'}, 'dir': {'data': None, 'checkpoint': '/cluster/scratch/goezsoy/dcgmm_checkpoints', 'logging': '../logs', 'pretrain': '../pretrain'}, 'training': {'epochs': 2, 'num_constrains': 6000, 'batch_size': 128, 'alpha': 10000.0, 'q': 0, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'ml': 0, 'decay_rate': 0.9, 'epochs_lr': 100, 'lrs': True}, 'model': {'latent_dim': 128, 'num_clusters': 10, 'activation': 'sigmoid', 'type': 'VGG', 'is_unsupervised': False}}
Epoch 1/2
5/5 - 11s - loss: 5.6222 - cont_loss: 5.6222
Epoch 2/2
5/5 - 10s - loss: 5.4237 - cont_loss: 5.4237
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape_1:0", shape=(None,), dtype=int32), values=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Reshape:0", shape=(None, None), dtype=float32), dense_shape=Tensor("gradient_tape/ContrastiveAE/loop_body/GatherV2/pfor/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/cluster/home/goezsoy/.local/lib/python3.8/site-packages/sklearn/utils/linear_assignment_.py:124: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.
  warnings.warn(
WARNING:tensorflow:Saver is deprecated, please switch to tf.train.Checkpoint or tf.keras.Model.save_weights for training checkpoints. When executing eagerly variables do not necessarily have unique names, and so the variable.name-based lookups Saver performs are error-prone.
pretrain accuracy: 0.16575
Traceback (most recent call last):
  File "main_contrastive.py", line 180, in <module>
    run_experiment(cfg)
  File "main_contrastive.py", line 155, in run_experiment
    rec = model.predict(temp_X)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 1629, in predict
    tmp_batch_outputs = self.predict_function(iterator)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 828, in __call__
    result = self._call(*args, **kwds)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 871, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 725, in _initialize
    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/function.py", line 2969, in _get_concrete_function_internal_garbage_collected
    graph_function, _ = self._maybe_define_function(args, kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/function.py", line 3361, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/function.py", line 3196, in _create_graph_function
    func_graph_module.func_graph_from_py_func(
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/func_graph.py", line 990, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 634, in wrapped_fn
    out = weak_wrapped_fn().__wrapped__(*args, **kwds)
  File "/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/func_graph.py", line 977, in wrapper
    raise e.ag_error_metadata.to_exception(e)
TypeError: in user code:

    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *
        return step_function(self, iterator)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica
        return fn(*args, **kwargs)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1463 run_step  **
        with ops.control_dependencies(_minimum_control_deps(outputs)):
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/ops.py:5359 control_dependencies
        return get_default_graph().control_dependencies(control_inputs)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/func_graph.py:362 control_dependencies
        return super(FuncGraph, self).control_dependencies(filtered_control_inputs)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/ops.py:4815 control_dependencies
        c = self.as_graph_element(c)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/ops.py:3726 as_graph_element
        return self._as_graph_element_locked(obj, allow_tensor, allow_operation)
    /cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tensorflow/python/framework/ops.py:3814 _as_graph_element_locked
        raise TypeError("Can not convert a %s into a %s." %

    TypeError: Can not convert a NoneType into a Tensor or Operation.

